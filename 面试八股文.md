#      面试复习

## IO

### 1. IO中的同步、异步、阻塞、非阻塞

同步和异步强调的是调用方的行为。

- 同步：调用方发起IO请求，必须等待IO操作完成才能继续执行后续代码
- 异步：调用方发起IO请求，不等待操作完成，后续代码立即继续执行，通过回调或通知获取结果

阻塞非阻塞强调的是线程的状态。

- 阻塞：线程在等待IO操作完成期间无法处理其他任务
- 非阻塞：线程发起IO请求后立即返回，可重复尝试直到操作完成（需要轮询或事件通知）

可以两两进行组合

- 同步阻塞IO：传统java IO，例如：FileInputStream
- 同步非阻塞IO：NIO的Selector模型，将SocketChannel设置为非阻塞模式，通过Selector轮询就绪的Channel
- 异步阻塞IO：真要说阻塞的点可能是异步回调的那个线程阻塞，future.get
- 异步非阻塞IO：java的AIO（AsynchronousSocketChannel）异步读写无需轮询，直接通过回调处理

### 2. select、poll、epoll

这三个都是操作系统提供的IO多路复用机制

|                   | select                                                       | poll                                                         | epoll                                                        |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 使用方式          | 调用select方法，将需要监听的文件描述符集合传递给内核，内核阻塞直到某个文件描述符就绪（可读/可写/异常） | 使用一个动态数组代替固定大小的位图来存储文件描述符集合，理论上可以支持更多的文件描述符。 | 三个接口：通过 `epoll_create` 创建一个epoll实例。通过 `epoll_ctl` 将文件描述符注册到epoll实例中，并指定感兴趣的事件类型（如读/写）。通过 `epoll_wait` 等待就绪的文件描述符集合，内核只会返回就绪的文件描述符，而不需要遍历所有文件描述符。<br />两个模式：水平触发LT：只要文件描述符处于就绪状态（如可读或可写），`epoll_wait` 就会持续返回该事件。边缘触发ET：仅在文件描述符状态发生变化时（如从不可读变为可读）触发一次事件。 |
| 文件描述符数量    | 受限，通常1024                                               | 理论上无限制                                                 | 理论上无限制                                                 |
| 时间复杂度        | O(n)                                                         | O(n)                                                         | O(1)（近似）                                                 |
| 用户态/内核态交互 | 每次调用都需要拷贝文件描述符集合                             | 每次调用都需要拷贝文件描述符集合                             | 文件描述符集合存储在内核中                                   |
| 适用场景          | 小规模并发场景                                               | 中等规模并发场景                                             | 大规模高并发场景                                             |
| 跨平台性          | 跨平台                                                       | 跨平台                                                       | 仅限Linux                                                    |

### 3. 如何选择select、poll、epoll模型

| **场景**                      | **推荐模型**       | **原因**                                                     |
| ----------------------------- | ------------------ | ------------------------------------------------------------ |
| 小规模连接（< 1000 FD）       | `select` 或 `poll` | 文件描述符数量少，`select` 和 `poll` 性能足够好，开发简单。  |
| 中等规模连接（1000~10000 FD） | `poll`             | `poll` 支持更多 FD，性能优于 `select`，开发复杂度低于 `epoll`。 |
| 高并发场景（> 10000 FD）      | `epoll`            | `epoll` 的事件驱动机制和 O(1) 时间复杂度使其适合高并发场景。 |
| 跨平台需求                    | `poll` 或 `select` | `epoll` 是 Linux 特有，`poll` 和 `select` 具有更好的跨平台兼容性。 |
| 短连接场景                    | `poll` 或 `select` | `epoll_ctl` 的频繁调用会带来额外开销，`poll` 更适合短连接场景。 |
| 长连接场景                    | `epoll`            | 长连接场景下，`epoll` 的事件通知机制能显著降低 CPU 开销。    |

### 4. select、poll、epoll示例代码

select

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/select.h>

#define MAX_FD 1024

int main() {
    fd_set readfds;
    int sockfd = STDIN_FILENO; // 监控标准输入（键盘输入）

    while (1) {
        FD_ZERO(&readfds);                // 清空集合
        FD_SET(sockfd, &readfds);         // 将 sockfd 添加到集合中

        // 调用 select，阻塞等待事件
        int ret = select(sockfd + 1, &readfds, NULL, NULL, NULL);
        if (ret == -1) {
            perror("select error");
            exit(EXIT_FAILURE);
        }

        // 检查是否就绪
        if (FD_ISSET(sockfd, &readfds)) {
            char buffer[1024] = {0};
            ssize_t n = read(sockfd, buffer, sizeof(buffer) - 1);
            if (n > 0) {
                printf("Read from stdin: %s\n", buffer);
            } else {
                perror("read error");
                break;
            }
        }
    }

    return 0;
}

```

poll

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <poll.h>

#define MAX_FD 1024

int main() {
    struct pollfd fds[1];
    fds[0].fd = STDIN_FILENO;      // 监控标准输入
    fds[0].events = POLLIN;        // 关注可读事件

    while (1) {
        // 调用 poll，阻塞等待事件
        int ret = poll(fds, 1, -1); // -1 表示无限期阻塞
        if (ret == -1) {
            perror("poll error");
            exit(EXIT_FAILURE);
        }

        // 检查是否就绪
        if (fds[0].revents & POLLIN) {
            char buffer[1024] = {0};
            ssize_t n = read(STDIN_FILENO, buffer, sizeof(buffer) - 1);
            if (n > 0) {
                printf("Read from stdin: %s\n", buffer);
            } else {
                perror("read error");
                break;
            }
        }
    }

    return 0;
}

```

epoll

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/epoll.h>

#define MAX_EVENTS 1024

int main() {
    int epollfd = epoll_create1(0); // 创建 epoll 实例
    if (epollfd == -1) {
        perror("epoll_create1 error");
        exit(EXIT_FAILURE);
    }

    struct epoll_event event;
    event.events = EPOLLIN | EPOLLET; // 设置为 ET 模式
    event.data.fd = STDIN_FILENO;    // 监控标准输入

    // 注册事件
    if (epoll_ctl(epollfd, EPOLL_CTL_ADD, STDIN_FILENO, &event) == -1) {
        perror("epoll_ctl error");
        exit(EXIT_FAILURE);
    }

    struct epoll_event events[MAX_EVENTS];
    while (1) {
        // 等待事件
        int nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1);
        if (nfds == -1) {
            perror("epoll_wait error");
            exit(EXIT_FAILURE);
        }

        for (int i = 0; i < nfds; i++) {
            if (events[i].data.fd == STDIN_FILENO) {
                char buffer[1024] = {0};
                ssize_t n = read(STDIN_FILENO, buffer, sizeof(buffer) - 1);
                if (n > 0) {
                    printf("Read from stdin: %s\n", buffer);
                } else {
                    perror("read error");
                    close(epollfd);
                    return -1;
                }
            }
        }
    }

    close(epollfd);
    return 0;
}

```

### 5. java中BIO、NIO、AIO

1. **BIO (Blocking IO)**: 是同步阻塞IO。发起请求 -> 阻塞等待 -> 处理完成
2. **NIO (Non-blocking IO / New IO)**: 被称为非阻塞同步IO或新IO。Selector主动轮询channel -> 处理请求 -> 处理完成
3. **AIO (Asynchronous IO)**: 是异步非阻塞IO。发起请求 -> 通知回调

### 6. BIO、NIO、AIO代码示例

bio

```java
ServerSocket serverSocket = new ServerSocket(8080);
System.out.println("BIO Server started on port 8080");
while (true) {
    Socket clientSocket = serverSocket.accept(); // 阻塞等待客户端连接
    System.out.println("Accepted connection from " + clientSocket);
    BufferedReader in = new BufferedReader(new InputStreamReader(clientSocket.getInputStream()));
    String request = in.readLine(); // 阻塞读取客户端数据
    System.out.println("Received: " + request);
    OutputStream out = clientSocket.getOutputStream();
    out.write(("Echo: " + request + "\n").getBytes()); // 向客户端发送响应
    out.flush();
    clientSocket.close();
}
```

nio

```java
Selector selector = Selector.open();
ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();
serverSocketChannel.socket().bind(new InetSocketAddress(8080));
serverSocketChannel.configureBlocking(false);
serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);
System.out.println("NIO Server started on port 8080");
while (selector.select() > 0) {
    Iterator<SelectionKey> keys = selector.selectedKeys().iterator();
    while (keys.hasNext()) {
        SelectionKey key = keys.next();
        keys.remove();
        if (key.isAcceptable()) {
            ServerSocketChannel server = (ServerSocketChannel) key.channel();
            SocketChannel client = server.accept();
            client.configureBlocking(false);
            client.register(selector, SelectionKey.OP_READ);
            System.out.println("Accepted connection from " + client);
        } else if (key.isReadable()) {
            SocketChannel client = (SocketChannel) key.channel();
            ByteBuffer buffer = ByteBuffer.allocate(256);
            client.read(buffer);
            String request = new String(buffer.array()).trim();
            System.out.println("Received: " + request);
            ByteBuffer response = ByteBuffer.wrap(("Echo: " + request).getBytes());
            client.write(response);
        }
    }
}
```

## Java基础

### 1. Object类有哪些方法

- getClass：获取类的Class对象
- hashCode：获取对象的hashCode值
- equals：比较对象是否相等，比较值和地址
- clone：浅拷贝，使用时要实现java.lang.Cloneable接口，比如A和B都有一个成员变量是X，B是Aclone出来的，改变X，A和B的都改变
- toString：返回字符串包括该对象的类名称，"@"字符以及该对象的哈希码的无符号十六进制表示形式，一般会被重写
- finalize：在垃圾回收之前被执行，可以通过重写finalize方法来重置系统资源，执行清理活动并且最大程度的减少内存泄露，JDK9之后不用了
- wait：让当前线程进入等待序列
- wait(long timeout)：在其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量前，导致当前线程等待
- wait(long timeout, int nanos)：在其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量前，导致当前线程等待
- notify：该方法唤醒在该对象上等待的某个线程
- notifyAll：该方法唤醒在该对象上等待的所有线程

### 2. 接口和抽象类的区别

| **对比维度**   | **抽象类**                                                   | **接口**                                                     |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **方法实现**   | 可以包含具体方法（非抽象方法）和抽象方法（无实现）。         | （Java 8前）只能定义抽象方法；（Java 8+）可以定义默认方法、静态方法和抽象方法。 |
| **继承与实现** | 子类通过 `extends` 继承抽象类，且**单继承**（只能继承一个抽象类）。 | 类通过 `implements` 实现接口，且**多实现**（可以实现多个接口）。 |
| **构造方法**   | 可以有构造方法。                                             | 无构造方法。                                                 |
| **成员变量**   | 可以定义具体成员变量（非`static`和`final`的变量）。          | （Java 9前）只能定义 `public static final` 常量；（Java 9+）支持 `private` 成员变量。 |
| **访问权限**   | 方法默认权限是 `public` 或 `protected`（需显式声明）。       | 方法默认权限是 `public`（需显式声明）。                      |

抽象类适用于共享代码和状态的场景。强调的是什么是什么的关系。

接口适用于需要多实现或行为解耦的场景。强调的是拥有什么样的行为。

### 3. 为什么接口的成员变量只能是public static final

"接口中的成员变量必须是 `public static final`，这是由接口的设计目标和语义决定的。

首先，接口的核心目的是定义**行为契约**，而不是存储状态或数据。为了保持接口的纯粹性，Java强制接口中的变量满足以下特性：

1. **`static`：避免实例依赖**
    接口本身不能被实例化，因此接口中的变量无法与某个实例绑定。如果允许非静态变量，会导致逻辑混乱，因为接口没有实例来存储这些变量。
2. **`final`：不可变性**
    接口的设计初衷是提供行为契约，而非存储可变状态。如果允许变量是可变的，可能会导致实现类之间意外修改共享状态，破坏接口的行为一致性。
3. **`public`：全局可见性**
    接口的目的是定义公共的行为规范，供所有实现类使用。强制为 `public` 确保所有实现类都能访问这些常量，符合接口的开放性和通用性。

这种设计带来的好处包括：

- 简化设计，避免接口中出现状态管理和复杂性问题；
- 提高安全性，避免因多线程或并发导致的状态不一致；
- 符合接口语义，保持设计的纯粹性。

相比之下，抽象类可以有普通成员变量，因为它设计的目标是**代码复用**和**状态共享**，允许定义普通成员变量来存储状态。而接口专注于行为定义，因此不需要普通成员变量。"

### 4. ==和equals

- ==：基础数据类型：比较的是他们的值是否相等，比如两个int类型的变量。引用数据类型：比较的是引用的地址是否相同，比如说新建了两个User对象，比较的是两个User的地址是否一样。

- equals：Object类的源码里比较的是地址。但是像String这里面的会被重写。

- 实例：

  ```java
  String str1 = "Hello";
  String str2 = new String("Hello");
  String str3 = str2; // 引用传递
  System.out.println(str1 == str2); // false
  System.out.println(str1 == str3); // false
  System.out.println(str2 == str3); // true
  System.out.println(str1.equals(str2)); // true
  System.out.println(str1.equals(str3)); // true
  System.out.println(str2.equals(str3)); // true
  ```

- 上面实例的内存解释：String str1 = "Hello";会在堆区存放一个字符串对象"hello"(1)，然后栈里有str1指向它(1)。String str2 = new String("Hello");会在堆区再次存放一个字符串对象"hello"(2)，然后栈里有str2指向它(2)。String str3 = str2;栈里会有一个str3，指向"hello"(2)。==比较地址，equals比较值。

- 延申：

  ```java
  String s1 = "Hello";
  String s2 = new String("Hello");
  s2 = s2.intern();
  System.out.println(s1 == s2);       //  true
  System.out.println(s1.equals(s2));  //  true
  ```

- 在这里多了一个intern方法，他的意思是检查字符串池里是否存在。String s1 = "Hello";会在堆区存放一个字符串对象"hello"。s2调用intern()方法时，因为字符串里已经有了，所以就直接把s2指向它就行了。所以s1和s2指向同一个。

### 5. 为什么重写equals()，必须要重写hashCode()

- 两个对象equals相等，那么他们hashCode一定也相同
- 两个对象hashCode相等，equals不一定相等
- 通常只要我们重写 equals方法就要重写 hashCode方法
- 如果不重写，在使用HashMap，HashTable时，是根据hashCode来判断的。假如说User类重写equals，只要类型相等，name相同，就返回true。那么User u1 = new User("abc");User u2 = new User("abc");这俩作为key往hashMap里put时，不会有覆盖。当我们重写了hashCode让User的name作为计算的值，用来产生最终的hash值，这样HashMap就可以帮我们把两个对象，路由到一个下标下面了，再通过equals比对，确定两个是同一个对象，从而达到去重的效果。

### 6. sleep()和wait()的区别

- 这两个方法来自不同的类分别是，sleep来自Thread类，和wait来自Object类
- 最主要是sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法
- 使用范围：wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用
- sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常

### 7. Java泛型是什么？使用泛型有什么好处

- 在集合中存储对象并在使用前进行类型转换非常不方便。泛型防止了那种情况的发生。它提供了编译期的类型安全，确保你只能把正确类型的对象放入集合中，避免了在运行时出现ClassCastException。

### 8. Java泛型是如何工作的

- 泛型是通过类型擦除来实现的，编译器在编译时擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息。例如List<String>在运行时仅用一个List来表示。这样做的目的，是确保能和Java 5之前的版本开发二进制类库进行兼容。你无法在运行时访问到类型参数，因为编译器已经把泛型类型转换成了原始类型。

### 9. 什么是泛型中的限定通配符和非限定通配符

- 限定通配符对类型进行了限制。有两种限定通配符，一种是<? extends T>它通过确保类型必须是T的子类来设定类型的上界,不能add只能get。要用的话只能封装一个方法，方法参数可以是子类
- 另一种是<? super T>它通过确保类型必须是T的父类来设定类型的下界。泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误。例子： List<? super Person> list = new ArrayList<>(); 只能往里面addPerson类和其子类和null。反而父类放不进去。只能add不能get。要用的话只能封装一个方法，方法参数可以是父类。
- 另一方面<?>表示了非限定通配符，因为<?>可以用任意类型来替代。

### 10. 什么是反射

- 反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。

### 11. 获取Class对象的方式

1. 第一种方法通过类的全路径字符串获取 Class 对象，这也是我们平时最常用的反射获取 Class 对象的方法；

   ```java
   Class studentClass = Class.forName("com.test.reflection.pojo.Student");
   ```

2. 第二种方法有限制条件：需要导入类的包；

   ```java
   Class studentClass2 = Student.class;
   ```

3. 第三种方法已经有了 Student 对象

   ```java
   Student studentObject = new Student();
   Class studentClass3 = studentObject.getClass();
   ```
   
4. 第四种方法类加载器

   ```java
   Class studentClass4 = Main.getClassLoader().loadClass("com.test.reflection.pojo.Student");
   ```

### 12. 如何利用反射创建对象

- 使用Class对象的newInstance()方法创建该Class对象的实例，要求必须要有无参数的构造方法
- 使用Class对象获取指定的Constructor对象，再调用Constructor的newInstance()方法创建对象类的实例，此时可以选择使用某个构造方法。如果这个构造方法被私有化起来，那么必须先申请访问，将可以访问设置为true(setAccessible(boolean flag))

### 13. Java内置注解

- @Override：java.lang.Override中，只适用于修饰方法，表示一个方法声明打算重写超类中的另一个方法声明

- @Deprecated：java.lang.Deprecated中，可以用于修饰方法、属性、类，表示不鼓励程序员使用这样的元素

- @SuppressWarnings：java.lang.SuppressWarnings中，用来抑制编译时的警告信息。这个注解使用的时候需要参数，比如：

  ```java
  @SuppressWarnings("all")
  
  @SuppressWarnings("unchecked")
  
  @SuppressWarnings(value = {"unchecked", "deprecation"})
  ```

### 14. Java的元注解 

- 元注解的作用就是负责注解其他注解，Java定义了4个标准的meta-annotation类型，他们被用来提供对其他annotation类型做说明。他们都在java.lang.annotation包下。
- @Target：用于描述注解的使用范围
- @Retention：表示需要在什么级别保持该注解信息。(SOURCE < CLASS < RUNTIME)
- @Document：说明该注解将被包含在javadoc中
- @Inherited：说明子类可以父类中的该注解

### 15. Exception和Error有什么区别

- Exception 和 Error 都是继承了 Throwable 类，在 Java 中只有 Throwable 类型的实例才可以被抛出（throw）或者捕获（catch），它是异常处理机制的基本组成类型。
- Exception 和 Error 体现了 Java 平台设计者对不同异常情况的分类。Exception 是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。Error 是指在正常情况下，不大可能出现的情况，绝大部分的 Error 都会导致程序（比如 JVM 自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如 OutOfMemoryError 之类，都是 Error 的子类。
- Exception 又分为可检查（checked）异常和不检查（unchecked）异常，可检查异常在源代码里必须显式地进行捕获处理，这是编译期检查的一部分。Error，是 Throwable 不是 Exception。不检查异常就是所谓的运行时异常，类似 NullPointerException、ArrayIndexOutOfBoundsException 之类，通常是可以编码避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。

### 16. 异常处理的基本原则

- 尽量不要捕获类似Exception这样的通用异常,而是应该捕获特定异常
- 不要生吞(swallow)异常

### 17. final、finally、finalize有什么不同

- final 可以用来修饰类、方法、变量，分别有不同的意义，final 修饰的 class 代表不可以继承扩展，final 的变量是不可以修改的，而 final 的方法也是不可以重写的（override）。
- finally 则是 Java 保证重点代码一定要被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭 JDBC 连接、保证 unlock 锁等动作。
- finalize 是基础类 java.lang.Object 的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize 机制现在已经不推荐使用，并且在 JDK 9 开始被标记为 deprecated。

### 18. String、StringBuffer、StringBuilder有什么区别

- String 是 Java 语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的 Immutable 类，被声明成为 final class，所有属性也都是 final 的。
- StringBuffer 是为解决上面提到拼接产生太多中间对象的问题而提供的一个类，我们可以用 append 或者 add 方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer 本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，所以除非有线程安全的需要，不然还是推荐使用它的后继者，也就是 StringBuilder。
- StringBuilder 在能力上和 StringBuffer 没有本质区别，但是它去掉了线程安全的部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。
- 在字节码层面，String在字符串拼接时，会new一个StringBuilder进行拼接。而StringBuilder由于之前new了，只需要调用append方法就行。

### 19. String str1 = "abc"; String str2 = new String ("abc"); 输出str1 == str2结果是什么

- false。str1和str2是引用类型，比较地址，前面str1引用的"abc"是常量池的，后者str2引用的是堆中的。地址不同。
- 可以调用intern()方法，如果常量池有，就直接引用它，没有就缓存起来。JDK1.6之前，少用这个方法，因为他们缓存在了永久代，使用不当会OOM。1.8之后，方法区由元空间实现，基本上问题解决了。
- 无论在哪里，使用String s = "a"; ==的结果都是ture。(静态变量和局部变量比，成员变量和局部变量比等等)

### 20. 重写和重载的区别

- 重写实现的是运行时的多态，而重载实现的是编译时的多态
- 重写的方法参数列表必须相同；而重载的方法参数列表必须不同
- 重写是父类与子类之间，重载是在一个类中
- 重写的方法的返回值类型只能是父类类型或者父类类型的子类，访问修饰符的限制一定要大于被重写方法的访问修饰符（public>protected>default>private)，而重载的方法对返回值类型没有要求

## Java集合

### 1. arraylist和linkedlist的区别

- ArrayList的实现是基于数组，连续的一块内存空间，LinkedList的实现是基于双向链表，不需要连续的空间
- 对于随机访问，ArrayList优于LinkedList，ArrayList可以根据下标以O(1)时间复杂度对元素进行随机访问。而LinkedList的每一个元素都依靠地址指针和它后一个元素连接在一起，在这种情况下，查找某个元素的时间复杂度是O(n)
- 对于插入和删除操作，LinkedList优于ArrayList，因为当元素被添加到LinkedList任意位置的时候，不需要像ArrayList那样重新计算大小或者是更新索引
- LinkedList比ArrayList更占内存，因为LinkedList的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素
- ArrayList扩容：新数组长度是原来的1.5倍(用移位操作)，然后用Arrays.copyOf将数组的元素复制到新数组

### 2. Arrays.asList(a).toArray == Object[].class结果是什么?

- false，这是1.8的一个Bug

### 3. HashMap的底层数据结构

- JDK7，数组+链表组成。链表是为了解决哈希冲突。加入数据时用头插法
- JDK8，数组+链表+红黑树组成。加入数据是尾插法
  - 链表超过8且数据总量超过64就会转成红黑树
  - 不超过64就扩容

### 4. 为什么不直接用红黑树？而选择先用链表，再转红黑树

- 因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于 8 个的时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于 8 个的时候， 红黑树搜索时间复杂度是 O(logn)，而链表是 O(n)，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了

### 5. 为什么链表改为红黑树的阈值是 8

理想情况下使用随机的哈希码，容器中节点分布在 hash 桶中的频率遵循泊松分布。个数为8的时候概论已经很小了

### 6. HashMap默认加载因子是多少？为什么是 0.75，不是 0.6 或者 0.8 ？

默认的loadFactor是0.75，0.75是对空间和时间效率的一个平衡选择，一般不要修改，除非在时间和空间比较特殊的情况下 ：

- 如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值 。
- 相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1

### 7. HashMap 中 key 的存储索引是怎么计算的

1. 取key的 hashCode 值
2. 根据 hashcode 计算出hash值（高16位异或低16位）
3. 通过取模计算下标（数组长度是2的幂次方，进行与操作非常方便）

### 8. HashMap的put方法流程

1. 首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标
2. 如果数组是空的，则调用 resize 进行初始化
3. 如果没有哈希冲突直接放在对应的数组下标里
4. 如果冲突了，且 key 已经存在，就覆盖掉 value
5. 如果冲突后，发现该节点是红黑树，就将这个节点挂在树上
6. 如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；否则，链表插入键值对，若 key 存在，就覆盖掉 value
7. JDK1.7版本就是先判断是不是需要扩容，不扩容就头插法

### 9. HashMap的扩容

只需要看看原来的 hash 值新增的那个bit是1还是0就好了，是0的 话索引没变，是1的话索引变成原索引 + oldCap

### 10. 解决Hash冲突

1. 开放地址法 
2. 再哈希法
3. 链地址法
4. 建立公共溢出区

### 11. 说说ConcurrentHashMap

1.7 put流程

1. 获取key的hash值
2. 根据散列码找到对应的segment
3. 对当前segment进行整体加锁，使用lock()
4. 当新建节点总数超过阈值，则调用rehash方法对segment进行扩容
5. 再次hash找到对应的具体的hashEntry
6. 如果hashEntry节点具有相同的key，则更新该hashEntry的value值，否则新建一个hashEntry，将他设置为链表的新head节点，并且next指向原来的头节点（头插法）

1.8 put的流程

1. 检查key和value都不能为空，算出key的hash值
2. 如果table没有初始化、则初始化
3. 根据hash值取出table里的首节点，如果为空，就把当前值构造成节点通过cas插入当前桶中，如果成功就退出循环，如果失败就进行下一轮
4. 如果hash值对应的桶节点不为空，并且节点hash值为-1，表示正在扩容，当前线程就加入扩容队伍帮助扩容，helpTransfer
5. 如果hash值匹配到的节点的hash值和value都和当前要put进去的值相等，并且设置了onlyIfAbsent为真，就直接返回当前存在的value值
6. 以上情况都不满足，则对当前节点加锁，执行put链表和红黑树逻辑，和hashmap差不多

|                  | 1.7     | 1.8                |
| ---------------- | ------- | ------------------ |
| 保证线程安全机制 | 分段锁  | cas + synchronized |
| 锁的粒度         | segment | 每个数组元素       |

## JVM

### 1. 什么是JVM内存结构

- **程序计数器**：程序计数器是一块很小的内存空间，用于存储字节码的指令地址，提供给执行引擎去取指执行。（线程私有，无内存溢出问题）
- **虚拟机栈**：描述java方法执行过程的内存模型，每个方法执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态连接、返回地址等信息，当线程请求的栈深度超过了虚拟机允许的最大深度时，就会抛出StackOverFlow的异常。（线程私有，描述java方法的执行过程）
- **本地方法栈**：本地方法区和虚拟机栈的作用类似，区别是虚拟机栈为执行 Java 方法服务，本地方法栈为 Native 方法服务。（线程私有）
- **堆**：在 JVM 运行过程中创建的对象和产生的数据都被存储在堆中，堆是被线程共享的内存区域，也是垃圾收集器进行垃圾回收的最主要的内存区域。（线程共享）
- **方法区**：jdk8以前方法区是由永久代实现的，存储类的元信息，常量池，静态变量等，jdk8以后，方法区由元空间实现，存储类的元信息等，常量池、静态变量存储在堆中（线程共享）

### 2. JVM内存分配与回收策略

1. 对象优先分配在Eden区。new出来的对象都放在堆内存里，JVM将堆分为新生代和老年代。新生代8/10是Eden区，1/10是ServivorFrom区，1/10是ServivorTo区。Eden区空间不足会发起一次minor GC。
2. 大对象直接进入老年代。JVM参数：-XX:PretenureSizeThreshold（只在Serial和ParNew两个收集器下有效）
3. 长期存活的对象将进入老年代。若Servivor区的对象经过一次GC存活下来，则其年龄加一，默认到15进入老年代。
4. Minor GC后存活的对象Survivor区放不下，则部分去老年代，部分放在Survivor区。
5. Eden、SurvivorFrom与SurvivorTo区默认比例8:1:1。如果Eden区满了，就进行minor GC，存活的对象放进Survivor区。
6. 对象动态年龄判断。如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。
7. 老年代空间分配担保机制。在MinorGC之前，判断老年代剩余可用空间是否小于年轻代里现有的所有对象大小之和，没有，就进行minorGC，如果是，就看是否配置担保参数：-xx:-HandlePromotionFailure，没有就直接FullGC，如果配置了，就判断老年代剩余可用空间是否小于之前每次minorGC后进入老年代的对象平均大小，否就进行minorGC，是就进行FullGC。

### 3. minor GC和Full GC有什么不同

1. minor GC/Young GC：指放生在新生代的垃圾收集动作。非常频繁，且速度很快
   - eden区满了，在new对象时，就会触发
   - eden和from存活对象移动到to，年龄+1
   - 将eden和from回收
   - 将原来的from和to名字交换
2. Major GC/Full GC：一般会回收老年代，年轻代，方法区的垃圾，速度很慢
   - 老年代满了，就会触发

### 4. 如何确定垃圾

- **引用计数法**：在为对象添加一个引用时，引用计数加 1；在为对象删除一个引用时，引进计数减 1；如果一个对象的引用计数为 0，则表示此刻该对象没有被引用，可以被回收。（循环引用问题）
- **可达性分析**：首先定义一些 GC Roots 对象（哪些可以作为GC Roots对象：栈帧本地变量表、方法区常量池、方法区静态属性、活跃线程引用对象、本地方法栈JNI对象），然后以这些 GC Roots 对象作为起点向下搜索，如果在 GC roots 和一个对象之间没有可达路径，则称该对象是不可达的。不可达对象要经过至少两次标记才能判定其是否可以被回收，如果在两次标记后该对象仍然是不可达的，则将被垃圾收集器回收。

### 5. java中常见的垃圾回收算法

1. **标记清除算法**：其过程分为标记和清除两个阶段。在标记阶段利用可达性遍历内存，标记所有需要回收的对象，在清除阶段清除可回收的对象并释放其所占用的内存空间。（有碎片）
2. **复制算法**：复制算法首先将内存划分为两块大小相等的内存区域，即区域 1 和区域 2，新生成的对象都被存放在区域 1 中，在区域 1 内的对象存储满后会对区域 1 进行一次标记，并将标记后仍然存活的对象全部复制到区域 2 中，这时区域 1 将不存在任何存活的对象，直接清理整个区域 1 的内存即可。（清理效率高，易实现，不适合有大量存活久的对象）
3. **标记整理算法**：在标记完成后将存活的对象移到内存的另一端，然后清除该端的对象并释放内存。（结合了标记清除算法和复制算法的优点）
4. **分代收集算法**：JVM将堆分为新生代和老年代。新生代8/10是Eden区，1/10是ServivorFrom区，1/10是ServivorTo区。新生代使用复制算法（新生代需要复制的对象少），进行垃圾回收时会将在 Eden 区和 ServivorFrom 区中存活的对象复制到 ServivorTo 区，然后清理 Eden 区和 ServivorFrom 区的内存空间。老年代使用标记清除算法或标记整理（老年代主要是生命周期长的对象和大对象）。还有一个区域，即方法区的永久代，永久代用来存储 Class 类、常量、方法描述等。在永久代主要回收废弃的常量和无用的类。新生代使用复制算法时，如果ServivorTo区空间不够，则直接进入老年区。若Servivor区的对象经过一次GC存活下来，则其年龄加一，默认到15进入老年代。还有对象动态年龄判断机制,如果form区年龄总和超过survivor区的50%，就进入老年代。

### 6. JVM垃圾收集器

- Serial：单线程收集器。新生代采用复制算法，老年代采用标记-整理算法。简单而高效
- Serial Old：单线程收集器。在JDK1.5及以前与Parallel Scavenge收集器搭配使用。或者作为CMS收集器的后备方案
- parNew收集器：Serial收集器的多线程版本。新生代采用复制算法，老年代采用标记-整理算法。默认线程数和cpu数相同。运行在Server模式下的虚拟机的首要选择。除了Serial收集器外，只有它能与CMS收集器配合工作
- Parallel Scavenge收集器：是Server模式下的默认收集器。新生代采用复制算法，老年代采用标记-整理算法。高效率的利用CPU。在优化比较困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机完成。
- Parllel Old收集器：使用多线程，标记-整理算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑Parallel Scavenge收集器和Parllel Old收集器。
- CMS收集器（老年代）：以获取最短回收停顿时间为目标的收集器。HotSpot虚拟机第一款真正意义上的并发收集器。标记-清除算法。优点：并发收集、低停顿。缺点：对CPU资源敏感，无法处理浮动垃圾，使用标记-清除算法，会有大量空间碎片。执行过程中的不确定性，会存在上一次垃圾回收还没执行完，然后垃圾回收又被触发的情况。过程：
  1. 初始标记：stop-the-world，仅仅标记GC Roots能直接关联到的对象，速度很快。
  2. 并发标记：从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但不需要停顿用户线程。
  3. 重新标记：stop-the-world，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。
  4. 并发清除：清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。
- G1收集器：
  1. G1垃圾收集器将整个JVM内存分为多个大小相等的region,年轻代和老年代逻辑分区 
  2. G1是Java9以后的默认垃圾回收器了
  3. G1在整体上使用标记整理算法，局部使用复制算法
  4. G1的每个Region大小在1-32M之间，可以通过-XX:G1HeapRegionSize=n指定区大小
  5. 总的Region个数最大可以存在2048个，即heap最大能够达到32M\*2048=64G
  6. 0.5<obj<1,那么放到old区，old标记为H
  7. 1<obj<n,连续的n个region,作为H
  8. G1 mixGC的过程
     - 初始标记：标记出GCRoot对象，以及GCRoot所在的Region(RootRegion)
     - Root Region Scanning:扫表整个old的Region
     - 并发标记：并发追溯标记，进行GCRootsTracing的过程
     - 最终标记：修正并发标记期间，因程序运行导致标记发生变化的那一部分对象
     - 清理回收：根据时间来进行价值最大化的回收，重置rset

### 7. java中的引用类型

1. 强引用：在 Java 中最常见的就是强引用。在把一个对象赋给一个引用变量时，这个引用变量就是一个强引用。有强引用的对象一定为可达性状态，所以不会被垃圾回收机制回收。因此，强引用是造成 Java 内存泄漏（Memory Link）的主要原因。
2. 软引用：软引用通过 SoftReference 类实现。如果一个对象只有软引用，则在系统内存空间不足时该对象将被回收。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。
3. 弱引用：弱引用通过 WeakReference 类实现，并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系，如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择。
4. 虚引用(幻象引用)：虚引用通过 PhantomReference 类实现，你不能通过它访问对象。虚引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制，比如，通常用来做所谓的 Post-Mortem 清理机制，java平台自身Cleaner机制等。也有人利用虚引用监控对象的创建和销毁。

### 8. JVM的类加载机制

1. 加载：读取Class文件，将其转化为某种静态数据结构存储在方法区内，并在堆中生成一个便于用户调用的java.lang.Class类型的对象
2. 验证：(元数据、字节码验证)对Class静态结构进行语法和语义分析，保证其不会产生危害虚拟机的行为
3. 准备：主要工作是在方法区中为类变量分配内存空间并设置类中静态变量的默认值。初始值指不同数据类型的默认值，这里需要注意 final 类型的变量（给的值）和非 final 类型的变量（默认值）在准备阶段的数据初始化过程不同。
4. 解析：符号引用替换为直接引用。(A引用了B，在编译阶段，A不知道B有没有编译，B此时也没有被加载，A不知道B的实际地址，所以用一个字符串S来代表B的地址，S就是符号引用。在运行时，如果A发生了类加载，到解析阶段，发现B还未加载，就会触发B的类加载，将B加载到虚拟机中，此时A中B的符号引用将会被替换成B的实际地址，这就是直接引用。如果A调用B是一个具体的实现类，那么就称为静态解析，而如果使用了多态，B可能是一个抽象类或者接口，B可能有两个具体的实现类C和D，这个时候不会替换，等到运行过程中发生了调用，此时虚拟机调用栈中将会得到具体的类型信息，这时再进行解析。这也是为啥有时候解析会发生在初始化之后，这就是动态解析)
5. 初始化：会判断代码中是否存在主动的资源初始化操作。比如成员变量的赋值动作，静态变量的赋值动作，以及静态代码块的逻辑。只有显式的调用new，才会调用构造函数，进行对象的实例化。

### 9. 什么情况下JVM不会执行类的初始化流程 

- 常量在编译时会将其常量值存入使用该常量的类的常量池中，该过程不需要调用常量所在的类，因此不会触发该常量类的初始化
- 在子类引用父类的静态字段时，不会触发子类的初始化，只会触发父类的初始化
- 定义对象数组，不会触发该类的初始化
- 在使用类名获取 Class 对象时不会触发类的初始化
- 在使用 Class.forName 加载指定的类时，可以通过 initialize 参数设置是否需要对类进行初始化
- 在使用 ClassLoader 默认的 loadClass 方法加载类时不会触发该类的初始化。

### 10. JVM的类加载器

- 启动类加载器：负责加载 Java_HOME/lib 目录中的类库，或通过-Xbootclasspath 参数指定路径中被虚拟机认可的类库
- 扩展类加载器：负责加载 Java_HOME/lib/ext 目录中的类库，或通过 java.ext.dirs 系统变量加载指定路径中的类库
- 应用程序类加载器：负责加载用户路径（classpath）上的类库。
- 除了上述 3 种类加载器，我们也可以通过继承 java.lang.ClassLoader 实现自定义的类加载器。

### 11. 双亲委派机制

- 双亲委派机制指一个类在收到类加载请求后不会尝试自己加载这个类，而是把该类加载请求向上委派给其父类去完成，其父类在接收到该类加载请求后又会将其委派给自己的父类，以此类推，这样所有的类加载请求都被向上委派到启动类加载器中。若父类加载器在接收到类加载请求后发现自己也无法加载该类（通常原因是该类的 Class 文件在父类的类加载路径中不存在），则父类会将该信息反馈给子类并向下委派子类加载器加载该类，直到该类被成功加载，若找不到该类，则 JVM 会抛出 ClassNotFoud 异常。

### 12. 创建出来的对象放在哪儿

- 大部分放在堆里面
- 没有方法逃逸的对象，直接栈上分配
- 没有线程逃逸，可以进行syn擦除，同步擦除策略
- 标量替换优化，替换的聚合量

### 13. 对象空间的内存分配

- 指针碰撞法。使用过的空间在一边，空闲的在另一边，中间是指针。该方法适用于GC后没有碎片。
- 空闲列表。维护一个列表记录哪些内存块可用。分配时，从列表找一个足够大的空间划分给对象实例，并更新列表上的记录。
- 解决线程安全：
  - 一种是对分配内存空间的动作进行同步处理，实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性。
  - 另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在java堆中预先分配一小块内存，称为本地线程分配缓冲

## Java多线程

### 1. java如何开启线程

1. 继承Thread类、重写run()方法
2. 实现Runnable接口，实现run()方法
3. 实现Callable接口，实现call()方法，通过FutureTask创建一个线程，可以获得返回值
4. 创建线程池

### 2. 说说ThreadLocal

ThreadLocal 的实现依赖于 Java 的线程模型，具体来说是基于每个线程的 `Thread` 对象中的 `threadLocals` 属性。这个属性是一个 `ThreadLocalMap` 类型的哈希表，用来存储线程本地变量。当我们在某个线程中调用 `ThreadLocal` 的 `set()` 方法时，实际上是将当前线程作为 key，变量值作为 value 存储到该线程的 `threadLocals` 哈希表中。而调用 `get()` 方法时，则是从当前线程的 `threadLocals` 中取出对应的值。

注意：

- key是强引用，需要手动回收，不然会内存泄漏
- 哈希冲突的解决使用线性探测法，依次往后找

场景：

分布式链路追踪系统，每个请求都传递traceId，使用treadLocal存traceId

### 3. Volatile关键字作用

- 内存可见性：所有线程都能看到共享内存的最新状态
- 防止指令重排：在new一个对象时，会执行分配内存，初始化对象，然后这个变量指向内存。如果发生指令重排，执行顺序是132，执行到第3的时候，线程B刚好进来了，并且执行到注释2，这时候判断mInstance 不为空，直接使用一个未初始化的对象。

### 3. Volatile和Synchronized有什么区别

- synchronized通过加锁的方式，可以在需要原子性、可见性和有序性这三种特性的时候都可以作为其中一种解决方案
- volatile通过在volatile变量的操作前后插入内存屏障的方式，保证了变量在并发场景下的可见性和有序性
- volatile关键字是无法保证原子性的，而synchronized通过monitorenter和monitorexit两个指令，可以保证被synchronized修饰的代码在同一时间只能被一个线程访问，即可保证不会出现CPU时间片在多个线程间切换，即可保证原子性
- volatile是Java虚拟机提供的一种轻量级同步机制，不是锁。而Synchronized会有阻塞和性能损耗的问题
- Volatile能防止指令重排

### 4. 对AQS的理解。AQS如何实现可重入锁

- AQS的成员属性：

  - state：资源是否被占用的标记位，volatile保证线程可见性，int，可以在共享模式下由多个线程占用
  - head、tail：头尾节点，封装的一个内部类Node(prev、next、waiter、status)，未拿到资源的线程排队的双向链表

- AQS的核心方法：

  - protected boolean tryAcquire(int arg)：被protect修饰，参数是int，代表对state的修改，返回是boolean，代表是否成功获得锁。该方法只有一行，就是抛出异常。很明显要继承AQS重写这个方法。比如：

    ```java
    class Syncer extends AbstractQueuedSynchronizer {
    	@Override
    	protected boolean tryAcquire(int arg) {
    		if (arg != 1) {
    			return false;
    		}
    		if (getState() == 1) {
    			return false;
    		}
    		return compareAndSetState(0, 1);
    	}
    }
    ```

  - public final void acquire(int arg) ：不允许重写，调用之后一定获得锁。先调用tryAcquire，如果不行就调用acquire的重载方法。然后进行尝试获取锁，入队，修改status等操作。acquireQueued这个方法，如果当前线程所在节点处于头节点后面一个，就会不断尝试拿锁，直到成功。如果不是头节点，则判断是不是需要挂起，如果之前节点不是头节点并且状态是singal，则需要挂起。

  - protected boolean tryRelease(int arg) ：和tryAcquire差不多，需要重写

  - public final boolean release(int arg)：尝试释放成功，就要唤醒等待队列的其他节点。先把自己设置为head，然后从尾到头找第一个head，然后去自旋拿锁。

### 5. A、B、C三个线程，如何保证三个线程同时执行？如何在并发情况下保证三个线程依次执行？如何保证三个线程有序交错进行？

- 同时执行：使用CountDownLatch类，初始化时为1。让这三个线程都await()，然后主线程里调用countDown()，三个线程就同时进行了
- 依次执行：volatile修饰一个变量，每个线程都要判断，做完任务之后，修改这个变量，让下一个线程满足条件
- 有序交错执行：定义一个信号量int number；然后private Lock lock = new ReentrantLock();然后private Condition conditionA = lock.newCondition();。。。线程里执行的时候就是lock.lock(); while(numer!=0){conditionA.await();}改变信号量，唤醒下一个线程conditionB.signal();最后lock.unlock()

### 6. 说说几种常见的线程池及使用场景

- newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行
- newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待
- newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程
- newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行

### 7. 线程池的参数

- corePoolSize：核心池的大小
- maximumPoolSize：线程池最大线程数
- keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止
- unit：参数keepAliveTime的时间单位
- workQueue：一个阻塞队列，用来存储等待执行的任务
- threadFactory：用于设置创建线程的工厂
- handler：表示当拒绝处理任务时的策略，有以下四种取值：1、AbortPolicy：直接抛出异常。2、CallerRunsPolicy：只用调用者所在线程来运行任务。3、DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。4、DiscardPolicy：不处理，丢弃掉。

### 8. CAS实现原子性操作

CAS包含三个操作数：内存位置V、预期值A和新值B。它的核心逻辑是：如果内存位置V的值等于预期值A，那么就将内存位置V的值更新为新值B，否则不做任何操作。整个过程是原子性的，由CPU指令保证。

### 9. CAS中的ABA问题

- ABA问题指的是多个线程同时执行,那么开始时其获得的值都是A,当一个线程修改了A为B,第二个线程修改了B为A,那么第三个线程修改时判断A仍然是A,认为其没有修改过,因此会CAS成功

- 在JDK1.5之后提供了`AtomicStampedReference`类来解决ABA问题,解决思路是保存元素的引用,引用相当于版本号,是每一个变量的标识,因此在CAS前判断下是否是同一个引用即可

### 10. CAS应用题。三个线程将一个值累加到100。

```java
// 1.错误写法
public class Main {
    static Integer num = 0;
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++) {
            new Thread(() -> {
                while (num < 1000) {
                    System.out.println("thread name:" + Thread.currentThread().getName() + ":" + num++);
                }
            }).start();
        }
    }
}

// 2.原子类
public class Main {
    static AtomicInteger num = new AtomicInteger(0);
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++) {
            new Thread(() -> {
                while (num.get() < 1000) {
                    System.out.println("thread name:" + Thread.currentThread().getName() + ":" + num.incrementAndGet());
                }
            }).start();
        }
    }
}
```

### 11. synchronized与ReentrantLock的区别

- 底层实现上来说，synchronized 是JVM层面的锁，是Java关键字，通过monitor对象来完成（monitorenter与monitorexit），对象只有在同步块或同步方法中才能调用wait/notify方法，ReentrantLock 是从jdk1.5以来（java.util.concurrent.locks.Lock）提供的API层面的锁
- synchronized 不需要用户去手动释放锁，ReentrantLock则需要用户去手动释放锁
- synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成； ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断
- synchronized为非公平锁 ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁
- synchronized不能绑定； ReentrantLock通过绑定Condition结合await()/singal()方法实现线程的精确唤醒
- synchronized锁的是对象，锁是保存在对象头里面的，根据对象头数据来标识是否有线程获得锁/争抢锁；ReentrantLock锁的是线程，根据进入的线程和int类型的state标识锁的获得/争抢
- synchronized的阻塞队列是头插法，ReentrantLock的是尾插法

### 12. 并发操作三大特性

1. 原子性：一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行
2. 可见性：是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存上，volatile 就是负责保证可见性的。
3. 有序性：保证线程内串行语义，避免指令重排等。

### 13. Java的对象结构

- 对象头：Mark Word(和运行时状态有关的数据)、Class Point(指向当前对象类型所在方法区中的类型数据)
- 实例数据：初始化对象时，设置的属性，方法等
- 填充字节：保证对象大小是8bit的倍数

### 14. synchronized 底层如何实现？Java的锁机制

synchronized 代码块是由一对儿 monitorenter/monitorexit 指令实现的，Monitor 对象是同步的基本实现单元。在 Java 6 之前，Monitor 的实现完全是依靠操作系统内部的互斥量（Mutex Lock），因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量级操作。现代的（Oracle）JDK 中，JVM 对此进行了大刀阔斧地改进，提供了三种不同的锁：偏斜锁（Biased Locking）、轻量级锁和重量级锁，大大改进了其性能。

- 四种状态：无锁、偏向锁(1.6引入)、轻量级锁(1.6引入)、重量级锁。
- 锁只能升级，不能降级(99%的情况)
- 无锁：无竞争，或者存在竞争，用非锁方式同步线程(CAS)
- 简单概括升级过程：当一把锁第一次被线程持有的时候是偏向锁，如果这个线程再次加锁还是偏向锁。如果别的线程来加锁(交替执行)膨胀为轻量锁，如果是资源竞争膨胀为重量锁
- 偏向锁：对象头里锁标志位是01，且前一位是1，就是偏向锁。然后再去读对象头前23bit，线程ID，通过线程ID来确认当前想要获得对象锁的这个线程。如果发现有多个线程在竞争，那么就会升级会轻量级锁
- 轻量级锁：锁标志位是00。当一个线程想要获得某个对象的锁时，如果是轻量级锁，线程会在自己的虚拟机栈中开辟一块被称为Lock Record的空间(存放对象头Mark Word的副本，以及owner指针)，线程通过CAS尝试获取锁，一旦获得，会复制对象头中的Mark Word，并且owner指针指向该对象。对象头中的前30bit会生成一个指针，指向Lock Record。其他线程再来，就会自旋（不断的CAS获取锁）。如果自旋很多次或多个线程竞争，就会升级为重量级锁。
- 重量级锁：锁标志位是10。前面的位是一个地址，指向C++里面的一个对象ObjectMonitor。通过Monitor来管理资源。首先Entry Set有一些想进入Monitor的线程，处于Waiting状态。某一个线程A进入后，会处于Active状态，假设该线程执行时，遇到一个判断条件，需要它让出执行权，它将进入Wait Set，状态变为Waiting。此时Entry Set里的线程就有机会进入Monitor。假设线程B进入完成任务，可以通过notify的形式唤醒Wait Set中的线程A，让A进入Monitor继续执行任务，执行完后便可以退出。(synchronized同步机制)

### 15. 讲一下悲观锁和乐观锁

- 悲观锁：操作系统会悲观的认为，如果不严格同步线程调用，那么一定会产生异常，所以用互斥锁将资源锁定，只供一个线程调用，而阻塞其他线程。
- 乐观锁：由CAS来实现同步的工具，由于不会锁定资源，而且当线程需要修改共享资源的对象时，总是会乐观的认为，对象状态值没有被其他线程修改过，而是每次自己都会主动尝试去compare状态值。(其实是使用了无锁机制)

### 16. 用synchronized实现一个读写锁

```java
public class ReadWriteLock {
    private int readCount = 0;
    private int writeCount = 0;

    /**
     * 读锁
     */
    public synchronized void lockRead() throws InterruptedException {
        while (writeCount > 0) {
            wait();
        }
        readCount++;
    }

    /**
     * 释放读锁
     */
    public synchronized void unlockRead() {
        readCount--;
        notifyAll();
    }

    /**
     * 写锁
     */
    public synchronized void lockWrite() throws InterruptedException {
        while (writeCount > 0) {
            wait();
        }

        writeCount++;

        // 读锁为0时获取写锁
        while (readCount > 0) {
            wait();
        }
    }

    /**
     * 释放写锁
     */
    public synchronized void unlockWrite() {
        writeCount--;
        notifyAll();
    }
}
```

### 17. 非公平锁和公平锁

- 公平锁:按照请求锁的顺序分配，拥有稳定获得锁的机会，但是性能可能比非公平锁低
- 非公平锁：不按照请求的顺序分配，不一定拥有获得锁的机会，但是性能可能比公平锁高(后申请的线程，可能在前面休眠线程恢复前拿到锁，这样就可能提高并发的性能，这是因为，通常情况，唤醒一个挂起的线程，线程切换之间产生短暂延时，非公平锁就能利用这段时间来完成操作)

### 18. 说说ReentrantLock

- 一个成员变量Sync，这是一个内部类。它继承了AQS。核心方法就是nonfairTryAcquire和tryRelease等
- 在new一个ReentrantLock时，默认会sync = new NonfairSync();也就是非公平锁。这里面就重写了lock和tryAcquire两个方法。lock一上来就是CAS操作获取锁，不管前面有没有在等待，这里就体现它的非公平。但是只有一次机会，没成功就调用acquire方法(先tryAcquire，失败进入FIFO队列)。tryAquire方法就是直接调用父类的nonfairTryAcquire
- 在new一个ReentrantLock时，传入参数为true，就new一个公平锁fairSync。它也是重写了lock和tryAcquire两个方法。lock直接调用了父类AQS的acquire方法。tryAquire，如果锁空闲，且FIFO队列种没有排在当前线程之前的线程，就允许当前线程直接获取锁，获取失败返回false，然后在acquire方法种进入排队。如果锁不是空闲的，为了满足可重入，这里也进行一些判断，如果当前线程也不是持有锁的独占线程，也返回false。如果当前线程已经获取锁，对state进行累加，可以继续使用。
- 内部写好了，本身的方法直接调用内部类的方法就行。

### 19. 一个线程两次调用 start() 方法会出现什么情况？谈谈线程的生命周期和状态转移。

Java 的线程是不允许启动两次的，第二次调用必然会抛出 IllegalThreadStateException，这是一种运行时异常，多次调用 start 被认为是编程错误。

线程生命周期的不同状态，在 Java 5 以后，线程状态被明确定义在其公共内部枚举类型 java.lang.Thread.State 中

- 新建（NEW），表示线程被创建出来还没真正启动的状态，可以认为它是个 Java 内部状态。

- 就绪（RUNNABLE），表示该线程已经在 JVM 中执行，当然由于执行需要计算资源，它可能是正在运行，也可能还在等待系统分配给它 CPU 片段，在就绪队列里面排队。在其他一些分析中，会额外区分一种状态 RUNNING，但是从 Java API 的角度，并不能表示出来。

- 阻塞（BLOCKED），这个状态和我们前面两讲介绍的同步非常相关，阻塞表示线程在等待 Monitor lock。比如，线程试图通过 synchronized 去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。

- 等待（WAITING），表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待（wait），另外的生产者线程去准备任务数据，然后通过类似 notify 等动作，通知消费线程可以继续工作了。Thread.join() 也会令线程进入等待状态。

- 计时等待（TIMED_WAIT），其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如 wait 或 join 等方法的指定超时版本，如下面示例：

  ```java
  public final native void wait(long timeout) throws InterruptedException;
  ```

- 终止（TERMINATED），不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫作死亡。

### 20. 三个线程交替打印0-100

```java
// 使用synchronized来解决
public class Test1 {
    // 锁
    private static final Object LOCK = new Object();

    // 线程数量
    private static final int THREAD_COUNT = 3;

    // 开始
    private static volatile int start = 0;

    // 结束
    private static final int END = 100;

    private static class Print implements Runnable {

        private final int index;

        private Print(int index) {
            this.index = index;
        }

        @Override
        public void run() {
            while (start < END) {
                synchronized (LOCK) {
                    while (start % THREAD_COUNT != index) {
                        try {
                            LOCK.wait();
                        } catch (InterruptedException e) {
                            throw new RuntimeException(e);
                        }
                    }

                    if (start <= END) {
                        System.out.println(String.format("线程%s 打印结果：%s", index + 1, start));
                    }

                    start++;

                    LOCK.notifyAll();
                }
            }
        }
    }

    public static void main(String[] args) {
        for (int i = 0; i < THREAD_COUNT; i++) {
            new Thread(new Print(i)).start();
        }
    }
}

// 使用ReentrantLock配合CONDITION使用
public class Test1 {
    private static final ReentrantLock LOCK = new ReentrantLock();

    private static final Condition CONDITION = LOCK.newCondition();

    private static final int THREAD_COUNT = 3;

    private static volatile int start = 0;

    private static final int END = 100;

    private static class Print implements Runnable {

        private final int index;

        private Print(int index) {
            this.index = index;
        }

        @Override
        public void run() {
            while (start < END) {
                LOCK.lock();
                try {
                    while (start % THREAD_COUNT != index) {
                        CONDITION.await();
                    }

                    if (start <= END) {
                        System.out.printf("线程%s 打印结果：%s%n", index + 1, start);
                    }

                    start++;

                    CONDITION.signalAll();
                } catch (InterruptedException e) {
                    throw new RuntimeException(e);
                } finally {
                    LOCK.unlock();
                }
            }
        }
    }

    public static void main(String[] args) {
        for (int i = 0; i < THREAD_COUNT; i++) {
            new Thread(new Print(i)).start();
        }
    }
}
```

## Netty

Netty 是一个被广泛使用的，基于NIO的 Java 网络应用编程框架

### 1. Netty的线程模型

![](/images/Netty线程模型.jpg)

- Netty 抽象出两组线程池：BossGroup、WorkerGroup
  - BossGroup 专门负责接收客户端连接
  - WorkerGroup 专门负责网络读写操作
  - BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup，相当于一个事件循环组
- NioEventLoopGroup 可以有多个线程，即含有多个NioEventLoop
- NioEventLoop 表示一个不断循环的执行处理任务的线程
  - 每个 NioEventLoop 中包含有一个 Selector，一个 taskQueue
    - Selector 上可以注册监听多个 NioChannel，也就是监听Socket网络通信
    - 每个 NioChannel 只会绑定在唯一的 NioEventLoop 上
    - 每个 NioChannel 都绑定有一个自己的 ChannelPipeline
  - NioEventLoop 内部采用串行化（Pipeline）设计：责任链模式
    - 消息读取 ==> 解码 ==> 处理（handlers） ==> 编码 ==> 发送，始终由IO线程NioEventLoop 负责

### 2. 一个Client连接的执行流程

1. Boss的NioEventLoop 循环执行步骤：
   1. 轮询 accept 事件
   2. 处理 accept 事件：与client建立连接，生成NioSocketChannel ，并将其注册到某个worker的NIOEventLoop的 selector
   3. 处理任务队列的任务 ， 即 runTasks
2. Worker的NIOEventLoop 循环执行步骤：
   1. 轮询read、write 事件
   2. 在对应NioSocketChannel中，处理业务相关操作（ChannelHandler）
   3. 处理任务队列的任务，即 runTasks
3. 每个Worker的NioEventLoop 处理业务时会使用管道Pipeline。Pipeline中包含了 Channel，通过
    管道可以获取到对应Channel，Channel 中维护了很多的Handler处理器。

### 3. 核心API

1. ServerBootstrap 和 Bootstrap

   - ServerBootstrap 是 Netty 中的服务端启动助手，通过它可以完成服务端的各种配置；
     - ServerBootstrap group(parentGroup , childGroup)， 该方法用于设置两个
       EventLoopGroup，连接线程组和工作线程组
     - public B channel(Class<? extends C> channelClass)，该方法用来设置服务端或客户端通道
       的实现类型
     - public B option(ChannelOption option, T value)，用来给 ServerChannel 添加配置
     - public ServerBootstrap childOption(ChannelOption childOption, T value)，用来给接收
       通道添加配置
     - public ServerBootstrap childHandler(ChannelHandler childHandler)，该方法用来设置业
       务处理类（自定义handler）
     - public ChannelFuture bind(int inetPort) ，该方法用于设置占用端口号

   - Bootstrap 是 Netty 中的客户端启动助手，通过它可以完成客户端的各种配置。
     - public B group(EventLoopGroup group) ，该方法用来设置客户端的 EventLoopGroup
     - public B channel(Class<? extends C> channelClass)，该方法用来设置服务端或客户端通道
       的实现类型
     - public ChannelFuture connect(String inetHost, int inetPort) ，该方法用来配置连接服务端
       地址信息，host:port

2. EventLoopGroup（Boss\Worker Group）

   1. 在 Netty 服务端编程中，一般需要提供两个 EventLoopGroup： ①BossEventLoopGroup专门负责接
      收客户端连接、②WorkerEventLoopGroup专门负责网络读写操作。
      - Netty 为了更好的利用多核 CPU 资源，一般会有多个 EventLoop 同时工作，每个 EventLoop 维护
        着一个 Selector 实例。
      - EventLoopGroup 提供 next 接口，可以从组里面按照一定规则获取其中一个 EventLoop 来处理任
        务。
      - EventLoopGroup 本质是一组 EventLoop，池化管理的思想
   2. 通常一个服务端口即一个ServerSocketChannel 对应一个Selector 和一个EventLoop 线程，
      BossEventLoop 负责接收客户端的连接并将 SocketChannel 交给 WorkerEventLoopGroup 来进行 IO
      处理。
      - BossEventLoopGroup 通常是单线程的 EventLoop，EventLoop 维护着一个注册了
        ServerSocketChannel 的 Selector 实例
      - Boss的EventLoop 不断轮询 Selector 将连接事件分离出来，通常是 OP_ACCEPT 事件， 然后将接
        收到的 SocketChannel 交给 WorkerEventLoopGroup
      - WorkerEventLoopGroup 会由 next 选择其中一个 EventLoop 来将这个 SocketChannel 注册到其
        维护的 Selector 并对其后续的事件进行处理。
   3. ChannelHandler
      1. 我们经常需要自定义一个 Handler 类去继承 ChannelInboundHandlerAdapter，然后通过重写相应方法实现业务逻辑，一般都需要重写哪些方法：
         - channelActive(ChannelHandlerContext ctx)，通道就绪事件
         - channelRead(ChannelHandlerContext ctx, Object msg)，通道读取数据事件
         - channelReadComplete(ChannelHandlerContext ctx) ，数据读取完毕事件
         - exceptionCaught(ChannelHandlerContext ctx, Throwable cause)，通道发生异常事件
   4. ChannelPipeline
      1. ChannelPipeline是一个 Handler 的集合，它负责处理和拦截 inbound 或者 outbound 的事件和操
         作，相当于一个贯穿 Netty 的链（责任链模式）。ChannelHandler不知道彼此。所以要用ChannelHandlerContext上下文来说明，ChannelHandlerContext包含ChannelHandler、Channel、pipeline的信息。
      2. 常用接口：
         1. ChannelPipeline addFirst(ChannelHandler... handlers)，把业务处理类（handler）添加到
            Pipeline链中的第一个位置
         2. ChannelPipeline addLast(ChannelHandler... handlers)，把业务处理类（handler）添加到
            Pipeline链中的最后一个位置
   5. ChannelHandlerContext
      - ChannelHandlerContext是事件处理器上下文对象， Pipeline链中的实际处理节点。 每个处理节点ChannelHandlerContext 中包含一个具体的事件处理器 ChannelHandler ， 同时ChannelHandlerContext 中也绑定了对应的 Pipeline 和 Channel 的信息，方便对 ChannelHandler进行调用。
      - 常用方法：
        - ChannelFuture close()，关闭通道
        - ChannelOutboundInvoker flush()，刷新
        - ChannelFuture writeAndFlush(Object msg) ，将数据写到ChannelPipeline中当前ChannelHandler 的下一个 ChannelHandler 开始处理（出栈交给下一个handler将继续处理）。
   6. ChannelOption
      1. Netty 在创建 Channel 实例后，一般都需要设置 ChannelOption 参数。ChannelOption 是Socket 的标准化参数而非 Netty 的独创。
      2. 常用参数：
         1. ChannelOption.SO_BACKLOG：用来初始化服务器可连接队列大小，对应 TCP/IP 协议 listen 函数中的 backlog 参数。
            - 服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接。
            - 如果请求连接过多，服务端将不能及时处理，多余连接放在队列中等待，backlog 参数指定了等待队列大小。
         2. ChannelOption.SO_KEEPALIVE ，连接是否一直保持（是否长连接）。
   7. ChannelFuture
      1. ChannelFuture表示 Channel 中异步 IO 操作的未来结果，在 Netty 中异步IO操作都是直接返回，调用者并不能立刻获得结果，但是可以通过 ChannelFuture 来获取 IO 操作的处理状态。Netty异步非阻塞处理事件，如果事件很费时，会通过Future异步处理，不会阻塞。
      2. 常用方法：
         - Channel channel()，返回当前正在进行IO操作的通道
         - ChannelFuture sync()，等待异步操作执行完毕
   8. Unpooled
      - Unpooled 是 Netty 提供的一个专门用来操作缓冲区的工具类
      - 常用方法：
        - ByteBuf copiedBuffer(CharSequence string, Charset charset)，通过给定的数据和字符编码返回一个 ByteBuf 对象（类似于 NIO 中的 ByteBuffer 对象）



## 消息队列-kafka

### 1. kafka的架构是怎样的

- 生产者
  - 发消息到指定topic，支持异步、同步
- Topic & 分区
  - Topic逻辑分类，物理拆分为多个有序不可变分区，实现并行处理。
  - 分区内消息通过Offset唯一标识，保证顺序性。
  - Leader-Follower副本机制：Leader处理读写，Follower异步/同步复制（ISR机制），保障高可用。
- Broker集群
  - 每个Broker是独立服务节点，存储多个分区副本。
- 消费者组（Consumer Group）
  - 组内消费者竞争消费不同分区（1分区仅由1消费者消费），实现横向扩展。
  - 通过Offset提交机制记录消费进度（保存至内部Topic `__consumer_offsets`）。
- ZooKeeper/KRaft
  - 传统架构依赖ZooKeeper管理元数据、Controller选举。
  - Kafka 3.0+逐步用KRaft（Raft协议）替代ZooKeeper，实现自洽元数据管理。

### 2. 生产者发送数据流程

1. 发送前拦截
   1. 经过一系列拦截器，可实现ProducerInterceptor接口的onSend方法加入自己的拦截器
2. 核心发送方法
   - 获取元数据：waitOnMetadata
   - 序列化器：keySerializer.serialize、valueSerializer.serialize
   - 分区器：int partition = partition(record, serializedKey, serializedValue, cluster)
     - 可在调用发送方法时直接指定给哪个分区
     - 可实现Partitioner接口，然后配置上分区算法类props.put("partitioner.class", "com.your.package.CustomPartitioner");
   - 将数据放入到RecordAccumulator：accumulator.append
     - RecordAccumulator对象里的关键字段ConcurrentMap<TopicPartition, Deque<ProducerBatch>> batches;
     - 这么设计是因为来一个发送一个浪费性能，所以来一批发送一批，可以配置一批数据的大小为多少
3. Sender线程循环取数据并发送
   1. 从RecordAccumulato中拿数据封装成ProduceRequest
   2. 将ProduceRequest放入在途请求缓冲区，大小为5
   3. 网络客户端从缓冲区拿出请求进行发送
4. 发送完成后
   1. 处理响应
   2. 触发拦截器，实现ProducerInterceptor接口其中的onAcknowledgement方法
   3. 触发用户设置的回调

### 3. 生产者发送数据ack机制

org.apache.kafka.clients.producer.ProducerConfig#ACKS_CONFIG

- acks = 0：异步形式，单向发送，不会等待 broker 的响应
- acks = 1：leader写入本地日志（LEO更新），但是HW可能未推进
- acks = all 或 -1：等待 Leader 将消息写入本地日志，并确保所有 ISR 副本的 LEO ≥ Leader 的 HW。此时 HW 会推进，消息对消费者可见。

如果设置了acks=all，那么消息一定不会丢失，但是可能会出现重复消息（解决办法：消费者有幂等性控制机制）。

LEO（Log End Offset）：当前日志中最后一条消息的偏移量（即下一条待写入消息的位置）

HW（High Watermark）：消费者可见的最大消息偏移量（即 HW 之前的所有消息均已同步到 ISR 中的所有副本）

### 4. 服务端Broker的消息处理架构模型

请求进来后，由网络线程池（大小可配置，默认为3）接收，然后放入到共享的请求队列，然后IO线程池（大小可配置，默认为8）来进行业务处理，处理完成的结果给到网络线程池，网络线程池发送响应

![](images\kafka-broker.png)

### 5. 服务端Broker消息存储的文件布局

1. kafka存储的整体架构
   - 日志目录：每个broker存储的日志目录
   - 分区目录：每个分区都有自己独立的目录（例如：topic_0）
   - 日志分段：每个分区的日志被分割为多个分段文件（Segment），每个分段是一个独立的文件集合。
     - {起始偏移量}.log：存储消息的二进制数据，按顺序追加写入，默认最大1G（配置项：log.segment.bytes），达到最大值时会生成新的.log文件
       - offset:8 bytes（消息偏移量）
       - message_size:4 bytes（消息体大小）
       - CRC:4 bytes（校验码）
       - magic_byte:1 byte（消息格式版本）
       - attributes:2 bytes（消息属性，如压缩、时间戳等）
       - timestamp:8 bytes（消息时间戳）
       - key:可变长度（可选）
       - value:可变长度（消息体）
       - headers:可变长度（可选）
     - {起始偏移量}.index：存储偏移量到文件位置（offset → position）的映射。索引每隔 4KB 的消息数据记录一条（配置：index.interval.bytes 默认4096），查询算法：二分查找
       - offset:8 bytes：（消息偏移量）
       - position:4 bytes：（消息在 .log 文件中的起始位置）
     - {起始偏移量}.timeindex：存储时间戳到偏移量（timestamp → offset）的映射。支持基于时间范围的查询
       - timestamp:8 bytes（消息时间戳）
       - offset:4 bytes（对应的消息偏移量）
2. 日志分段（log segment）的生命周期
   1. 分段的创建
      - 当前 .log 文件大小达到 log.segment.bytes（默认 1GB）。
      - 或者时间间隔达到 log.roll.ms（默认 1天）。
   2. 分段的清理
      - 当消息的创建时间超过 log.retention.hours（默认 7天），则删除过期的分段。
      - 通过日志清理器（Log Cleaner）定期合并分段，保留最新版本的消息（基于key去重）。
   3. 分段的删除
      - 分段被标记为可删除后，需等待 log.segment.delete.delay.ms（默认 60秒）才能物理删除。
      - 删除前会检查是否有副本正在同步（避免数据丢失）。

### 6. kafka的消费者

1. 消费者基础模型
   1. 消费者组（consumer group）
      - 逻辑单元：一组协同工作的消费者实例，共同消费一个或多个主题
      - 分区分配：组内每个消费者独占消费一个或多个分区，实现负载均衡
      - 伸缩性：组内消费者数量可动态增减，触发分区再分配（Rebalance）
   2. 订阅模式
      - 组订阅（group subscribe）：消费者组共同消费主题，每条消息仅被组内一个消费者处理
      - 独立消费者（Standalone Consumer）：直接指定分区消费，无组协调，适用于特殊场景（如灾备）
   3. 消费位移
      - 消费者定期将已处理消息的偏移量提交到__consumer_offsets主题
2. 消费者工作流程
   1. 初始化和订阅
      - 创建消费者实例：配置bootstrap.servers、group.id等参数
      - 订阅：调用subscribe()，支持正则匹配主题
   2. 加入消费者组
      - 协调器（Coordinator）选择：计算 group.id 的哈希值，选择对应的 Broker 作为组协调器。
      - 组注册：消费者向协调器发送JoinGroup请求，协调器分配成员id并选举组领导者
        - 如果有新的消费者加入这个组，协调器会将组内之前所有消费者踢出组，然后所有消费者都发joinGroup请求。
      - 分区分配：组领导者执行分配策略，通过syncGroup请求将分配结果同步给所有成员
   3. 消息拉取并处理
      - 会不停的发送Fetch请求，拉取数据
      - 还会发送heartBeat心跳请求
   4. 位移提交
      - 自动提交：由 enable.auto.commit=true 控制，后台线程定期提交。
      - 手动提交
        - 同步提交：commitSync()
        - 异步提交：commitAsync()
3. 消费者协调与再平衡（Rebalance）
   1. 触发条件
      - 消费者增减：新加入消费者或者现有消费者宕机
      - 主题分区数变化
      - 会话超时：消费者未在session.timeout.ms内发送心跳
   2. 再平衡流程
      1. 所有消费者停止消费，进入REBALANCE状态
      2. 给组领导者重新分配分区，更新元数据
      3. 消费者收到新分配方案，重置位移并恢复消费
   3. 再平衡优化
      - 增量再平衡（Incremental Rebalance）：仅调整受影响的分区，减少停顿时间。
      - 静态成员（Static Membership）：通过 `group.instance.id` 避免临时离线触发再平衡。
4. 容错与一致性保障
   1. 位移提交策略
      - 至少一次（At-Least-Once）：先处理消息再提交位移，可能重复消费。
      - 至多一次（At-Most-Once）：先提交位移再处理消息，可能丢失消息。
      - 精确一次（Exactly-Once）：结合 Kafka 事务与幂等生产者，确保端到端一致性。
   2. 消费者故障恢复
      - 位移恢复：新消费者从 `__consumer_offsets` 读取位移，继续消费。
      - 分区再分配：故障消费者的分区由其他成员接管，从提交的位移处开始消费。
5. 常见问题与解决方案
   1. 消费者卡死：poll()调用间隔超过max.poll.interval.ms，解决方法：优化处理逻辑或增加max.poll.interval.ms
   2. 再平衡频繁触发：网络抖动或者消费者处理超时，解决方法：调整session.timeout.ms和heartbeat.interval.ms
   3. 位移提交失败：解决方法：可在回调中实现异步提交的重试逻辑。 同时监控位移主题，确保__consumer_offsets的副本数和保留策略合理

### 7. kafka如何实现顺序消费

- 全局有序
  - 只有 1 个分区，至于备份分区，看着填
  - 将来消费的时候呢，就只有一个消费者会持有这个所谓的【 1 个分区】进行消费，然后我们就正常循环接收一条条消息消费就好了
- 分区有序
  - N 个分区，M 个备份分区，N 其实要区分的是，需要有序的一批消息，请放入同一个分区
  - int partition = partition(record, serializedKey, serializedValue, cluster);
  - 需要在创建 KafkaProducer 对象的时候，需要在 Properties 设置属性 partitioner.class 对应的全类名即可。

### 8. kafka分布式集群脑裂问题

脑裂问题：假设有3个broker，其中broker1是controller，broker1因为网络卡住了，此时broker3选举成了新controller，然后broker1又恢复了，broker1和3都同时告诉broker2自己是管理者，这就是脑裂问题

解决办法：zookeeper里创建了一个controller_epoch节点，每选举成功一个controller，值就加1，可以理解为表示第几任controller，对于上述问题，broker2就听从最新controller就行

### 9. kafka里使用零拷贝

- 基础概念：
  - 传统数据拷贝：4次上下文切换（用户态/内核态切换）+ 4 次数据拷贝
    1. 磁盘 → 内核缓冲区：磁盘拷贝到内核的 Page Cache。
    2. 内核缓冲区 → 用户缓冲区：数据从内核态拷贝到用户态（例如 Java 的堆内存）。
    3. 用户缓冲区 → 内核 Socket 缓冲区：数据再次从用户态拷贝回内核态的 Socket 缓冲区。
    4. Socket 缓冲区 → 网卡：拷贝到网卡缓冲区
  - 零拷贝：直接通过内核缓冲区操作，无需再复制到用户空间
    1. 磁盘 → 内核缓冲区
    2. 内核缓冲区 → 网卡
- 实现原理：核心方法就是linux的sendfile系统调用，java中的FileChannel.transferTo()底层调用sendfile，实现零拷贝。现代网卡使用DMA，直接内存访问
- kafka中的零拷贝
  - 需要将本地文件发送网络时（如消费者拉数据），FileChannel.transferTo()，底层会调用sendfile方法
  - kafka的日志写入通过FileChannel.write()操作，Producer发送的消息被Broker写入内存缓冲区（log.append()），内存缓冲区通过mmap与磁盘文件绑定，数据直接写入PageCache（内核缓冲区）。然后后台线程会异步将pageCache的数据刷盘到磁盘。kafka的日志写入是顺序写入。
- 如果数据还没来得及从pageCache刷盘到磁盘就宕机，数据会丢失吗
  - 默认场景下可能丢失数据：Kafka 为追求高吞吐，默认依赖异步刷盘和操作系统机制，宕机时 Page Cache 未刷盘的数据会丢失。
  - 通过配置提升可靠性：结合 acks=all、多副本、合理设置 最小ISR副本数 和主动刷盘参数，可将数据丢失风险降至极低。

### 10.kafka里mmap怎么用的

mmap（Memory-Mapped Files，内存映射文件） 是一种将磁盘文件直接映射到进程虚拟内存地址空间的技术。通过 mmap，应用程序可以像访问内存一样直接读写文件，无需通过传统的 read()/write() 系统调用。

Kafka 将 mmap 用于索引文件（.index 和 .timeindex）的访问优化，而数据文件（.log）仍使用零拷贝（sendfile）。

### 11. controller选举是怎么实现的

这里的controller选举主要指的还是Kafka依赖于ZK实现的controller选举机制，也就是说，kafka的所有broker节点会监听ZK中的一个controller临时节点，如果这个节点没有创建，那么broker就会申请创建，一旦创建成功，那么创建成功的broker就会当选为集群的管理者controller，一旦失去了和ZK的通信，那么临时节点就会消失，此时就会再次进行controller的选举，选举的规则是完全一样的，一旦新的controller选举，那么controller纪元会被更新。

### 12. 分区副本AR, ISR, OSR的含义？

- AR：分区的所有副本集合
- ISR：正在同步数据的副本列表，列表的第一个就是分区的Leader副本，其他的副本就是Follower副本。
- OSR：OSR就是没有处于同步数据的副本列表。

一旦副本拉取数据满足了特点的条件，那么会从OSR中移除并增加到ISR中。同样，如果副本没有拉取数据满足了特定的条件，就会从ISR中移除，放入到OSR中。

### 13. 生产者消息重复或消息丢失的原因

消息重复：kafka有重试机制，上一条消息由于网络卡了一会儿，触发重试，但是上一条消息恢复正常了，都发送成功了，就会有重复消息。解决办法：kafka提供了幂等性操作解决数据重复，必须开启重试且ack=-1.kafka提供的幂等性操作只能保证同一个生产者会话中同一个分区中的数据不会重复，一旦数据发送过程中，生产者对象重启，那么幂等性操作就会失效。那么此时就需要使用Kafka的事务功能来解决跨会话的幂等性操作。但是跨分区的幂等性操作是无法实现的。

消息丢失：未开启重试，ack为0，可能由于网络问题发送给broker失败，造成消息丢失

### 14. 消费者消息重复或消息丢失的原因

重复消费：每隔一段时间自动保存偏移量，如果消费者重启，就可能重复消费。消费者手动保存偏移量，先业务操作再进行提交偏移量，业务操作完毕但是还没提交偏移量就重启，也可能重复消费，解决办法：保证业务逻辑是幂等的

消息丢失：消费者手动保存偏移量，先提交偏移量再进行业务操作，业务还没处理完消费者就重启，消息就会丢失

### 15. kafka有哪些高性能设计

最重要的还是顺序IO和零拷贝。 

- 分区：分区能提升并行写入能力，分区的分布式存储（跨broker分布）和副本机制（ISR机制）保证高可用
- segment顺序写：顺序写性能优势（100MB/s vs 随机写 100k/s）。顺序写减少磁盘寻址延迟，避免随机 IO 的性能损耗
- 生产者：线程+队列+批量发送，节省网络开销，ack机制保证高可用
- 零拷贝：Kafka 使用 `sendfile` 系统调用或 `mmap` 映射文件到内存，避免内核态到用户态的数据复制。生产者写入时直接通过页缓存（Page Cache）写入，消费者读取时直接通过 `mmap` 读取，减少数据拷贝次数。
- 消费者：批量拉取，减少网络开销。消费者组的负载均衡机制（如分区分配策略）允许水平扩展消费能力，提升整体吞吐。
- kafka的索引：Kafka 的消息索引（如 offset.index 和 time.index）仅存储部分位置，减少磁盘 I/O 和内存占用。例如：每 4KB 数据存储一个索引条目，查找时通过二分法快速定位。
- broker存储数据：将数据直接写入操作系统的page cache，由os管理刷盘（fsync）
- 数据压缩：网络传输数据时，可使用gzip、snappy、lz4等压缩算法
- 无状态设计：消费者自行管理offset，kafka不维护消费者状态，消费者通过消费者通过 __consumer_offsets 主题自主提交 Offset，减少协调开销。

### 16. 事务消息

- 事务消息解决的问题：
  - **Exactly Once Semantics（精确一次语义）**：确保消息不会重复消费，也不会丢失。
  - **跨分区的原子性**：在一个事务中，可以对多个分区进行写操作，并且这些操作要么全部成功，要么全部失败。
  - **生产者与消费者的协调**：支持生产者在事务中同时写入消息和消费偏移量（offset），从而避免数据不一致的问题。
- 核心组件：
  - Transaction Coordinator
    - 管理事务的生命周期（如开始、提交、回滚）。
    - 决定事务是否可以提交或需要回滚。
    - 持久化事务的状态到内部的主题（`__transaction_state`）。
  - Transactional Producer
    - 生产者需要显式地开启事务功能，通过设置 `transactional.id` 来标识一个事务。
    - 开启事务后，生产者的所有操作都会被标记为事务的一部分，直到事务被提交或回滚。
  - 事务日志（Transaction Log）
    - Kafka 使用一个内部主题（__transaction_state）来存储事务的状态信息，包括事务的元数据、事务的状态（如准备中、已提交、已回滚等）以及事务涉及的分区信息。
- 工作流程：
  - 初始化事务：
    - 生产者调用 `initTransactions()` 方法，向 Transaction Coordinator 注册当前的 `transactional.id`。
    - Transaction Coordinator 会检查是否有未完成的事务，并清理残留状态。
  - 开启事务：
    - 调用 `beginTransaction()` 方法，标记事务开始。
    - 此时，生产者的后续操作会被记录为事务的一部分。
  - 发送消息：
    - 生产者可以向多个分区发送消息，这些消息会被标记为“未提交”状态。
    - 消息的实际内容会被写入 Kafka 的日志中，但消费者暂时无法消费这些消息。
  - 提交或回滚事务：
    - 如果事务成功完成，调用 `commitTransaction()` 方法，Transaction Coordinator 会将事务状态更新为“已提交”，并通知相关的分区允许消费者消费这些消息。
    - 如果事务失败，调用 `abortTransaction()` 方法，Transaction Coordinator 会将事务状态更新为“已回滚”，并丢弃未提交的消息。

### 17. 事务消息的实战

场景：创建订单并扣减库存

提交事务的时机是由生产者决定的，所以还是可能会导致订单消费者成功，库存消费者失败。

解决方案：

- 生产者端
  - 开启事务后，先发送订单创建消息和库存扣减消息。
  - 调用 `commitTransaction()` 提交事务前，检查是否有前置条件（如库存是否充足）。如果有异常，则回滚事务。
- 消费者端
  - 订单消费者和库存消费者分别实现幂等性处理，确保消息重复消费不会导致数据不一致。
  - 如果库存消费者消费失败（如库存不足），记录补偿日志，并通过后续补偿机制处理。
- 补偿机制
  - 定时任务定期扫描补偿日志，尝试重新扣减库存或回滚订单。
  - 如果多次尝试仍然失败，通知管理员介入处理。

## Spring

### 1. 什么是IOC

IOC就是控制反转，核心思想就是将对象的创建和依赖关系交给容器管理，而不是由调用者自行创建。在spring中，开发只需要通过配置或者注解告诉容器有哪些bean以及他们之间的关系，容器就会自动完成这些bean的实例化、装配和管理。

IOC的一个重要实现方式就是依赖注入。spring有构造器注入、setter方法注入、字段注入。

spring IOC容器就是整个机制的核心，负责加载配置信息，解析BeanDefinition，创建bean实例，完成依赖注入

spring中一些核心类和方法

- DefaultListableBeanFactory：spring IOC容器的核心实现类，管理bean的定义，注册和生命周期
  - registerBeanDefinition(String beanName, BeanDefinition beanDefinition)：注册一个Bean定义到容器中。
  - getBean(String name)：是父接口BeanFactory里的方法，根据Bean的名字从容器中获取Bean实例。
  - preInstantiateSingletons()：预实例化所有非懒加载的单例Bean。
- AbstractAutowireCapableBeanFactory：负责具体的Bean实例化和依赖注入。
  - createBean(String beanName, RootBeanDefinition mbd, Object[] args)：创建Bean实例
  - populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw)：为Bean填充属性，完成依赖注入
  - initializeBean(String beanName, Object bean, RootBeanDefinition mbd)：执行Bean的初始化操作，包括调用初始化方法、应用后置处理器等。
- AutowiredAnnotationBeanPostProcessor：这是一个后置处理器，用于处理@Autowired和@Value注解，完成自动装配。
  - postProcessProperties(PropertyValues pvs, Object bean, String beanName)：在Bean的属性填充阶段，解析并注入标注了@Autowired的字段或方法。
- BeanDefinition：定义了Bean的元数据信息，包括Bean的类名、作用域（Scope）、是否懒加载、初始化方法、销毁方法等。
- ApplicationContext：这是Spring IOC容器的高级接口，扩展了BeanFactory，提供了更多的功能，比如事件发布、国际化支持等。
  - getBean(String name)：获取指定名称的Bean
  - publishEvent(ApplicationEvent event)：发布一个事件，触发监听器的响应

### 2. Spring里的bean的生命周期

- **加载配置**：容器读取XML配置文件、注解或Java配置类，解析出所有的BeanDifinition。
- **注册Bean定义**：将解析出的BeanDifinition注册到BeanFactory中。
- **实例化Bean**：根据Bean定义，容器通过反射创建Bean实例。
- **属性填充**：各种字段赋值
- **设置Bean名称**：如果Bean实现了BeanNameAware接口，容器会调用setBeanName()方法传入当前Bean的ID作为参数。
- **设置Bean工厂**：如果Bean实现了BeanFactoryAware接口，容器会调用setBeanFactory()方法传入当前的BeanFactory。
- **设置应用上下文**：如果Bean实现了ApplicationContextAware接口，容器会调用setApplicationContext()方法传入当前的ApplicationContext。
- **预初始化**：如果Bean实现了BeanPostProcessor接口，容器会在调用InitializingBean的afterPropertiesSet()方法和自定义的初始化方法之前调用postProcessBeforeInitialization()方法。
- **初始化**：如果Bean实现了InitializingBean接口，容器会调用其afterPropertiesSet()方法。如果是某个方法打上了@PostConstruct注解，则先执行注解方法再执行afterPropertiesSet
- **后初始化**：如果Bean实现了BeanPostProcessor接口，容器会在调用完自定义的初始化方法和afterPropertiesSet()方法之后调用postProcessAfterInitialization()方法。
- **使用Bean**：开发者通过getBean方法或依赖注入的方式获取Bean实例。
- **销毁Bean**：当容器关闭时，如果Bean实现了DisposableBean接口，容器会调用其destroy()方法。如果是某个方法打上了@PreDestroy注解，则先执行注解方法再执行destroy

### 3. Spring是怎么解决循环依赖问题的

三级缓存：

- Map<String, ObjectFactory<?>> singletonFactories：存放创建bean的工厂对象，存的是一个ObjectFactory（FunctionalInterface接口）

- Map<String, Object> earlySingletonObjects：存放尚未完全初始化的Bean（初始化或属性填充阶段的bean）

- Map<String, Object> singletonObjects：最终完成了初始化的bean统统放进这里

还有两个重要的容器：

- Set\<String\> singletonsCurrentlyInCreation：存放正在创建过程的bean。如果是创建bean的时候发现该set已经有了，说明发生了循环依赖
- Map<Object, Object> earlyBeanReferences：创建对象时，会首先往singletonFactories放一个ObjectFactory，其调用的方法就是getEarlyBeanReference，该方法执行逻辑就是如果有代理，就创建bean的代理对象，如果没有代理就直接返回bean。如果有代理，会往earlyBeanReferences放入原来的bean。后续执行postProcessAfterInitialization方法时，就判断有没有已经执行过代理逻辑了，执行过就直接返回bean（因为这里传进来的bean就已经是代理bean），没执行过就执行代理逻辑，返回代理bean。这样确保了代理bean是单例，不会创建多个

简单场景：classA依赖classB，classB依赖classA，scope都是单例singleton

| classA的行为                                                 | classB的行为                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **实例化**：创建classA对象，singletonFactories存入classA的ObjectFactory |                                                              |
| **属性填充**：需要classB，缓存中都没有                       |                                                              |
|                                                              | **实例化**：创建classB对象，singletonFactories存入classB的ObjectFactory |
|                                                              | **属性填充**：需要classA，从singletonFactories拿到classA的ObjectFactory（Functional接口），然后调用其getObject()方法得到classA，然后将classA放入到earlySingletonObjects，从singletonFactories移除 |
|                                                              | **完成初始化**：继续执行其他初始化逻辑（如`@PostConstruct`）最终将自己将自身放入`singletonObjects`，并从`singletonFactories`移除`ClassB`的ObjectFactory |
| **属性填充完成**：完成注入classB                             |                                                              |
| **完成初始化**：继续执行其他初始化逻辑，将classA从earlySingletonObjects移动到singletonObjects |                                                              |

复杂场景：classA有AOP

| ClassA的行为（AOP代理场景）                                  | ClassB的行为                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **实例化**：创建`ClassA`的原始对象，生成代理对象的`ObjectFactory`（包含AOP逻辑），存入`singletonFactories` |                                                              |
| **属性填充**：需要注入`ClassB`，检查缓存（`singletonObjects`、`earlySingletonObjects`、`singletonFactories`均无`ClassB`） |                                                              |
|                                                              | **实例化**：创建`ClassB`的原始对象，生成`ObjectFactory`（普通对象，无需代理），存入`singletonFactories` |
|                                                              | **属性填充**：需要注入`ClassA`，从`singletonFactories`中找到`ClassA`的`ObjectFactory`（代理工厂） |
|                                                              | **生成代理对象**：调用`ClassA`的`ObjectFactory.getObject()`，触发AOP代理逻辑，生成`ClassA`的代理对象，将其放入`earlySingletonObjects`，并从`singletonFactories`移除`ClassA`的工厂 |
|                                                              | **完成初始化**：`ClassB`继续执行其他初始化逻辑（如`@PostConstruct`），最终将自身放入`singletonObjects`，并从`singletonFactories`移除`ClassB`的工厂 |
| **属性填充完成**：成功注入`ClassB`（此时`ClassB`已完全初始化） |                                                              |
| **执行AOP增强逻辑**：对`ClassA`的代理对象进行后续初始化（如代理方法的增强处理） |                                                              |
| **完成初始化**：将`ClassA`的代理对象从`earlySingletonObjects`移动到`singletonObjects` |                                                              |

如果classA和classB都是构造器注入场景，spring无法处理，启动报错

如果scope是prototype，每次创建新实例，spring无法处理，启动报错

### 4. @Lazy是怎么解决循环依赖的

场景：classA依赖classB。classB依赖classA。classB被标记为@Lazy。

首先创建classA，在填充classA的时候，会为classB字段生成一个代理对象，将其注入到classB字段中。当真正使用classB的时候，才开始创建，填充的时候直接就能从singletonObjects里拿到classA注入其classA字段

### 5. 什么是AOP

面向切面编程。是一种编程范式，它的核心思想是将横切关注点（Cross-Cutting Concerns）从业务逻辑中分离出来，从而提高代码的模块化程度和可维护性。

具体来说，AOP的核心概念包括以下几个：

1. **切面（Aspect）**：切面是横切关注点的模块化实现。比如，一个用于日志记录的切面可以包含所有与日志相关的逻辑。
2. **连接点（Join Point）**：程序执行过程中的某个特定点，比如方法调用、方法执行、异常抛出等。在Spring AOP中，连接点通常是方法的执行。
3. **通知（Advice）**：切面在特定的连接点上执行的动作。根据执行时机的不同，通知可以分为前置通知（Before）、后置通知（After）、返回通知（After Returning）、异常通知（After Throwing）以及环绕通知（Around）。
4. **切入点（Pointcut）**：用来定义哪些连接点会被通知所影响。切入点表达式是用来匹配连接点的一种机制，比如可以通过正则表达式或者注解来指定需要拦截的方法。
5. **引入（Introduction）**：允许我们为现有的类动态地添加新的方法或属性。
6. **织入（Weaving）**：将切面应用到目标对象并创建代理对象的过程。织入可以在编译时、类加载时或者运行时完成。在Spring AOP中，织入是在运行时完成的。

### 6. spring是怎么实现AOP的

Spring AOP 使用了两种动态代理技术来实现 AOP：

- **JDK 动态代理**：如果目标对象实现了接口，Spring 默认会使用 JDK 动态代理。JDK 动态代理的核心是 `java.lang.reflect.Proxy` 类和 `java.lang.reflect.InvocationHandler` 接口。它会在运行时为接口生成一个代理类，并在调用方法时拦截这些方法调用。
- **CGLIB 动态代理**：如果目标对象没有实现任何接口，Spring 会使用 CGLIB 来生成代理对象。CGLIB 是一个基于字节码操作的库，它通过继承目标类并重写其方法来实现代理功能。

可以通过配置或注解（如 `@EnableAspectJAutoProxy(proxyTargetClass = true)`）强制 Spring 使用 CGLIB。

AOP的核心流程：

1. **定义切面（Aspect）**：通过注解（如 `@Aspect`）或 XML 配置定义切面，并在其中声明通知（Advice）。
2. **解析切入点表达式（Pointcut Expression）**：Spring 使用 AspectJ 的切入点表达式语法来匹配需要拦截的方法。
3. **创建代理对象**：Spring 在容器初始化时会为目标对象生成代理对象。代理对象内部封装了对目标对象的调用以及切面逻辑。
4. **拦截方法调用**：当调用目标方法时，实际上是调用了代理对象的方法。代理对象会根据切入点表达式判断是否需要执行切面逻辑。
5. **执行通知（Advice）**：根据通知类型（前置、后置、环绕等），在目标方法执行的不同阶段执行相应的切面逻辑。

### 7. springboot的自动装配

自动装配主要依赖三个核心元素：@EnableAutoConfiguration注解、spring.factories文件和条件注解。当项目启动时，Spring Boot会扫描classpath下的所有jar包中的META-INF/spring.factories文件，加载其中定义的自动配置类。

同时引入了多个Starter，导致某些自动配置产生了冲突。后来通过在application.properties中使用debug=true开启了自动配置报告，详细分析了哪些配置被应用，哪些被排除

## 分布式

### 事务

#### 1. 什么是CAP理论

- **一致性Consistency**：所有节点在同一时间看到的数据完全一致
- **可用性Availability**：服务的读写总是会成功响应
- **分区容错性Partition tolerance**：分布式系统在遇到某个节点或网络分区故障时，仍能对外提供服务

根据CAP理论，只能同时满足两个。

- CA：放弃分区容错性，当网络发生故障时，系统将无法正常工作。
- CP：放弃可用性，当网络发生故障时，某些请求无法得到响应，但最终会保持一致
- AP：放弃一致性，当网络发生故障时，系统能正常对外提供服务，但是可能读到旧数据

#### 2. 什么是BASE理论

- **基本可用Basically Available**：系统出现部分故障时，仍能对外提供服务
- **柔性状态Soft state**：允许一段时间内出现不一致的状态
- **最终一致性Eventually consistent**：经过一段时间后，系统会通过补偿机制保证数据最终达到一致

#### 3. 分布式事务

1. 两阶段提交2PC
   - **准备阶段**：协调者向所有参与者发送准备请求，如果所有参与者都回复可以，则进入下一阶段。如果存在回复不可以，则事务直接回滚
   - **提交阶段**：如果所有参与者都同意执行事务，协调者会发送提交请求，所有参与者提交事务。出现问题还是所有参与者的事务都回滚
2. 三阶段提交3PC
   - **CanCommit 阶段**：协调者询问参与者是否可以执行事务操作
   - **PreCommit 阶段**：预提交事务，准备执行具体业务操作
   - **DoCommit 阶段**：正式提交事务，完成操作
   - 超时机制：
     - 如果参与者在某个阶段没收到协调者的指令
       - 如果处于PreCommit 阶段，参与者默认提交事务
       - 如果处于CanCommit 阶段，参与者会默认回滚事务
     - 如果协调者没收到参与者的响应，会重新发送请求或者超时处理
3. TCC：以转账场景为例，A账户给B账户转100元
   - **Try阶段**：尝试执行业务操作，预留资源但不提交
     - A账户检查余额是否足够，并冻结100元，B账户预留接收100元的能力
   - **Confirm 阶段**：确认执行业务操作，真正提交资源
     - A 账户正式扣减 100 元（从“冻结金额”转移到实际扣减）。B 账户正式增加 100 元（将“预留金额”转移到实际余额）。
   - **Cancel 阶段**：取消业务操作，释放预留的资源
     - A 账户解冻 100 元（将“冻结金额”恢复到可用余额）。B 账户撤销预留操作
   - Confirm和Cancel必须得是幂等的。
4. Saga
   - Saga是一种长事务解决方案
   - 将一个分布式事务分解为多个子事务，每个子事务都可以独立地提交或回滚
   - 如果某个子事务失败，可以通过一系列的补偿操作来恢复系统的状态。
5. 基于消息的最终一致性
   - 利用消息队列来实现分布式事务，核心思想是通过消息的可靠传递来保证最终一致性
   - 典型流程：
     1. 在本地事务中完成业务操作，并将消息写入消息表
     2. 通过消息队列异步投递消息，确保消息被下游消费
     3. 如果消息投递失败，则通过重试机制保证最终一致性

| 特性/方案      | 两阶段提交2PC              | 三阶段提交3PC                                | TCC模式                                      | 消息最终一致性           | Seata-AT模式                 |
| -------------- | -------------------------- | -------------------------------------------- | -------------------------------------------- | ------------------------ | ---------------------------- |
| **一致性级别** | 强一致性                   | 弱一致性                                     | 最终一致性                                   | 最终一致性               | 强一致性                     |
| **性能开销**   | 高，存在锁资源             | 中等，相比于2PC好一点                        | 中等，需业务补偿逻辑                         | 较低，异步处理           | 较低，自动管理回滚           |
| **实现复杂度** | 简单，依赖数据库XA协议     | 比2PC复杂一点                                | 复杂，代码侵入，需手动实现Try/Confirm/Cancel | 中等，需保证消息可靠传递 | 简单，对业务代码侵入小       |
| **适用场景**   | 短事务、强一致性要求的场景 | 高并发、对一致性要求不高的场景               | 核心交易场景，如支付、转账                   | 对实时性要求不高的场景   | 通用业务场景，适合微服务架构 |
| **缺点**       | 同步阻塞，单点问题风险大   | 可能存在某些事务提交某些事务回滚，数据不一致 | 开发成本高，业务侵入性强                     | 数据可能暂时不一致       | 依赖额外组件，对表结构有要求 |

#### 4. 数据库ACID事务的一致性和CAP理论中的一致性有什么区别？

| 特性               | ACID一致性                                   | CAP一致性                            |
| ------------------ | -------------------------------------------- | ------------------------------------ |
| **适用场景**       | 单机数据库事务                               | 分布式系统                           |
| **核心目标**       | 保证事务执行前后数据满足业务规则和完整性约束 | 保证所有节点在同一时刻看到相同的数据 |
| **约束范围**       | 事务级别的数据完整性                         | 分布式系统中多个节点的数据一致性     |
| **实现方式**       | 原子性、隔离性、持久性协同保障               | 分布式一致性协议（如Raft、Paxos）    |
| **是否与性能冲突** | 一般不冲突                                   | 强一致性会牺牲性能和可用性           |

### 锁

#### 1. 什么是分布式锁？它的作用是什么？

分布式锁是一种在分布式系统中用来控制多个节点（进程或服务）对共享资源进行互斥访问的机制。它通过某种协调服务（如Redis、Zookeeper等）来实现，确保在分布式环境下，同一时间只有一个节点能够持有锁并操作共享资源。

作用：

1. **保证数据一致性**：在分布式系统中，多个服务实例可能同时操作同一个共享资源（比如数据库中的某条记录）。分布式锁可以确保这些操作是串行化的，避免并发问题。
2. **防止重复执行**：例如，在分布式任务调度系统中，可能会有多个节点尝试执行同一个任务。通过分布式锁，可以确保任务只被执行一次。
3. **控制并发访问**：在高并发场景下，分布式锁可以限制对某些关键资源的并发访问，从而避免系统过载或数据不一致的问题。

#### 2. 分布式锁与本地锁的主要区别是什么？

| 特性         | 本地锁                                              | 分布式锁                                           |
| ------------ | --------------------------------------------------- | -------------------------------------------------- |
| **作用范围** | 单个JVM进程内                                       | 跨多个JVM进程、跨多台机器                          |
| **实现方式** | 基于Java内置锁（如`synchronized`或`ReentrantLock`） | 基于第三方协调服务（如Redis、Zookeeper、数据库等） |
| **依赖环境** | 不依赖外部组件                                      | 需要依赖外部存储或协调服务                         |
| **性能**     | 性能较高，无需网络通信                              | 性能较低，涉及到网络通信                           |
| **可靠性**   | 只适用于单机环境，无法应对分布式场景                | 更复杂，但支持分布式场景                           |
| **锁的释放** | JVM自动管理（如线程结束时释放锁）                   | 需要显式释放，或通过超时机制避免死锁               |
| **适用场景** | 单机应用、单进程内的并发控制                        | 分布式系统、微服务架构下的并发控制                 |

#### 3. 用redis实现一个分布式锁

核心思想：使用lua脚本将setnx和expire两个命令合并为一个原子操作

加锁代码如下：

```lua
-- Lua 脚本（原子执行）
local result = redis.call('SET', KEYS[1], ARGV[1], 'NX', 'EX', tonumber(ARGV[2]))
return result
```

```java
redis.eval(luaScript, Collections.singletonList(lockKey), identifier, "30");
```

释放锁代码如下：

```java
// 使用 Lua 脚本实现 CAS（Compare And Swap）
String script = "if redis.call('GET', KEYS[1]) == ARGV[1] then return redis.call('DEL', KEYS[1]) else return 0 end";
Long result = (Long) redis.eval(script, 
    Collections.singletonList(lockKey), 
    identifier);
if (result == 1) {
    System.out.println("锁释放成功");
}
```

可重入锁：将锁的值设计为 `客户端唯一标识符:持有次数` 的格式，例如 `client_123:3` 表示客户端 `client_123` 已持有锁 3 次。

#### 4. 用zookeeper实现一个分布式锁

1. 创建一个持久化节点作为锁的根节点，例如/lock
2. 创建临时顺序节点，每个客户端尝试获取锁时，会在 `/lock` 下创建一个临时顺序节点，例如 `/lock/0000000001`、`/lock/0000000002` 等
3. 判断是否获得锁，客户端创建完自己的临时顺序节点后，需要检查自己是否是当前最小编号的节点：如果是，则获得锁。如果不是，则监听比自己编号小的前一个节点的变化（即 Watcher 机制）。
4. 锁的等待和通知，如果客户端未获得锁，则进入等待状态，并设置一个 Watcher 监听前一个节点的删除事件。当前一个节点被删除时，ZooKeeper 会通知客户端重新检查自己是否是最小编号的节点。
5. 锁的释放，当客户端完成任务后，主动删除自己的临时顺序节点（例如 `/lock/0000000001`）。由于节点是临时节点，如果客户端意外断开连接，ZooKeeper 也会自动删除该节点，从而释放锁。

原理总结：

- **公平性**：通过顺序节点保证锁的获取顺序严格按请求顺序执行。
- **可靠性**：通过临时节点和 Watcher 机制，确保锁在客户端异常退出时能够自动释放。
- **强一致性**：ZooKeeper 的 Paxos 协议保证数据一致性，避免脑裂问题。

#### 5. redisson的几种锁

| 锁类型       | 特点                                                         | 使用场景                                                 | 示例代码                                                     |
| ------------ | ------------------------------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------------ |
| **可重入锁** | 支持同一线程多次获取                                         | 递归调用、嵌套调用                                       | RLock lock = redissonClient.getLock("lockKey");              |
| **公平锁**   | 按请求顺序分配锁，避免饥饿问题                               | 需要公平性的场景，需要严格按照请求顺利处理任务           | RLock fairLock = redissonClient.getFairLock("fairLockKey");  |
| **联锁**     | 同时对多个资源加锁。联锁的获取是原子性的，避免了死锁问题。   | 需要同时操作多个资源的场景，例如跨服务调用或分布式事务。 | RLock lock1 = redissonClient.getLock("lock1");<br />RLock lock2 = redissonClient.getLock("lock2");<br />RLock multiLock = redissonClient.getMultiLock(lock1, lock2); |
| **红锁**     | 基于多个 Redis 实例实现高可用锁                              | Redis 单点部署存在风险，需要更高的容错能力。             | Config config1 = new Config();<br/>config1.useSingleServer().setAddress("redis://127.0.0.1:6379");<br/>RedissonClient redisson1 = Redisson.create(config1);<br/>Config config2 = new Config();<br/>config2.useSingleServer().setAddress("redis://127.0.0.1:6380");<br/>RedissonClient redisson2 = Redisson.create(config2);<br/>RLock lock1 = redisson1.getLock("lock1");<br/>RLock lock2 = redisson2.getLock("lock2");<br/>RLock redLock = redissonClient.getRedLock(lock1, lock2); |
| **读写锁**   | 支持读写分离，允许多个线程同时获取读锁，但只允许一个线程获取写锁。 | 读多写少的场景，例如缓存系统、配置中心等                 | RReadWriteLock rwLock = redissonClient.getReadWriteLock("rwLockKey");<br />rwLock.readLock().lock();<br />rwLock.writeLock().lock(); |
| **信号量**   | 控制同时访问某个资源的线程数量。支持分布式环境下的限流和资源分配。 | 限制并发线程数的场景，例如限流、连接池管理等。           | RSemaphore semaphore = redissonClient.getSemaphore("semaphoreKey");<br/>semaphore.trySetPermits(10); // 设置初始许可数量<br/><br/>if (semaphore.tryAcquire()) {<br/>    try {<br/>        // 核心业务逻辑<br/>    } finally {<br/>        semaphore.release();<br/>    }<br/>} |
| **计数锁**   | 允许一个或多个线程等待，直到其他线程完成某些操作后触发。     | 多线程协作的场景，例如等待多个任务完成后继续执行。       | RCountDownLatch latch = redissonClient.getCountDownLatch("latchKey");<br/>latch.trySetCount(5); // 设置初始计数值<br/><br/>new Thread(() -> {<br/>    try {<br/>        latch.await(); // 等待计数变为 0<br/>    } catch (InterruptedException e) {<br/>        e.printStackTrace();<br/>    }<br/>}).start();<br/><br/>for (int i = 0; i < 5; i++) {<br/>    new Thread(() -> {<br/>        // 执行任务<br/>        latch.countDown(); // 减少计数<br/>    }).start();<br/>} |
| **局部锁**   | 本地缓存锁状态，减少 Redis 访问                              | 高频加锁操作、读多写少的场景。最终一致性                 | // 创建一个本地缓存的 Map<br/>RMap<String, String> map = redissonClient.getMap("myMap", LocalCachedMapOptions.defaults());<br/>// 获取局部锁<br/>RLock lock = map.getLock("key");<br/>lock.lock(); |

#### 6. 锁一般会设置超时时间，为什么？超时时间一般设置多大？

设置超时时间的原因：

- 防止死锁
- 避免长时间占用资源
- 容错机制：分布式系统中可能存在网络延迟、节点故障等问题。超时时间提供了一种容错机制，确保即使某些异常情况发生，系统仍然能够正常运行。

超时时间一般设置多大：

- 业务处理时间：超时时间应该大于业务逻辑的最大执行时间。
- 系统性能：超时时间过长会导致锁资源被长时间占用，降低系统的并发能力。超时时间过短可能导致锁在业务处理完成前就过期，引发数据一致性问题。
- 经验值：简单操作：3~5 秒。复杂操作：10~30 秒。特殊场景：根据具体需求调整。
- 自动续期：可以使用 Redisson 提供的 看门狗（Watchdog）机制，自动延长锁的有效时间

总结：锁的超时时间是为了防止死锁和资源长时间占用，通常设置为业务逻辑最大执行时间的 2~3 倍，实际值需要根据具体场景灵活调整。

#### 7. 分布式锁什么情况下会发生死锁

- 没有正确释放锁，finally里面没有正确释放
- 锁的超时时间不足，线程A拿到锁因超时自动释放，此时线程B拿到锁，线程 A 完成业务逻辑后尝试释放锁，但此时锁已经被线程 B 持有，可能导致数据不一致或死锁。
  - 解决方案：释放锁时提前判断拿到该锁的是不是当前线程
- 多个锁交叉持有。线程 A 先获取锁 X，再尝试获取锁 Y。线程 B 先获取锁 Y，再尝试获取锁 X。两个线程互相等待对方释放锁，导致死锁。
  - 解决方案：
    - 使用全局统一的加锁顺序。例如，总是先获取锁 X，再获取锁 Y。
    - 使用 Redisson 提供的 联锁（MultiLock） 功能，确保多个锁的获取是原子性的。
- 锁的粒度过大
  - 解决方案：尽量使用细粒度的锁，例如按用户ID、订单ID等维度划分锁key

### 缓存

#### 1. 什么是缓存穿透、缓存击穿和缓存雪崩？如何解决这些问题？

|          | 缓存穿透                                                     | 缓存击穿                                                     | 缓存雪崩                                                     |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 概念     | 客户端请求的数据在缓存中不存在，同时在数据库中也不存在。会导致每次请求都会到数据库。 | 某个热点数据在缓存中恰好失效，此时大量并发请求直接涌入数据库。 | 大量缓存在同一时间点集中失效，导致所有请求瞬间涌向数据库     |
| 解决方案 | **布隆过滤器**：在缓存之前再加上一层布隆过滤器，用来快速判断某个key是否存在于数据库中。<br />**缓存空值**：如果数据库中确实没有对应的数据，可以在缓存中存储一个特殊的空值（如 `null` 或者特定标志），并设置一个较短的过期时间。这样可以防止恶意或高频请求重复打到数据库。 | **互斥锁**：通过分布式锁让第一个请求去加载数据写入缓存<br />**永不过期策略**：对于一些非常核心的热点数据，可以采用逻辑上的“永不过期”策略。例如，通过后台定时任务定期刷新缓存中的数据。<br />**异步刷新**：如果业务接受，可以异步加载缓存，缓存没加载好时直接返回空值或默认值 | **随机化过期时间**：给每个缓存 key 设置一个基础 TTL，并在此基础上增加一个小范围的随机值。这样可以避免大量缓存在同一时间点同时失效。<br />**多级缓存架构**：使用多级缓存（如本地缓存 + 分布式缓存）。即使分布式缓存失效，本地缓存仍然能够承担一部分流量，减轻数据库的压力。<br />**限流与降级**：配合服务治理框架（如 Sentinel 或 Hystrix），对高并发场景进行限流和降级处理。比如，当检测到数据库负载过高时，直接返回默认值或者错误提示，保护系统稳定性。 |

#### 2. 布隆过滤器是什么？

Redis的布隆过滤器是一种空间效率极高的概率型数据结构，用于判断一个元素是否在一个集合中。它的主要用途包括：

- **快速判断一个元素是否在一个集合中**：布隆过滤器可以快速地告诉你一个元素"可能在集合中"或"肯定不在集合中"。如果布隆过滤器返回"可能在集合中"的结果，那么这个元素有可能在集合中，但也有一定的误报率；如果布隆过滤器返回"肯定不在集合中"的结果，那么这个元素就一定不在集合中。
- **减少磁盘读写**：布隆过滤器可以避免对不存在的数据进行不必要的磁盘操作。例如，在分布式系统中，客户端在访问某个数据之前，可以先通过布隆过滤器检查该数据是否存在，如果不存在，则直接返回错误信息，避免了不必要的网络传输和磁盘读取操作。
- **降低缓存穿透的概率**：布隆过滤器可以有效地减少缓存穿透的概率。当一个请求查询的数据不存在时，如果没有使用布隆过滤器，那么每次请求都会穿透到后端数据库，增加了系统的负载。而使用布隆过滤器后，可以在数据不存在的情况下直接返回，从而减少了对后端数据库的访问次数。

### 一致性

#### 1. paxos算法

解决什么问题：在分布式系统中，由于网络延迟、节点故障等原因，不同节点可能会有不同的状态或数据。为了保证系统的 **一致性（Consistency）**，需要一种机制让所有节点对某个值达成一致。例如：在 ZooKeeper 中，多个服务器需要就某个配置值达成一致

三个角色：提议者、接收者、学习者

两个阶段：

- 准备阶段
  1. Proposer 向所有的 Acceptor 发送一个 Prepare 请求，附带一个递增的提案编号
  2. 如果 Acceptor 收到的提案编号比之前收到的所有提案编号都大，则它会承诺不再接受任何编号小于该提案编号的提案。如果它之前已经接受了某个值，则返回该值给 Proposer
- 接受阶段
  1. Proposer 根据收到的回复，选择一个值（如果有多个值，则选择编号最大的那个），并向所有 Acceptor 发送 Accept 请求，附带该值和提案编号
  2. 如果 Acceptor 收到的提案编号大于等于它承诺的最小编号，则接受该值。
- 当大多数Acceptor接受了某个值后，该值就被认为是最终一致的值。Learner 可以通过查询 Acceptor 来学习这个值

#### 2. Multi-Paxos算法

基本 Paxos 的问题

- **多次通信开销**：每次提案都需要经过 Prepare 和 Accept 两个阶段，导致网络通信频繁。
- **活锁问题**：如果多个 Proposer 同时竞争提案编号，可能会导致提案反复失败（即活锁）。
- **复杂性**：Paxos 的实现和调试难度较高，尤其是在大规模分布式系统中。

Multi-Paxos 的目标：通过引入一个稳定的 Leader 节点来优化 Paxos 的性能，减少通信开销，并避免活锁问题。

阶段 1：选举 Leader

1. 所有节点参与选举，选出一个 Leader。
2. Leader 获得大多数 Acceptor 的认可后，开始负责后续的提案。

阶段 2：提案处理

1. Prepare 阶段（只需一次）：Leader 初始时执行一次 Prepare 请求，获得大多数 Acceptor 的承诺。
2. Accept 阶段（多次）：
   - Leader 直接向 Acceptor 发送 Accept 请求，附带提案编号和值。
   - 如果 Acceptor 收到的提案编号大于等于其承诺的最小编号，则接受该值。
3. 学习阶段：Learner 从 Acceptor 获取最终一致的值。

#### 3. raft算法

**1. 核心概念**

**(1) 角色**

Raft 中有三种角色，节点可以在不同时间担任不同的角色：

- **Leader（领导者）**：负责处理客户端请求，并将日志条目复制到其他节点。
- **Follower（跟随者）**：被动接收 Leader 的日志条目，并响应 Leader 的请求。
- **Candidate（候选者）**：在选举过程中临时的角色，用于竞选成为新的 Leader。

**(2) 任期（Term）**

Raft 将时间划分为一系列连续的 **任期（Term）**，每个任期都有一个唯一的编号。

- 每个任期开始时会进行一次选举。
- 如果某个节点当选为 Leader，则该任期结束。
- 如果选举失败或发生网络分区，则可能进入下一个任期。

**(3) 日志复制**

Raft 使用日志来记录状态变更，所有节点通过日志保持一致性：

- 每个日志条目包含一个命令（如写操作）和任期编号。
- Leader 负责将日志条目复制到大多数节点后，才能提交并应用到状态机。

------

**2. 工作流程**

**(1) 选举（Election）**

1. 当 Follower 在一定时间内未收到 Leader 的心跳消息时，它会转变为 Candidate 并发起选举。
2. Candidate 向其他节点发送投票请求（RequestVote），附带当前任期编号和日志信息。
3. 如果某个 Candidate 收到大多数节点的投票，则当选为新的 Leader。

**(2) 日志复制（Log Replication）**

1. Leader 接收客户端请求，并将请求内容作为日志条目追加到本地日志中。
2. Leader 将日志条目复制到其他节点（AppendEntries 请求）。
3. 只有当大多数节点成功复制了某个日志条目后，该条目才被提交并应用到状态机。

**(3) 提交（Commit）**

1. Leader 通过心跳消息通知其他节点哪些日志条目已被提交。
2. 所有节点将已提交的日志条目应用到本地状态机，从而保证一致性。

**(4) 安全性**

Raft 通过以下机制保证安全性：

- **选举限制**：只有日志最新的节点才能当选为 Leader。
- **日志匹配**：如果两个日志条目具有相同的索引和任期编号，则它们的内容必须相同。

#### 4. 一致性哈希算法

**基本原理**：一致性哈希的核心思想是将所有的节点（服务器）和数据映射到一个虚拟的环形空间（称为一致性哈希环），并通过哈希值计算它们的位置。数据顺时针找到的第一个节点就是其所在的服务器。

**相较于传统哈希算法（取模哈希hash(key) % N）的优势**：传统哈希扩容缩容时，所有数据都需要重新计算哈希，导致数据大量迁移。而哈希环上节点的增减只会迁移少部分数据

**虚拟节点**：优化手段，用于解决数据分布不均的问题。每个物理节点会被映射到多个虚拟节点。这些虚拟节点均匀分布在一致性哈希环上。数据项通过哈希计算后，会找到最近的虚拟节点，再通过虚拟节点找到对应的物理节点。

#### 5. redis缓存和mysql数据库的一致性怎么保证

|          | 旁路缓存                                                     | 读写穿透                                                     | 写回缓存                                                     | 基于消息队列                                           |                       分布式锁配合双写                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------ | :----------------------------------------------------------: |
| 核心思路 | 读：先读缓存，命中则返回，未命中则读数据库，然后写入缓存并返回<br />写：先更数据库，再删除缓存 | 读：先读缓存，命中则返回，未命中则由缓存层负责从数据库读数据并写入缓存后返回<br />写：直接写入缓存，由缓存层同步更新数据库 | 读：先读缓存，命中则返回，未命中则读数据库，然后写入缓存并返回<br />写：只更新缓存，异步将数据写入数据库 | 更新数据库后发一条消息，消费者拿到消息后更新或删除缓存 | 读：先读缓存，命中则返回，未命中则加锁加载数据<br />写：加锁，依次更新数据库和缓存 |
| 优点     | 实现简单<br />避免了更新缓存带来的开销                       | 对业务代码透明，只需要与缓存交互即可<br />数据一致性较高     | 写性能高                                                     | 能实现最终一致性<br />系统解耦，提升扩展性             |                         一致性非常高                         |
| 缺点     | 存在短暂的不一致（延迟双删解决）<br />缓存删除失败可能导致不一致 | 实现复杂，需要对缓存层定制化开发<br />性能不如旁路缓存，因为每次写都要同时更新缓存和数据库 | 数据库一致性较差<br />存在数据丢失的风险                     | 需要维护消息队列的可靠性和幂等性                       |       性能较差<br />分布式锁有一定复杂性和风险（死锁）       |
| 适用场景 | 读多写少，一致性要求不高，例如：商品信息                     | 一致性要求较高，例如：用户的账户余额                         | 写多读少，一致性要求较低，例如：日志收集系统                 | 要求最终一致性、高并发，例如：订单的状态               |                     要求强一致性，低并发                     |

