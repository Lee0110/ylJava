#      面试复习

## 计算机网络

### 1. OSI与TCP/IP各层的结构与功能,都有哪些协议?

- 五层协议各层作用
  - 应用层(application-layer)的任务是通过应用进程间的交互来完成特定网络应用。应用层的协议包括域名系统DNS、HTTP协议、电子邮件的SMTP协议。这一层的数据都叫报文
  - 运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。运输层的协议：TCP(提供面向连接的，可靠的数据传输服务)和UDP(提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）)[]()
  - 在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信⼦网。网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。 常用IP协议，分组也叫IP数据报
  - 数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。将IP数据报组装成帧。
  - 物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。
- OSI多的两层
  - 会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。
  - 表示层的具体功能如下：
    数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。
    数据的编码：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。
    压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。
    数据的加密和解密：可以提高网络的安全性。
- TCP/IP只有四层
  - 网络接口层包括用于协作IP数据在已有网络介质上传输的协议。它定义像地址解析协议(Address Resolution Protocol,ARP)这样的协议，提供TCP/IP协议的数据结构和实际物理硬件之间的接口。

### 2. OSI七层图片

- ![](/images/OSI七层模型.gif)

### 3. TCP三次握手和四次挥手

- TCP三次握手

  -  服务器通过创建socket、bind、listen完成初始化，通过accept完成连接的建立。
  -  客户端通过创建socket、connect发起连接建立请求

  ![](images/TCP三次握手.jpg)

- TCP四次挥手

  ![](images/TCP四次挥手.jpg)

### 4. 为什么握手是三次

- 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误
- 例子：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。

### 5. 为什么挥手是四次

- 本质的原因是tcp是全双公的，要实现可靠的连接关闭，A发出结束报文FIN，收到B确认后A知道自己没有数据需要发送了，B知道A不再发送数据了，自己也不会接收数据了，但是此时A还是可以接收数据，B也可以发送数据；当B发出FIN报文的时候此时两边才会真正的断开连接，读写分开。

### 6. 如果TCP连接时某一次握手丢失了,会发生什么

- 第一次握手丢失：会触发超时重传机制，在linux里，最大重传次数由tcp_syn_retries内核参数控制，默认是5。通常每次等待时间是上一次的两倍。超过5次后还是没有回应ACK，就直接断开TCP连接。

- 第二次握手丢失：
  - 客户端会认为自己的报文丢失了，会触发超时重传机制，重新发SYN报文
  - 服务端也会触发超时重传机制，重传SYN-ACK报文，linux里最大重传次数由tcp_synack_retries内核参数决定
- 第三次握手丢失：服务端也会触发超时重传机制，重传SYN-ACK报文

### 7. 如果TCP断开连接时某一次挥手丢失了，会发生什么

- 第一次挥手：客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，直接进入到 close 状态。
- 第二次挥手：客户端会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。
- 第三次挥手：服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。
- 第四次挥手：服务端就会重发 FIN 报文

### 8. TCP、UDP区别

TCP：面向连接、可靠、传输形式为字节流、慢、所需资源多、应用场景:文件传输、邮件传输等

UDP：无连接、不可靠、传输形式为数据报文段 、快、所需资源少、应用场景：QQ语音、QQ视频等

UDP首部由源端口号、目标端口号、包长、和校验和组成

TCP首部由源端口号、目标端口号、序列号、确认应答号、数据偏移、保留、控制位、窗口大小、校验和、紧急指针、选项、填充组成

### 9. TCP如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层
3. 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段
4. TCP接收端会丢弃重复的数据
5. 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，会提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大⼩的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. 拥塞控制：当网络拥塞时，减少数据的发送
7. ARQ协议： 它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组
8. 超时重传：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

### 10. ARQ协议(自动重传请求)

自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议

- 停止等待ARQ协议

  - 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组
  - 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认
  - 优点：简单
  - 缺点：信道利用率低，等待时间长

- 连续ARQ协议

  连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了

  优点：信道利用率高，容易实现，即使确认丢失，也不必重传

  缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息

### 11. 滑动窗口和流量控制

TCP利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大⼩，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

### 12. 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注⼊到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收

为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大⼩取决于网络的拥塞程度，并且动态变化。发送方让⾃⼰的发送窗口取为拥塞窗口和接收方的接受窗口中较⼩的一个

TCP的拥塞控制采用了四种算法，即慢开始 、 拥塞避免 、快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生

- 慢开始：cwnd初始值为1，之后每收到一次确认应答，拥塞窗口的值就加1。发送数据包时，将拥塞窗口的大小与接收端主机通知的窗口大小做比较，然后按照它们当中较小的那个值，发送比其还要小的数据量。如果拥塞窗口大小超过慢启动阀值（在超时重发时，设置为当时拥塞窗口的一半），则按比例放大：

  > (1个数据段的字节数 / 拥塞窗口字节) * 1个数据段字节数

- 拥塞避免：拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送方的cwnd加1

- 快重传与快恢复：在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地⼯作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地⼯作

### 13. HTTP协议有什么组成

- 请求报文:
  1. 报文首部
     1. 请求行
     2. 请求首部字段
     3. 通用首部字段
     4. 实体首部字段
     5. 其他
  2. 空行（CR+LF）
  3. 报文主体
- 响应报文:
  1. 报文首部
     1. 状态行
     2. 响应首部字段
     3. 通用首部字段
     4. 实体首部字段
     5. 其他
  2. 空行（CR+LF）
  3. 报文主体

### 14. HTTP状态码

|      | 类别                             | 原因短语                   | 常见的状态码                                                 |
| ---- | -------------------------------- | -------------------------- | ------------------------------------------------------------ |
| 1XX  | Informational（信息状态码）      | 接收的请求正在处理         |                                                              |
| 2XX  | Success（成功状态码）            | 请求正常处理完毕           | 200 OK、204 No Content、206 Partial Content                  |
| 3XX  | Redirection（重定向状态码）      | 需要进行附加操作以完成请求 | 301 Moved Permanently、302 Not Found、303 See Other、304 Not Modified、307 Temporary Redirect |
| 4XX  | Client Error（客户端错误状态码） | 服务器无法处理请求         | 400 Bad Request、401 Unauthorized、403 Forbidden、404 Not Found |
| 5XX  | Server Error（服务器错误状态码） | 服务器处理请求出错         | 500 Internal Server Error、503 Service Unbelievable          |

### 15. HTTP报文的首部

- 通用首部字段

  | 通用首部字段名    | 说明                       |
  | ----------------- | -------------------------- |
  | Cache-Control     | 控制缓存的行为             |
  | Connection        | 逐跳首部、连接的管理       |
  | Date              | 创建报文的日期时间         |
  | Pragma            | 报文指令                   |
  | Trailer           | 报文末端的首部一览         |
  | Transfer-Encoding | 指定报文主体的传输编码方式 |
  | Upgrade           | 升级为其他协议             |
  | Via               | 代理服务器的相关信息       |
  | Warning           | 错误通知                   |

- 请求首部字段

  | 请求首部字段名      | 说明                                          |
  | ------------------- | --------------------------------------------- |
  | Accept              | 用户代理可处理的媒体类型                      |
  | Accept-Charset      | 优先的字符集                                  |
  | Accept-Encoding     | 优先的内容编码                                |
  | Accept-Language     | 优先的语言（自然语言）                        |
  | Authorization       | Web认证信息                                   |
  | Except              | 期待的服务器的特定行为                        |
  | From                | 用户的电子邮箱地址                            |
  | Host                | 请求资源所在服务器                            |
  | If-Match            | 比较实体标记（ETag）                          |
  | If-Modified-Since   | 比较资源的更新时间                            |
  | If-None-Match       | 比较实体标记（与If-Match相反）                |
  | If-Range            | 资源未更新时发送实体Byte的范围请求            |
  | If-Unmodified-Since | 比较资源的更新时间（与If-Modified-Since相反） |
  | Max-Forwards        | 最大传输逐跳数                                |
  | Proxy-Authorization | 代理服务器要求客户端的认证信息                |
  | Range               | 实体的字节范围请求                            |
  | Referer             | 对请求中URI的原始获取方                       |
  | TE                  | 传输编码的优先级                              |
  | User-Agent          | HTTP客户端程序的信息                          |

- 响应首部字段

  | 响应首部字段名     | 说明                         |
  | ------------------ | ---------------------------- |
  | Accept-Ranges      | 是否接受字节范围请求         |
  | Age                | 推算资源创建经过时间         |
  | ETag               | 资源的匹配信息               |
  | Location           | 令客户端重定向至指定URI      |
  | Proxy-Authenticate | 代理服务器对客户端的认证信息 |
  | Retry-After        | 对再次发起请求的时机要求     |
  | Server             | HTTP服务器的安装信息         |
  | Vary               | 代理服务器缓存的管理信息     |
  | WWW-Authenticate   | 服务器对客户端的认证信息     |

- 为Cookie服务的首部字段

  | 首部字段名 | 说明                           | 首部类型     |
  | ---------- | ------------------------------ | ------------ |
  | Set-Cookie | 开始状态管理所使用的Cookie信息 | 响应首部字段 |
  | Cookie     | 服务器接收到的Cookie信息       | 请求首部字段 |

- 其他首部字段

  | 首部字段名       | 说明                                             | 首部类型     |
  | ---------------- | ------------------------------------------------ | ------------ |
  | X-Frame-Options  | 控制网站内容在其他Web网站的Frame标签内的显示问题 | 响应首部字段 |
  | X-XSS-Protection | 针对跨站脚本攻击（XSS）的一种对策                | 响应首部字段 |
  | DNT              | 拒绝个人信息被收集                               | 请求首部字段 |
  | P3P              | 让个人隐私变成一种仅供程序可理解的形式           | 响应首部字段 |


### 16. 在浏览器中输⼊url地址到显示主页的过程

1. 浏览器查找域名的IP地址 DNS解析
2. TCP三次握手进行连接
3. 浏览器向Web服务器发送一个HTTP请求
4. 服务器处理请求，发回一个HTML响应
5. 浏览器开始显示HTML，解析渲染页面
6. 连接结束

### 17. MAC和IP

- 都具有唯一性,但IP具有层次性(IP由网络号和主机号组成,网络号相同,说明它们同处于一个网段.在组织结构,提供商类型和地域分布都比较集中)
- MAC寻址参考地址转发表(记录实际的MAC地址本身),IP寻址参考路由控制表(网络号和子网掩码)
- IP32位，MAC48位
- IP在网络层，MAC在数据链路层
- IP基于地理划分，MAC只和硬件设备有关

### 18. HTTP使用的认证方式

- BASIC认证（基本认证）
- DIGEST认证（摘要认证）
- SSL客户端认证
- FormBase认证（基于表单认证）

### 19. HTTP的缺点

- 通信使用明文,内容可能被窃听
- 不验证通信方的身份,因此有可能遭遇伪装
- 无法证明报文的完整性,所以有可能已遭篡改

### 20. HTTP 和 HTTPS 的区别

- HTTP默认端口是80，HTTPS默认端口是443
- HTTPS = HTTP + 加密 + 认证 + 完整性保护
- HTTPS 协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用
- 安全性和资源消耗：HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。HTTPS加密过程：使用非对称加密方式安全地交换在稍后的对称加密中要使用的密钥，确保交换的密钥是安全的前提下（就是去认证），使用对称密钥加密方式进行通信。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

### 21. 数字证书认证机构的业务流程

1. 服务器把自己的公开密钥登录至数字证书认证机构
2. 数字证书认证机构用自己的私有密钥向服务器的公开密码部署数字签名并颁发公钥证书
3. 客户端拿到服务器的公钥证书后，使用数字证书认证机构的公开密钥，向数字证书认证机构验证公钥证书上的数字签名，以确认服务器的公开密钥的真实性
4. 使用服务器的公开密钥对报文加密后发送
5. 服务器用私有密钥对报文解密

### 22. HTTPS通信步骤

1. 客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件(CipherSuite)列表(所使用的加密算法及密钥长度等)
2. 服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的
3. 之后服务器发送Certificate报文。报文中包含公开密钥证书
4. 最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束
5. SSL第一次握手结束之后，客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串。该报文已用步骤3中的公开密钥进行加密。
6. 接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密
7. 客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准
8. 服务器同样发送Change Cipher Spec报文
9. 服务器同样发送Finished报文
10. 服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求
11. 应用层协议通信，即发送HTTP响应
12. 最后由客户端断开连接。断开连接时，发送close_notify报文。
13. 之后再发送TCP FIN报文来关闭与TCP的通信

在以上流程中，应用层发送数据时会附加一种叫做MAC(Message Authentication Code)的报文摘要。MAC能够查知报文是否遭到篡改，从而保护报文的完整性。

### 23. 对称加密和非对称加密

- 对称（共享）加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等。缺点是密钥的管理与分配，换句话说，如何把密钥发送到需要解密你的消息的人的手里是一个问题
- 非对称（公开）加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等

### 24. get和post区别

- get把请求的数据放在url上，即HTTP协议头上。post把数据放在HTTP的包体内（requrest body）
- GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据)。POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
- GET在浏览器回退时是无害的，POST会再次提交请求
- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息

### 25. cookie和session的区别

- 存在的位置：cookie 存在于客户端，临时文件夹中； session存在于服务器的内存中，一个session域对象为一个用户浏览器服务
- 安全性：cookie是以明文的方式存放在客户端的，安全性低，可以通过一个加密算法进行加密后存放； session存放于服务器的内存中，所以安全性好
- 网络传输量：cookie会传递消息给服务器；session本身存放于服务器，不会有传送流量
- 生命周期(以20分钟为例)：cookie的生命周期是累计的，从创建时，就开始计时，20分钟后，cookie生命周期结束；session的生命周期是间隔的，从创建时，开始计时如在20分钟，没有访问session，那么session生命周期被销毁。但是，如果在20分钟内（如在第19分钟时）访问过session，那么，将重新计算session的生命周期。关机会造成session生命周期的结束，但是对cookie没有影响
- 访问范围：cookie为多个用户浏览器共享； session为一个用户浏览器独享

### 26. Session、Cookie在登录操作中的应用

1. 客户端把用户ID和密码等登录信息放入报文的实体部分，通常是以POST方法把请求发送给服务器。而这时，会使用HTTPS通信来进行HTML表单画面的显示和用户输入数据的发送
2. 服务器会发放用以识别用户的Session ID。通过验证从客户端发送过来的登录信息进行身份认证，然后把用户的认证状态与SessionID绑定后记录在服务器端。向客户端返回响应时，会在首部字段Set-Cookie内写入Session ID。必须防止Session ID被盗，或被猜出。为了做到这点，Session ID应使用难以推测的字符串，且服务器端也需要进行有效期的管理，保证其安全性。另外，为减轻跨站脚本攻击(XSS)造成的损失，建议事先在Cookie内加上httponly属性
3. 客户端接收到从服务器端发来的Session ID后，会将其作为Cookie保存在本地。下次向服务器发送请求时，浏览器会自动发送Cookie,所以Session ID也随之发送到服务器。服务器端可通过验证接收到的Session ID识别用户和其认证状态

## 操作系统

### 1. 进程和线程的区别

- 进程是CPU资源分配的最小单位，线程是CPU调度的最小单位
- 线程可以和属于同一个进程的其他线程共享这个进程的全部资源
- 一个进程包含多个线程，一个线程只能在一个进程之中。每一个进程最少包含一个线程
- 进程之间的切换开销比较大，但是线程之间的切换开销比较小
- 因为线程之间是共享同一个进程的，所以线程之间的通信几乎不需要系统的干扰

### 2. 进程间通信方式

1. 管道
2. 命名管道
3. 消息队列
4. 共享内存
5. 信号量
6. 套接字Socket
7. 信号

### 3. 线程通信方式

1. 锁机制：包括互斥锁、条件变量、读写锁。互斥锁提供了以排他方式防止数据结构被并发修改的方法。读写锁允许多个线程同时读共享数据，而对写操作是互斥的。条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
2. 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
3. 信号机制(Signal)：类似进程间的信号处理。线程间的通信目的主要是用于线程同步，所以线程没有像进程
   通信中的用于数据交换的通信机制。

### 3. 线程有哪几种状态

- 创建状态(new) ：进程正在被创建，尚未到就绪状态。
- 就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- 运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- 阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- 结束状态(terminated)：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

### 4. 线程间的同步方式

1. 互斥量（Mutex）：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的synchronized 关键词和各种 Lock 都是这种机制。
2. 信号量（Semphares）：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. 事件（Event）：Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较

### 5. 进程的调度算法

1. 先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进⼊该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
2. 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
3. 时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间
4. 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级
5. 多级反馈队列调度算法：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法

### 6. 什么是虚拟内存

- 虚拟内存使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等


### 7. 内存管理机制

- 块式管理：将内存分为几个固定大⼩的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很⼩的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片
- 页式管理：把主存分为大⼩相等且固定的一页一页的形式，页较⼩，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址
- 段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间⼩很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、⼦程序段X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址
- 段页式管理：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页

### 8. 什么是死锁

指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进

### 9. 产生死锁的原因

1. 竞争资源
   1.  竞争不可剥夺资源
   2. 竞争临时资源
2. 进程间推进顺序非法

### 10. 死锁产生的必要条件

1. 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用
2. 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放
3. 不可剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放
4. 环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链

### 11. 死锁预防

1. 资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）
2. 只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏请求保持条件）
3. 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
4. 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

### 12. 避免死锁

- 银行家算法：在分配资源之前先看清楚，资源分配后是否会导致系统死锁

### 13. 死锁的解除

- 抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以解除死锁状态
- 终止或者撤销进程。终止或者撤销系统中的一个或多个死锁进程，直到打破循环环路，使系统从死锁状态解脱出来

## Java基础

### 1. Object类有哪些方法

- getClass：获取类的Class对象
- hashCode：获取对象的hashCode值
- equals：比较对象是否相等，比较值和地址
- clone：浅拷贝，使用时要实现java.lang.Cloneable接口，比如A和B都有一个成员变量是X，B是Aclone出来的，改变X，A和B的都改变
- toString：返回字符串包括该对象的类名称，"@"字符以及该对象的哈希码的无符号十六进制表示形式，一般会被重写
- finalize：在垃圾回收之前被执行，可以通过重写finalize方法来重置系统资源，执行清理活动并且最大程度的减少内存泄露，JDK9之后不用了
- wait：让当前线程进入等待序列
- wait(long timeout)：在其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量前，导致当前线程等待
- wait(long timeout, int nanos)：在其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量前，导致当前线程等待
- notify：该方法唤醒在该对象上等待的某个线程
- notifyAll：该方法唤醒在该对象上等待的所有线程

### 2. 接口和抽象类的区别

- 相同点
  1. 都不能被实例化
  2. 接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化
- 不同点
  1. 接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现
  2. 实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承
  3. 接口强调特定功能的实现，而抽象类强调所属关系
  4. 接口成员变量默认为public static final，必须赋初值，不能被修改；其所有的成员方法都是public、abstract的。抽象类中成员变量默认default，可在子类中被重新定义，也可被重新赋值；抽象方法被abstract修饰，不能被private、static、synchronized和native等修饰，必须以分号结尾，不带花括号

### 3. 什么时候用抽象类，什么时候用接口

抽象类：强调的是把共同(共有、相同)的属性方法， 抽象出来，统一写在一个地方（他们的实现代码是一样的），方便维护。（面向对象三大特性中的继承特性）

接口： 抽象的是行为 - 同一种行为的不同实现方式。当多个对象都拥有相同的行为，但是行为的具体实现方式不一样的时候可以用接口抽象（面向对象中的多态特性）

例如：所有的订单都有单号，单价，数量。都拥有，而且相同，所以可以用一个抽象类给统一描述出来。

所有的订单都需要支付，但是支付方式又不一样比如，微信支付，支付宝支付，同一种行为，但是具体的行为方式又不一样。所以用一个接口给抽象出来（规定一个行为标准）

### 4. ==和equals

- ==：基础数据类型：比较的是他们的值是否相等，比如两个int类型的变量。引用数据类型：比较的是引用的地址是否相同，比如说新建了两个User对象，比较的是两个User的地址是否一样。

- equals：Object类的源码里比较的是地址。但是像String这里面的会被重写。

- 实例：

  ```java
  String str1 = "Hello";
  String str2 = new String("Hello");
  String str3 = str2; // 引用传递
  System.out.println(str1 == str2); // false
  System.out.println(str1 == str3); // false
  System.out.println(str2 == str3); // true
  System.out.println(str1.equals(str2)); // true
  System.out.println(str1.equals(str3)); // true
  System.out.println(str2.equals(str3)); // true
  ```

- 上面实例的内存解释：String str1 = "Hello";会在堆区存放一个字符串对象"hello"(1)，然后栈里有str1指向它(1)。String str2 = new String("Hello");会在堆区再次存放一个字符串对象"hello"(2)，然后栈里有str2指向它(2)。String str3 = str2;栈里会有一个str3，指向"hello"(2)。==比较地址，equals比较值。

- 延申：

  ```java
  String s1 = "Hello";
  String s2 = new String("Hello");
  s2 = s2.intern();
  System.out.println(s1 == s2);       //  true
  System.out.println(s1.equals(s2));  //  true
  ```

- 在这里多了一个intern方法，他的意思是检查字符串池里是否存在。String s1 = "Hello";会在堆区存放一个字符串对象"hello"。s2调用intern()方法时，因为字符串里已经有了，所以就直接把s2指向它就行了。所以s1和s2指向同一个。

### 5. 为什么重写equals()，必须要重写hashCode()

- 两个对象equals相等，那么他们hashCode一定也相同
- 两个对象hashCode相等，equals不一定相等
- 通常只要我们重写 equals方法就要重写 hashCode方法
- 如果不重写，在使用HashMap，HashTable时，是根据hashCode来判断的。假如说User类重写equals，只要类型相等，name相同，就返回true。那么User u1 = new User("abc");User u2 = new User("abc");这俩作为key往hashMap里put时，不会有覆盖。当我们重写了hashCode让User的name作为计算的值，用来产生最终的hash值，这样HashMap就可以帮我们把两个对象，路由到一个下标下面了，再通过equals比对，确定两个是同一个对象，从而达到去重的效果。

### 6. sleep()和wait()的区别

- 这两个方法来自不同的类分别是，sleep来自Thread类，和wait来自Object类
- 最主要是sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法
- 使用范围：wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用
- sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常

### 7. Java泛型是什么？使用泛型有什么好处

- 在集合中存储对象并在使用前进行类型转换非常不方便。泛型防止了那种情况的发生。它提供了编译期的类型安全，确保你只能把正确类型的对象放入集合中，避免了在运行时出现ClassCastException。

### 8. Java泛型是如何工作的

- 泛型是通过类型擦除来实现的，编译器在编译时擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息。例如List<String>在运行时仅用一个List来表示。这样做的目的，是确保能和Java 5之前的版本开发二进制类库进行兼容。你无法在运行时访问到类型参数，因为编译器已经把泛型类型转换成了原始类型。

### 9. 什么是泛型中的限定通配符和非限定通配符

- 限定通配符对类型进行了限制。有两种限定通配符，一种是<? extends T>它通过确保类型必须是T的子类来设定类型的上界,不能add只能get。要用的话只能封装一个方法，方法参数可以是子类
- 另一种是<? super T>它通过确保类型必须是T的父类来设定类型的下界。泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误。例子： List<? super Person> list = new ArrayList<>(); 只能往里面addPerson类和其子类和null。反而父类放不进去。只能add不能get。要用的话只能封装一个方法，方法参数可以是父类。
- 另一方面<?>表示了非限定通配符，因为<?>可以用任意类型来替代。

### 10. 什么是反射

- 反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。

### 11. 获取Class对象的方式

1. 第一种方法通过类的全路径字符串获取 Class 对象，这也是我们平时最常用的反射获取 Class 对象的方法；

   ```java
   Class studentClass = Class.forName("com.test.reflection.pojo.Student");
   ```

2. 第二种方法有限制条件：需要导入类的包；

   ```java
   Class studentClass2 = Student.class;
   ```

3. 第三种方法已经有了 Student 对象

   ```java
   Student studentObject = new Student();
   Class studentClass3 = studentObject.getClass();
   ```
   
4. 第四种方法类加载器

   ```java
   Class studentClass4 = Main.getClassLoader().loadClass("com.test.reflection.pojo.Student");
   ```

### 12. 如何利用反射创建对象

- 使用Class对象的newInstance()方法创建该Class对象的实例，要求必须要有无参数的构造方法
- 使用Class对象获取指定的Constructor对象，再调用Constructor的newInstance()方法创建对象类的实例，此时可以选择使用某个构造方法。如果这个构造方法被私有化起来，那么必须先申请访问，将可以访问设置为true(setAccessible(boolean flag))

### 13. Java内置注解

- @Override：java.lang.Override中，只适用于修饰方法，表示一个方法声明打算重写超类中的另一个方法声明

- @Deprecated：java.lang.Deprecated中，可以用于修饰方法、属性、类，表示不鼓励程序员使用这样的元素

- @SuppressWarnings：java.lang.SuppressWarnings中，用来抑制编译时的警告信息。这个注解使用的时候需要参数，比如：

  ```java
  @SuppressWarnings("all")
  
  @SuppressWarnings("unchecked")
  
  @SuppressWarnings(value = {"unchecked", "deprecation"})
  ```

### 14. Java的元注解 

- 元注解的作用就是负责注解其他注解，Java定义了4个标准的meta-annotation类型，他们被用来提供对其他annotation类型做说明。他们都在java.lang.annotation包下。
- @Target：用于描述注解的使用范围
- @Retention：表示需要在什么级别保持该注解信息。(SOURCE < CLASS < RUNTIME)
- @Document：说明该注解将被包含在javadoc中
- @Inherited：说明子类可以父类中的该注解

### 15. Exception和Error有什么区别

- Exception 和 Error 都是继承了 Throwable 类，在 Java 中只有 Throwable 类型的实例才可以被抛出（throw）或者捕获（catch），它是异常处理机制的基本组成类型。
- Exception 和 Error 体现了 Java 平台设计者对不同异常情况的分类。Exception 是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。Error 是指在正常情况下，不大可能出现的情况，绝大部分的 Error 都会导致程序（比如 JVM 自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如 OutOfMemoryError 之类，都是 Error 的子类。
- Exception 又分为可检查（checked）异常和不检查（unchecked）异常，可检查异常在源代码里必须显式地进行捕获处理，这是编译期检查的一部分。Error，是 Throwable 不是 Exception。不检查异常就是所谓的运行时异常，类似 NullPointerException、ArrayIndexOutOfBoundsException 之类，通常是可以编码避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。

### 16. 异常处理的基本原则

- 尽量不要捕获类似Exception这样的通用异常,而是应该捕获特定异常
- 不要生吞(swallow)异常

### 17. final、finally、finalize有什么不同

- final 可以用来修饰类、方法、变量，分别有不同的意义，final 修饰的 class 代表不可以继承扩展，final 的变量是不可以修改的，而 final 的方法也是不可以重写的（override）。
- finally 则是 Java 保证重点代码一定要被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭 JDBC 连接、保证 unlock 锁等动作。
- finalize 是基础类 java.lang.Object 的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize 机制现在已经不推荐使用，并且在 JDK 9 开始被标记为 deprecated。

### 18. String、StringBuffer、StringBuilder有什么区别

- String 是 Java 语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的 Immutable 类，被声明成为 final class，所有属性也都是 final 的。
- StringBuffer 是为解决上面提到拼接产生太多中间对象的问题而提供的一个类，我们可以用 append 或者 add 方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer 本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，所以除非有线程安全的需要，不然还是推荐使用它的后继者，也就是 StringBuilder。
- StringBuilder 在能力上和 StringBuffer 没有本质区别，但是它去掉了线程安全的部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。
- 在字节码层面，String在字符串拼接时，会new一个StringBuilder进行拼接。而StringBuilder由于之前new了，只需要调用append方法就行。

### 19. String str1 = "abc"; String str2 = new String ("abc"); 输出str1 == str2结果是什么

- false。str1和str2是引用类型，比较地址，前面str1引用的"abc"是常量池的，后者str2引用的是堆中的。地址不同。
- 可以调用intern()方法，如果常量池有，就直接引用它，没有就缓存起来。JDK1.6之前，少用这个方法，因为他们缓存在了永久代，使用不当会OOM。1.8之后，方法区由元空间实现，基本上问题解决了。
- 无论在哪里，使用String s = "a"; ==的结果都是ture。(静态变量和局部变量比，成员变量和局部变量比等等)

### 19. 重写和重载的区别

- 重写实现的是运行时的多态，而重载实现的是编译时的多态
- 重写的方法参数列表必须相同；而重载的方法参数列表必须不同
- 重写是父类与子类之间，重载是在一个类中
- 重写的方法的返回值类型只能是父类类型或者父类类型的子类，访问修饰符的限制一定要大于被重写方法的访问修饰符（public>protected>default>private)，而重载的方法对返回值类型没有要求

## Java集合

### 1. arraylist和linkedlist的区别

- ArrayList的实现是基于数组，连续的一块内存空间，LinkedList的实现是基于双向链表，不需要连续的空间
- 对于随机访问，ArrayList优于LinkedList，ArrayList可以根据下标以O(1)时间复杂度对元素进行随机访问。而LinkedList的每一个元素都依靠地址指针和它后一个元素连接在一起，在这种情况下，查找某个元素的时间复杂度是O(n)
- 对于插入和删除操作，LinkedList优于ArrayList，因为当元素被添加到LinkedList任意位置的时候，不需要像ArrayList那样重新计算大小或者是更新索引
- LinkedList比ArrayList更占内存，因为LinkedList的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素
- ArrayList扩容：新数组长度是原来的1.5倍(用移位操作)，然后用Arrays.copyOf将数组的元素复制到新数组

### 2. Arrays.asList(a).toArray == Object[].class结果是什么?

- false，这是1.8的一个Bug

### 3. HashMap的底层数据结构

- JDK7，数组+链表组成。链表是为了解决哈希冲突。加入数据时用头插法
- JDK8，数组+链表+红黑树组成。加入数据是尾插法
  - 链表超过8且数据总量超过64就会转成红黑树
  - 不超过64就扩容

### 4. 为什么不直接用红黑树？而选择先用链表，再转红黑树

- 因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于 8 个的时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于 8 个的时候， 红黑树搜索时间复杂度是 O(logn)，而链表是 O(n)，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了

### 5. 为什么链表改为红黑树的阈值是 8

理想情况下使用随机的哈希码，容器中节点分布在 hash 桶中的频率遵循泊松分布。个数为8的时候概论已经很小了

### 6. HashMap默认加载因子是多少？为什么是 0.75，不是 0.6 或者 0.8 ？

默认的loadFactor是0.75，0.75是对空间和时间效率的一个平衡选择，一般不要修改，除非在时间和空间比较特殊的情况下 ：

- 如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值 。
- 相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1

### 7. HashMap 中 key 的存储索引是怎么计算的

1. 取key的 hashCode 值
2. 根据 hashcode 计算出hash值（高16位异或低16位）
3. 通过取模计算下标（数组长度是2的幂次方，进行与操作非常方便）

### 8. HashMap的put方法流程

1. 首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标
2. 如果数组是空的，则调用 resize 进行初始化
3. 如果没有哈希冲突直接放在对应的数组下标里
4. 如果冲突了，且 key 已经存在，就覆盖掉 value
5. 如果冲突后，发现该节点是红黑树，就将这个节点挂在树上
6. 如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；否则，链表插入键值对，若 key 存在，就覆盖掉 value
7. JDK1.7版本就是先判断是不是需要扩容，不扩容就头插法

### 9. HashMap的扩容

只需要看看原来的 hash 值新增的那个bit是1还是0就好了，是0的 话索引没变，是1的话索引变成原索引 + oldCap

### 10. 解决Hash冲突

1. 开放地址法 
2. 再哈希法
3. 链地址法
4. 建立公共溢出区

### 11. 说说ConcurrentHashMap

- 1.7：采用锁分段机制，将数据分成Segment数据段，给每一个数据段配一把锁。扩容的时候是被锁保护的。put时，先tryLock，如果返回true，则node=null，否则执行scanAndLockForPut方法（预先创建node，如果拿到锁就返回node）。接着获取所在HashEntry链表index的head，如果next=null，则初始化node，头插法，检查扩容。如果next！=null，则检查node key是不是相同，否就再去判断next是不是等于null，是就覆盖当前node。
- 1.8：取消分段锁，采用CAS进行值的设置，如果CAS失败再使用synchronized加锁添加元素

## JVM

### 1. 什么是JVM内存结构

- **程序计数器**：程序计数器是一块很小的内存空间，用于存储字节码的指令地址，提供给执行引擎去取指执行。（线程私有，无内存溢出问题）
- **虚拟机栈**：描述java方法执行过程的内存模型，每个方法执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态连接、返回地址等信息，当线程请求的栈深度超过了虚拟机允许的最大深度时，就会抛出StackOverFlow的异常。（线程私有，描述java方法的执行过程）
- **本地方法栈**：本地方法区和虚拟机栈的作用类似，区别是虚拟机栈为执行 Java 方法服务，本地方法栈为 Native 方法服务。（线程私有）
- **堆**：在 JVM 运行过程中创建的对象和产生的数据都被存储在堆中，堆是被线程共享的内存区域，也是垃圾收集器进行垃圾回收的最主要的内存区域。（线程共享）
- **方法区**：jdk8以前方法区是由永久代实现的，存储类的元信息，常量池，静态变量等，jdk8以后，方法区由元空间实现，存储类的元信息等，常量池、静态变量存储在堆中（线程共享）

### 2. JVM内存分配与回收策略

1. 对象优先分配在Eden区。new出来的对象都放在堆内存里，JVM将堆分为新生代和老年代。新生代8/10是Eden区，1/10是ServivorFrom区，1/10是ServivorTo区。Eden区空间不足会发起一次minor GC。
2. 大对象直接进入老年代。JVM参数：-XX:PretenureSizeThreshold（只在Serial和ParNew两个收集器下有效）
3. 长期存活的对象将进入老年代。若Servivor区的对象经过一次GC存活下来，则其年龄加一，默认到15进入老年代。
4. Minor GC后存活的对象Survivor区放不下，则部分去老年代，部分放在Survivor区。
5. Eden、SurvivorFrom与SurvivorTo区默认比例8:1:1。如果Eden区满了，就进行minor GC，存活的对象放进Survivor区。
6. 对象动态年龄判断。如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。
7. 老年代空间分配担保机制。在MinorGC之前，判断老年代剩余可用空间是否小于年轻代里现有的所有对象大小之和，没有，就进行minorGC，如果是，就看是否配置担保参数：-xx:-HandlePromotionFailure，没有就直接FullGC，如果配置了，就判断老年代剩余可用空间是否小于之前每次minorGC后进入老年代的对象平均大小，否就进行minorGC，是就进行FullGC。

### 3. minor GC和Full GC有什么不同

1. minor GC/Young GC：指放生在新生代的垃圾收集动作。非常频繁，且速度很快
   - eden区满了，在new对象时，就会触发
   - eden和from存活对象移动到to，年龄+1
   - 将eden和from回收
   - 将原来的from和to名字交换
2. Major GC/Full GC：一般会回收老年代，年轻代，方法区的垃圾，速度很慢
   - 老年代满了，就会触发

### 4. 如何确定垃圾

- **引用计数法**：在为对象添加一个引用时，引用计数加 1；在为对象删除一个引用时，引进计数减 1；如果一个对象的引用计数为 0，则表示此刻该对象没有被引用，可以被回收。（循环引用问题）
- **可达性分析**：首先定义一些 GC Roots 对象（哪些可以作为GC Roots对象：栈帧本地变量表、方法区常量池、方法区静态属性、活跃线程引用对象、本地方法栈JNI对象），然后以这些 GC Roots 对象作为起点向下搜索，如果在 GC roots 和一个对象之间没有可达路径，则称该对象是不可达的。不可达对象要经过至少两次标记才能判定其是否可以被回收，如果在两次标记后该对象仍然是不可达的，则将被垃圾收集器回收。

### 5. java中常见的垃圾回收算法

1. **标记清除算法**：其过程分为标记和清除两个阶段。在标记阶段利用可达性遍历内存，标记所有需要回收的对象，在清除阶段清除可回收的对象并释放其所占用的内存空间。（有碎片）
2. **复制算法**：复制算法首先将内存划分为两块大小相等的内存区域，即区域 1 和区域 2，新生成的对象都被存放在区域 1 中，在区域 1 内的对象存储满后会对区域 1 进行一次标记，并将标记后仍然存活的对象全部复制到区域 2 中，这时区域 1 将不存在任何存活的对象，直接清理整个区域 1 的内存即可。（清理效率高，易实现，不适合有大量存活久的对象）
3. **标记整理算法**：在标记完成后将存活的对象移到内存的另一端，然后清除该端的对象并释放内存。（结合了标记清除算法和复制算法的优点）
4. **分代收集算法**：JVM将堆分为新生代和老年代。新生代8/10是Eden区，1/10是ServivorFrom区，1/10是ServivorTo区。新生代使用复制算法（新生代需要复制的对象少），进行垃圾回收时会将在 Eden 区和 ServivorFrom 区中存活的对象复制到 ServivorTo 区，然后清理 Eden 区和 ServivorFrom 区的内存空间。老年代使用标记清除算法或标记整理（老年代主要是生命周期长的对象和大对象）。还有一个区域，即方法区的永久代，永久代用来存储 Class 类、常量、方法描述等。在永久代主要回收废弃的常量和无用的类。新生代使用复制算法时，如果ServivorTo区空间不够，则直接进入老年区。若Servivor区的对象经过一次GC存活下来，则其年龄加一，默认到15进入老年代。还有对象动态年龄判断机制,如果form区年龄总和超过survivor区的50%，就进入老年代。

### 6. JVM垃圾收集器

- Serial：单线程收集器。新生代采用复制算法，老年代采用标记-整理算法。简单而高效
- Serial Old：单线程收集器。在JDK1.5及以前与Parallel Scavenge收集器搭配使用。或者作为CMS收集器的后备方案
- parNew收集器：Serial收集器的多线程版本。新生代采用复制算法，老年代采用标记-整理算法。默认线程数和cpu数相同。运行在Server模式下的虚拟机的首要选择。除了Serial收集器外，只有它能与CMS收集器配合工作
- Parallel Scavenge收集器：是Server模式下的默认收集器。新生代采用复制算法，老年代采用标记-整理算法。高效率的利用CPU。在优化比较困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机完成。
- Parllel Old收集器：使用多线程，标记-整理算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑Parallel Scavenge收集器和Parllel Old收集器。
- CMS收集器（老年代）：以获取最短回收停顿时间为目标的收集器。HotSpot虚拟机第一款真正意义上的并发收集器。标记-清除算法。优点：并发收集、低停顿。缺点：对CPU资源敏感，无法处理浮动垃圾，使用标记-清除算法，会有大量空间碎片。执行过程中的不确定性，会存在上一次垃圾回收还没执行完，然后垃圾回收又被触发的情况。过程：
  1. 初始标记：stop-the-world，仅仅标记GC Roots能直接关联到的对象，速度很快。
  2. 并发标记：从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但不需要停顿用户线程。
  3. 重新标记：stop-the-world，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。
  4. 并发清除：清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。
- G1收集器：
  1. G1垃圾收集器将整个JVM内存分为多个大小相等的region,年轻代和老年代逻辑分区 
  2. G1是Java9以后的默认垃圾回收器了
  3. G1在整体上使用标记整理算法，局部使用复制算法
  4. G1的每个Region大小在1-32M之间，可以通过-XX:G1HeapRegionSize=n指定区大小
  5. 总的Region个数最大可以存在2048个，即heap最大能够达到32M\*2048=64G
  6. 0.5<obj<1,那么放到old区，old标记为H
  7. 1<obj<n,连续的n个region,作为H
  8. G1 mixGC的过程
     - 初始标记：标记出GCRoot对象，以及GCRoot所在的Region(RootRegion)
     - Root Region Scanning:扫表整个old的Region
     - 并发标记：并发追溯标记，进行GCRootsTracing的过程
     - 最终标记：修正并发标记期间，因程序运行导致标记发生变化的那一部分对象
     - 清理回收：根据时间来进行价值最大化的回收，重置rset

### 7. java中的引用类型

1. 强引用：在 Java 中最常见的就是强引用。在把一个对象赋给一个引用变量时，这个引用变量就是一个强引用。有强引用的对象一定为可达性状态，所以不会被垃圾回收机制回收。因此，强引用是造成 Java 内存泄漏（Memory Link）的主要原因。
2. 软引用：软引用通过 SoftReference 类实现。如果一个对象只有软引用，则在系统内存空间不足时该对象将被回收。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。
3. 弱引用：弱引用通过 WeakReference 类实现，并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系，如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择。
4. 虚引用(幻象引用)：虚引用通过 PhantomReference 类实现，你不能通过它访问对象。虚引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制，比如，通常用来做所谓的 Post-Mortem 清理机制，java平台自身Cleaner机制等。也有人利用虚引用监控对象的创建和销毁。

### 8. JVM的类加载机制

1. 加载：读取Class文件，将其转化为某种静态数据结构存储在方法区内，并在堆中生成一个便于用户调用的java.lang.Class类型的对象
2. 验证：(元数据、字节码验证)对Class静态结构进行语法和语义分析，保证其不会产生危害虚拟机的行为
3. 准备：主要工作是在方法区中为类变量分配内存空间并设置类中静态变量的默认值。初始值指不同数据类型的默认值，这里需要注意 final 类型的变量（给的值）和非 final 类型的变量（默认值）在准备阶段的数据初始化过程不同。
4. 解析：符号引用替换为直接引用。(A引用了B，在编译阶段，A不知道B有没有编译，B此时也没有被加载，A不知道B的实际地址，所以用一个字符串S来代表B的地址，S就是符号引用。在运行时，如果A发生了类加载，到解析阶段，发现B还未加载，就会触发B的类加载，将B加载到虚拟机中，此时A中B的符号引用将会被替换成B的实际地址，这就是直接引用。如果A调用B是一个具体的实现类，那么就称为静态解析，而如果使用了多态，B可能是一个抽象类或者接口，B可能有两个具体的实现类C和D，这个时候不会替换，等到运行过程中发生了调用，此时虚拟机调用栈中将会得到具体的类型信息，这时再进行解析。这也是为啥有时候解析会发生在初始化之后，这就是动态解析)
5. 初始化：会判断代码中是否存在主动的资源初始化操作。比如成员变量的赋值动作，静态变量的赋值动作，以及静态代码块的逻辑。只有显式的调用new，才会调用构造函数，进行对象的实例化。

### 9. 什么情况下JVM不会执行类的初始化流程 

- 常量在编译时会将其常量值存入使用该常量的类的常量池中，该过程不需要调用常量所在的类，因此不会触发该常量类的初始化
- 在子类引用父类的静态字段时，不会触发子类的初始化，只会触发父类的初始化
- 定义对象数组，不会触发该类的初始化
- 在使用类名获取 Class 对象时不会触发类的初始化
- 在使用 Class.forName 加载指定的类时，可以通过 initialize 参数设置是否需要对类进行初始化
- 在使用 ClassLoader 默认的 loadClass 方法加载类时不会触发该类的初始化。

### 10. JVM的类加载器

- 启动类加载器：负责加载 Java_HOME/lib 目录中的类库，或通过-Xbootclasspath 参数指定路径中被虚拟机认可的类库
- 扩展类加载器：负责加载 Java_HOME/lib/ext 目录中的类库，或通过 java.ext.dirs 系统变量加载指定路径中的类库
- 应用程序类加载器：负责加载用户路径（classpath）上的类库。
- 除了上述 3 种类加载器，我们也可以通过继承 java.lang.ClassLoader 实现自定义的类加载器。

### 11. 双亲委派机制

- 双亲委派机制指一个类在收到类加载请求后不会尝试自己加载这个类，而是把该类加载请求向上委派给其父类去完成，其父类在接收到该类加载请求后又会将其委派给自己的父类，以此类推，这样所有的类加载请求都被向上委派到启动类加载器中。若父类加载器在接收到类加载请求后发现自己也无法加载该类（通常原因是该类的 Class 文件在父类的类加载路径中不存在），则父类会将该信息反馈给子类并向下委派子类加载器加载该类，直到该类被成功加载，若找不到该类，则 JVM 会抛出 ClassNotFoud 异常。

### 12. 创建出来的对象放在哪儿

- 大部分放在堆里面
- 没有方法逃逸的对象，直接栈上分配
- 没有线程逃逸，可以进行syn擦除，同步擦除策略
- 标量替换优化，替换的聚合量

### 13. 对象空间的内存分配

- 指针碰撞法。使用过的空间在一边，空闲的在另一边，中间是指针。该方法适用于GC后没有碎片。
- 空闲列表。维护一个列表记录哪些内存块可用。分配时，从列表找一个足够大的空间划分给对象实例，并更新列表上的记录。
- 解决线程安全：
  - 一种是对分配内存空间的动作进行同步处理，实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性。
  - 另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在java堆中预先分配一小块内存，称为本地线程分配缓冲

## Java多线程

### 1. java如何开启线程

1. 继承Thread类、重写run()方法
2. 实现Runnable接口，实现run()方法
3. 实现Callable接口，实现call()方法，通过FutureTask创建一个线程，可以获得返回值
4. 创建线程池

### 2. 怎么保证线程安全

1. 使用JUC下面的类
2. 使用Synchronized关键字
3. 使用JDK提供的各种Lock

### 3. Volatile关键字作用

- 内存可见性：所有线程都能看到共享内存的最新状态
- 防止指令重排：在new一个对象时，会执行分配内存，初始化对象，然后这个变量指向内存。如果发生指令重排，执行顺序是132，执行到第3的时候，线程B刚好进来了，并且执行到注释2，这时候判断mInstance 不为空，直接使用一个未初始化的对象。

### 3. Volatile和Synchronized有什么区别

- synchronized通过加锁的方式，可以在需要原子性、可见性和有序性这三种特性的时候都可以作为其中一种解决方案
- volatile通过在volatile变量的操作前后插入内存屏障的方式，保证了变量在并发场景下的可见性和有序性
- volatile关键字是无法保证原子性的，而synchronized通过monitorenter和monitorexit两个指令，可以保证被synchronized修饰的代码在同一时间只能被一个线程访问，即可保证不会出现CPU时间片在多个线程间切换，即可保证原子性
- volatile是Java虚拟机提供的一种轻量级同步机制，不是锁。而Synchronized会有阻塞和性能损耗的问题
- Volatile能防止指令重排

### 4. 对AQS的理解。AQS如何实现可重入锁

- AQS的成员属性：

  - state：资源是否被占用的标记位，volatile保证线程可见性，int，可以在共享模式下由多个线程占用
  - head、tail：头尾节点，封装的一个内部类Node(prev、next、waiter、status)，未拿到资源的线程排队的双向链表

- AQS的核心方法：

  - protected boolean tryAcquire(int arg)：被protect修饰，参数是int，代表对state的修改，返回是boolean，代表是否成功获得锁。该方法只有一行，就是抛出异常。很明显要继承AQS重写这个方法。比如：

    ```java
    class Syncer extends AbstractQueuedSynchronizer {
    	@Override
    	protected boolean tryAcquire(int arg) {
    		if (arg != 1) {
    			return false;
    		}
    		if (getState() == 1) {
    			return false;
    		}
    		return compareAndSetState(0, 1);
    	}
    }
    ```

  - public final void acquire(int arg) ：不允许重写，调用之后一定获得锁。先调用tryAcquire，如果不行就调用acquire的重载方法。然后进行尝试获取锁，入队，修改status等操作。acquireQueued这个方法，如果当前线程所在节点处于头节点后面一个，就会不断尝试拿锁，直到成功。如果不是头节点，则判断是不是需要挂起，如果之前节点不是头节点并且状态是singal，则需要挂起。

  - protected boolean tryRelease(int arg) ：和tryAcquire差不多，需要重写

  - public final boolean release(int arg)：尝试释放成功，就要唤醒等待队列的其他节点。先把自己设置为head，然后从尾到头找第一个head，然后去自旋拿锁。

### 5. A、B、C三个线程，如何保证三个线程同时执行？如何在并发情况下保证三个线程依次执行？如何保证三个线程有序交错进行？

- 同时执行：使用CountDownLatch类，初始化时为1。让这三个线程都await()，然后主线程里调用countDown()，三个线程就同时进行了
- 依次执行：volatile修饰一个变量，每个线程都要判断，做完任务之后，修改这个变量，让下一个线程满足条件
- 有序交错执行：定义一个信号量int number；然后private Lock lock = new ReentrantLock();然后private Condition conditionA = lock.newCondition();。。。线程里执行的时候就是lock.lock(); while(numer!=0){conditionA.await();}改变信号量，唤醒下一个线程conditionB.signal();最后lock.unlock()

### 6. 说说几种常见的线程池及使用场景

- newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行
- newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待
- newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程
- newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行

### 7. 线程池的参数

- corePoolSize：核心池的大小
- maximumPoolSize：线程池最大线程数
- keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止
- unit：参数keepAliveTime的时间单位
- workQueue：一个阻塞队列，用来存储等待执行的任务
- threadFactory：用于设置创建线程的工厂
- handler：表示当拒绝处理任务时的策略，有以下四种取值：1、AbortPolicy：直接抛出异常。2、CallerRunsPolicy：只用调用者所在线程来运行任务。3、DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。4、DiscardPolicy：不处理，丢弃掉。

### 8. CAS实现原子性操作

- 读取旧值为一个临时变量
- 对旧值的临时变量进行操作或者依赖旧值临时变量进行一些操作
- 判断旧值临时变量是不是等于旧值,等于则没被修改,那么新值写入.不等于则被修改,此时放弃或者从步骤1重试

### 9. ABA问题

- ABA问题指的是多个线程同时执行,那么开始时其获得的值都是A,当一个线程修改了A为B,第二个线程修改了B为A,那么第三个线程修改时判断A仍然是A,认为其没有修改过,因此会CAS成功

- 在JDK1.5之后提供了`AtomicStampedReference`类来解决ABA问题,解决思路是保存元素的引用,引用相当于版本号,是每一个变量的标识,因此在CAS前判断下是否是同一个引用即可

### 10. CAS应用题。三个线程将一个值累加到100。

```java
// 1.错误写法
public class Main {
    static Integer num = 0;
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++) {
            new Thread(() -> {
                while (num < 1000) {
                    System.out.println("thread name:" + Thread.currentThread().getName() + ":" + num++);
                }
            }).start();
        }
    }
}

// 2.原子类
public class Main {
    static AtomicInteger num = new AtomicInteger(0);
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++) {
            new Thread(() -> {
                while (num.get() < 1000) {
                    System.out.println("thread name:" + Thread.currentThread().getName() + ":" + num.incrementAndGet());
                }
            }).start();
        }
    }
}
```

### 11. synchronized与ReentrantLock的区别

- 底层实现上来说，synchronized 是JVM层面的锁，是Java关键字，通过monitor对象来完成（monitorenter与monitorexit），对象只有在同步块或同步方法中才能调用wait/notify方法，ReentrantLock 是从jdk1.5以来（java.util.concurrent.locks.Lock）提供的API层面的锁
- synchronized 不需要用户去手动释放锁，ReentrantLock则需要用户去手动释放锁
- synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成； ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断
- synchronized为非公平锁 ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁
- synchronized不能绑定； ReentrantLock通过绑定Condition结合await()/singal()方法实现线程的精确唤醒
- synchronized锁的是对象，锁是保存在对象头里面的，根据对象头数据来标识是否有线程获得锁/争抢锁；ReentrantLock锁的是线程，根据进入的线程和int类型的state标识锁的获得/争抢
- synchronized的阻塞队列是头插法，ReentrantLock的是尾插法

### 12. 并发操作三大特性

1. 原子性：一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行
2. 可见性：可见性指当一个线程修改了共享变量时，其他线程能够立即得知修改。volatile、synchronized、final 关键字都能保证可见性
3. 有序性：虽然多线程存在并发和指令优化等操作，但在本线程内观察该线程的所有执行操作是有序的

### 13. Java的对象结构

- 对象头：Mark Word(和运行时状态有关的数据)、Class Point(指向当前对象类型所在方法区中的类型数据)
- 实例数据：初始化对象时，设置的属性，方法等
- 填充字节：保证对象大小是8bit的倍数

### 14. Java的锁机制

- 四种状态：无锁、偏向锁(1.6引入)、轻量级锁(1.6引入)、重量级锁。
- 锁只能升级，不能降级(99%的情况)
- 无锁：无竞争，或者存在竞争，用非锁方式同步线程(CAS)
- 简单概括升级过程：当一把锁第一次被线程持有的时候是偏向锁，如果这个线程再次加锁还是偏向锁。如果别的线程来加锁(交替执行)膨胀为轻量锁，如果是资源竞争膨胀为重量锁
- 偏向锁：对象头里锁标志位是01，且前一位是1，就是偏向锁。然后再去读对象头前23bit，线程ID，通过线程ID来确认当前想要获得对象锁的这个线程。如果发现有多个线程在竞争，那么就会升级会轻量级锁
- 轻量级锁：锁标志位是00。当一个线程想要获得某个对象的锁时，如果是轻量级锁，线程会在自己的虚拟机栈中开辟一块被称为Lock Record的空间(存放对象头Mark Word的副本，以及owner指针)，线程通过CAS尝试获取锁，一旦获得，会复制对象头中的Mark Word，并且owner指针指向该对象。对象头中的前30bit会生成一个指针，指向Lock Record。其他线程再来，就会自旋。如果多个线程自旋，就会升级为重量级锁。
- 重量级锁：锁标志位是10。前面的位是一个地址，指向C++里面的一个对象ObjectMonitor。通过Monitor来管理资源。首先Entry Set有一些想进入Monitor的线程，处于Waiting状态。某一个线程A进入后，会处于Active状态，假设该线程执行时，遇到一个判断条件，需要它让出执行权，它将进入Wait Set，状态变为Waiting。此时Entry Set里的线程就有机会进入Monitor。假设线程B进入完成任务，可以通过notify的形式唤醒Wait Set中的线程A，让A进入Monitor继续执行任务，执行完后便可以退出。(synchronized同步机制)

### 14. 讲一下悲观锁和乐观锁

- 悲观锁：操作系统会悲观的认为，如果不严格同步线程调用，那么一定会产生异常，所以用互斥锁将资源锁定，只供一个线程调用，而阻塞其他线程。
- 乐观锁：由CAS来实现同步的工具，由于不会锁定资源，而且当线程需要修改共享资源的对象时，总是会乐观的认为，对象状态值没有被其他线程修改过，而是每次自己都会主动尝试去compare状态值。(其实是使用了无锁机制)

### 15. 用synchronized实现一个读写锁

```java
public class ReadWriteLock {
    private int readCount = 0;
    private int writeCount = 0;

    /**
     * 读锁
     */
    public synchronized void lockRead() throws InterruptedException {
        while (writeCount > 0) {
            wait();
        }
        readCount++;
    }

    /**
     * 释放读锁
     */
    public synchronized void unlockRead() {
        readCount--;
        notifyAll();
    }

    /**
     * 写锁
     */
    public synchronized void lockWrite() throws InterruptedException {
        while (writeCount > 0) {
            wait();
        }

        writeCount++;

        // 读锁为0时获取写锁
        while (readCount > 0) {
            wait();
        }
    }

    /**
     * 释放写锁
     */
    public synchronized void unlockWrite() {
        writeCount--;
        notifyAll();
    }
}
```

### 16. 非公平锁和公平锁

- 公平锁:按照请求锁的顺序分配，拥有稳定获得锁的机会，但是性能可能比非公平锁低
- 非公平锁：不按照请求的顺序分配，不一定拥有获得锁的机会，但是性能可能比公平锁高(后申请的线程，可能在前面休眠线程恢复前拿到锁，这样就可能提高并发的性能，这是因为，通常情况，唤醒一个挂起的线程，线程切换之间产生短暂延时，非公平锁就能利用这段时间来完成操作)

### 17. 说说ReentrantLock

- 一个成员变量Sync，这是一个内部类。它继承了AQS。核心方法就是nonfairTryAcquire和tryRelease等
- 在new一个ReentrantLock时，默认会sync = new NonfairSync();也就是非公平锁。这里面就重写了lock和tryAcquire两个方法。lock一上来就是CAS操作获取锁，不管前面有没有在等待，这里就体现它的非公平。但是只有一次机会，没成功就调用acquire方法(先tryAcquire，失败进入FIFO队列)。tryAquire方法就是直接调用父类的nonfairTryAcquire
- 在new一个ReentrantLock时，传入参数为true，就new一个公平锁fairSync。它也是重写了lock和tryAcquire两个方法。lock直接调用了父类AQS的acquire方法。tryAquire，如果锁空闲，且FIFO队列种没有排在当前线程之前的线程，就允许当前线程直接获取锁，获取失败返回false，然后在acquire方法种进入排队。如果锁不是空闲的，为了满足可重入，这里也进行一些判断，如果当前线程也不是持有锁的独占线程，也返回false。如果当前线程已经获取锁，对state进行累加，可以继续使用。
- 内部写好了，本身的方法直接调用内部类的方法就行。

## MySQL数据库

### 1. 一条SQL查询语句是如何执行的

- 连接器：连接器负责跟客户端建立连接、获取权限、维持和管理连接。
- 查询缓存：之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。但是大多时候弊大于利，查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。MySQL8.0版本直接将查询缓存模块删除了。
- 分析器：词法分析，语法分析
- 优化器：优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。
- 执行器：开始执行的时候，要先判断一下你对这个表有没有执行查询的权限，如果没有，就会返回没有权限的错误 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。如果有权限，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

### 2. redo log和binlog的区别

- redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用
- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”
- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

### 3. 执行器和InnoDB引擎在执行update语句时的流程

> mysql> update T set c = c + 1 where ID = 2;

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成

### 4. 事务四大特性

1. 原子性，要么执行，要么不执行
2. 隔离性，所有操作全部执行完以前其它会话不能看到过程
3. 一致性，事务必须使数据库从一个一致性状态变换到另外一个一致性状态(Undo log)(举例说明：张三向李四转100元，转账前和转账后的数据是正确的状态，这就叫一致性，如果出现张三转出100元，李四账号没有增加100元这就出现了数据错误，就没有达到一致性。)
4. 持久性，一旦事务提交，对数据的改变就是永久的(redo log)

### 5. 事务的隔离级别

1. 读未提交：一个事务还没提交时，它做的变更就能被别的事务看到（可能发生脏读、不可重复读和幻读问题）
2. 读已提交：一个事务提交之后，它做的变更才会被其他事务看到（可能发生不可重复读和幻读问题）
3. 可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的（可能发生幻读问题）
4. 可串行化：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行（读锁和写锁））

### 6. 事务并发可能出现的情况

1. 脏读：指一个事务读取到另一个事务未提交的数据
2. 不可重复读：指一个事务对同一行数据重复读取两次，但得到的结果不同
3. 虚读/幻读：指一个事务执行两次查询，但第二次查询的结果包含了第一次查询中未出现的数据
4. 丢失更新：指两个事务同时更新一行数据，后提交（或撤销）的事务将之前事务提交的数据覆盖了

### 7. 事务隔离的实现

- 每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制(MVCC)

### 8. 索引的常见模型

- Hash：适用于只有等值查询的场景，比如Memcached及其一些NoSQL引擎
- 有序数组：在等值查询和范围查询场景中的性能就都非常优秀。只适用于静态存储引擎。
- 二叉搜索树：查询是O(logN)，维护它是一颗平衡二叉树也需要O(logN)，数据库大多不适用二叉树，树高过高，会使用N叉树

### 9.InnoDB的索引模型

- 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的
- 每一个索引在 InnoDB 里面对应一棵 B+ 树。

### 10. 主键索引和普通索引的区别

- 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引
- 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引
- 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树
- 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表

### 11. 聚簇和非聚簇索引的区别是什么

- 聚簇索引：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引，所以主键就是聚簇索引，修改聚簇索引其实就是修改主键。
- 非聚簇索引：索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引
- MySQL中Innodb中两者都有，而myisam只有非聚簇索引

### 12. 什么是覆盖索引

- 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。

### 13. 什么是最左前缀

- 联合索引的最左N个字段，也可以是字符串索引的最左M个字符

### 14. 在建立联合索引的时候，如何安排索引内的字段排序

- 这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

### 15. 什么是索引下推

- like 'hello%' and age > 10检索，MySQL5.6之前，会对匹配的数据进行回表查询。5.6之后，会先过滤掉age < 10的数据，再进行回表查询，减少回表率，提升检索速度。

### 16. Sql的优化

1. sql尽量使用索引,而且查询要走索引
2. 对sql语句优化
   1. 子查询变成left join
   2. limit 分布优化，先利用ID定位，再分页
   3. or条件优化，多个or条件可以用union all对结果进行合并（union all结果可能重复）
   4. 不必要的排序
   5. where代替having,having 检索完所有记录，才进行过滤
   6. 避免嵌套查询
   7. 对多个字段进行等值查询时，联合索引

### 17. MySQL记录存储(Page)

- 页头：记录页面控制信息，56字节，包括页的左右兄弟页面指针、页面空间使用情况等
- 记录：

  - 最大虚记录：比页内最大主键还大
  - 最小虚记录：比页内最小主键还小
- 记录堆：行记录存储区，分为有效记录和已删除记录两种
- 自由空间链表：已删除记录组成的链表
- 未分配空间：页面未使用空间
- Slot区：slot是一些页面有效记录的指针
- 页尾：页面最后部分、8个字节，主要存储页面的校验信息

### 18. MySQL的锁

- 全局锁：全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。典型使用场景是做全库逻辑备份。对于全部是InnoDB引擎的库，建议使用-Single-transaction参数，这里是使用事务的可重复读隔离级别，使用后能开启一个事务，确保拿到一致性视图。
- 表级锁：MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。与 FTWRL (Flush tables with read lock)类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。表锁一般用在数据库引擎不支持行锁的时候才被用到。
- 行锁：MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。

### 19. 两阶段锁协议

- 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

### 20. 出现死锁应该怎么办

- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。默认就是on。

### 21. 怎么解决由热点行更新导致的性能问题

- 问题的原因在于死锁检测要耗费大量的CPU资源
- 方法一：假如能确保这个业务一定不会出现死锁，可以临时把死锁检错关掉
- 方法二：控制并发度。比如控制同一行最多就10个线程在更新，可以考虑使用中间件实现，或者修改MySQL源码，基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。
- 方法三：你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。

### 22. 怎么删除表的前10000行

- 第一种方式：直接执行delete from T limit 10000，但是单个语句占用时间长，锁的时间也比较长，而且大事务还会导致主从延迟
- 第二种方式：在一个连接里循环执行20次delete from T limit 500
- 第三种方式：在20个连接里执行delete from T limit 500，会认为造成锁冲突

### 23. B-树和B+树的区别

- B-树内部节点是保存数据的;而B+树内部节点是不保存数据的，只作索引作用，它的叶子节点才保存数据。
- B+树相邻的叶子节点之间是通过链表指针连起来的，B-树却不是
- 查找过程中，B-树在找到具体的数值以后就结束，而B+树则需要通过索引找到叶子结点中的数据才结束
- B-树中任何一个关键字出现且只出现在一个结点中，而B+树可以出现多次

### 24. 什么是change buffer？什么时候用？怎样用收益大？

- 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。
- 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。
- 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。反过来，假设一个业务的更新模式是写入之后马上会做查询，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。change buffer 反而起到了副作用。

### 25. 唯一索引和普通索引怎么选择

- 这两者在查询上没有差别，主要是更新性能的影响。尽量使用普通索引
- 如果所有更新后面，马上要查，那么应该关闭change buffer
- 实际中，普通索引和change buffer配合使用

### 26. 如何给字符串字符段加索引

- 直接创建完整索引，这样可能比较占用空间
- 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引
- 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题，不支持范围扫描
- 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，不支持范围扫描

## Redis数据库

### 1. redis的底层数据结构

#### string

简单动态字符串 (Simple Dynamic String)SDS。不用c语言字段的char*，因为

1. 计算长度是O(n)
2. 对于二进制不友好，比如存储图片的二进制，可能会提前遇到字符串的结尾标志
3. 不可修改

redis的结构体

```c
struct --attribute_- ((-_packed__)) sdshdr8{
    uint8_t len;/* buf已保祥的字符串字节数，不包含结束标示*/
    uint8_t alloc;/* buf申请的总的字节数，不包含结束标示*/
    char buf [];
}

// 忽略sdshdr16、sdshdr32、sdshdr64、sdshdr5
```

比如字符串name的sds结构如下：

| len：4 | alloc：4 | n    | a    | m    | e    | \0   |
| ------ | -------- | ---- | ---- | ---- | ---- | ---- |

后面会多存一个 \0,实际存储多一个字节

#### IntSet

IntSet是Redis中set集合的一种实现方式，基于整数数组来实现，并且具备⻓
度可变、有序等特征。

```c
typedef struct intset {
    uint32_t encoding; /*编码方式，支持存放16位、32位、64位*/
    uint32_t Length;/* 元素个数 */
    int8_t contents[];/*整数数组，保存集合数据*/
}
```

假设原本有一个intset，元素是{5,10,20}，这时候存的都是16位，两个byte的数据。新增一个50000，那么会先进行扩容，两个byte扩展为4个byte，倒着扩容的，顺序是20，10，5，encoding改成INTSET_ENC_INT32，length改成4。 如果是要扩容的情况，就直接看是大于0还是小于0，小于0插最前面，大于0插最后面。如果不扩容，就二分查找法找到要插入的位置然后插入。

#### Dict

整个redis就类似于一个java1.7的hashmap。用Dict来实现

```c
typedef struct dictht {
    // entry数组 数组中保存的是指向entry的指针
    dictEntry **table;
    //哈希表大小
    unsigned Long size;
    //哈希表大小的掩码，总等于size - 1
    unsigned Long sizemask;
    // entry个数
    unsigned Long used;
}

typedef struct dictEntry {
    void *key; // 键
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;//值
    //下一个Entry的指针
    struct dictEntry *next;
}

typedef struct dict {
    dictType *type;// dict类型，内置不同的hash函数
    void *privdata; // 私有数据，在做特殊hash运算时用
    dictht ht[2];// 一个Dict包含两个哈希表，其中一个是当前数据，另一个一般是空，rehash时使用
    Long rehashidx; // rehash的进度，-1表示未进行
    int16_t pauserehash；// rehash是否暂停，1则暂停，o则继续
}
```

Dict的负载因子LoadFactor = used/size，新增时或者删除时都会检查，会进行扩容或者缩容

rehash过程：

1. 计算新hash表的realsize，即第一个大于等于dict.ht[0].used的2^n
2. 按照新的realsize申请内存空间，创建dictht，并赋值给dict.ht[1]
3. 设置rehashidx= 0，标示开始rehash
4. 将dict.ht[0]中的每一个dictEntry都rehash到dict.ht[1]
   每次执行新增、查询、修改、删除操作时，都检查一下dict.rehashidx是否大于-1，如果是则将ht[0].table[rehashidx]的entry链表rehash到dict.ht[1]，井且将rehashidx++。直至dict.ht[0]的所有数据都rehash到dict.ht[1] (渐进式hash，不会一次性就copy到新的hashTable)
5. 将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表
6. 将rehashidx赋值为-1，代表rehash结束
7. 在rehash过程中，新增操作，则直接写入ht[1]，查询、修改和删除则会在dict.ht[0]和dict.ht[1]依次查找并执行。这样可以确保h[0]的数据只减不增，随着rehash最终为空

#### ZipList

压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。

| zlbytes | tltail | zllen | entry1 | entry2 | ...  | entryN | zlend |
| ------- | ------ | ----- | ------ | ------ | ---- | ------ | ----- |

在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。

其中entry的结构如下：

| previous_entry_length | encoding | content |
| --------------------- | -------- | ------- |

- previous_entry_length：前一节点的字节大小，占1个或5个字节。如果前一节点的⻓度小于254字节，则采用1个字节来保存这个⻓度值。如果前一节点的⻓度大于254字节，则采用5个字节来保存这个⻓度值，第一个字节为0xfe，后4个字节才是真实⻓度数据
- encoding：编码属性，记录content的数据类型（字符串还是整数）以及content的字节数，占用1个、2个或5个字节
- Content：负责保存节点的数据，可以是字符串或整数

zipList可能导致的问题：连锁更新(Cascade Update）

如果每个entry都是250个字节，那么previous_entry_length只需要一个字节存就可以了，而如果恰好在最前面插入一个254字节的数据，就会导致后续的每一个entry的previous_entry_length都要从1个字节变成5个字节。

QuickList

zipList需要连续内存空间，存储数据也不能太多，怎么办？quickList是一个有前后指针的列表，每个node就是一个zipList，相当于就是把数据打碎了，但不是很碎，然后用一个有前后指针的列表来管理。能够设置每个zipList的大小，也能设置前后各有多少个zipList不压缩，其余压缩（更加节省空间）。

#### SkipList

有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。结构如下：

```c
typedef struct zskiplist {
    //头尾节点指针
    struct zskiplistNode *header, *tail;
    //节点数量
    unsigned Long Length;
    // 最大的索引层级，默认是1
    int Level;
} zskiplist;

typedef struct zskiplistNode {
    sds ele; //节点存储的值
    double score;// 节点分数，排序、查找用
    struct zskiplistNode *backward;// 前一个节点指针
    struct zskiplistLevel {
        struct zskiplistNode * forward;//下一个节点指针
        unsigned Long span;//索引跨度
    } level[];//多级索引数组
} zskiplistNode;
```

#### redisObject

redis的value都是redisObjec，管你什么类型都统统封装成redisObject，结构如下：

```c
typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS;
    int refcount;
    void *ptr;
} robj;
```

type：对象类型，分别是string、hash、list、set、zset，占4个bit位

encoding：底层编码方式，共有11种，占4个bit

lru：表示该对象最后一次被访问的时间，其占用24个bit

refcount：对象引用计数器

\*ptr：指针，指向实际存放数据的空间

| 编码方式                | 说明                 |
| ----------------------- | -------------------- |
| OBJ_ENCODING_RAW        | raw编码动态字符串    |
| OBJ_ENCODING_INT        | long类型的整数字符串 |
| OBJ_ENCODING_HT         | hash表（dict）       |
| OBJ_ENCODING_ZIPMAP     | 废弃                 |
| OBJ_ENCODING_LINKEDLIST | 双端链表             |
| OBJ_ENCODING_INTSET     | 整数集合             |
| OBJ_ENCODING_SKIPLIST   | 跳表                 |
| OBJ_ENCODING_EMBSTR     | embstr的动态字符串   |
| OBJ_ENCODING_QUICKLIST  | 快速列表             |
| OBJ_ENCODING_STREAM     | stream流             |

| 数据类型   | 编码方式                                             |
| ---------- | ---------------------------------------------------- |
| OBJ_STRING | int、embstr、raw                                     |
| OBJ_LIST   | LinkedList和ZipList（3.2以前）、QuickList（3.2以后） |
| OBJ_SET    | intset、HT                                           |
| OBJ_ZSET   | ZipList、HT、SkipList                                |
| OBJ_HASH   | ZipList、HT                                          |

### 2. redis的持久化

#### AOF

##### 定义

记录日志，但是是执行写入操作后再记。（不会阻塞当前这个写操作，但是会影响紧接着的下一个写操作，还有个好处就是不用检查语法是否正确）

##### 写回的配置项

Always：同步写回

Everysec：每秒写回

No：由操作系统来控制什么时候写回

性能越来越好，丢失数据越来越多

##### 日志文件太大怎么办

有重写机制，一个key可能被设置多次，重写机制就是浓缩日志，有一条最新的设置key的语句就行。这个机制是重新启了一个新线程，复制了一份当时的内存数据来进行操作的。不会阻塞主线程。

## 消息队列

### 1. 消息队列解决的问题

- 解耦
- 异步
- 削峰

### 2. 保证MQ重复消费幂等性

- 数据写库时, 首先检查主键, 如果有数据, 则不能插入, 进入一次update
- 写redis, 就没问题, redis的set天然幂等
- 生产者发消息时带上全局唯一ID, 消费者拿到消息后, 先去redis查这个id, 没有消费过就处理, 然后写入这个id到redis

### 3. 保证MQ消息不丢

- 生产者的问题: 使用confirm机制
- MQ的问题: 持久化到磁盘, queue持久化, 消息也持久化. 这个机制可以和confirm机制配合使用
- 消费者的问题: 打开autoAck机制或者自己手动Ack

### 4. 保证消息顺序性

- 需要保证顺序的数据放到同一个queue里
