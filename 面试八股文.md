#      面试复习

## 计算机网络

### 1. OSI与TCP/IP各层的结构与功能,都有哪些协议?

- 五层协议各层作用
  - 应用层(application-layer)的任务是通过应用进程间的交互来完成特定网络应用。应用层的协议包括域名系统DNS、HTTP协议、电子邮件的SMTP协议。这一层的数据都叫报文
  - 运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。运输层的协议：TCP(提供面向连接的，可靠的数据传输服务)和UDP(提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）)[]()
  - 在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信⼦网。网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。 常用IP协议，分组也叫IP数据报
  - 数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。将IP数据报组装成帧。
  - 物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。
- OSI多的两层
  - 会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。
  - 表示层的具体功能如下：
    数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。
    数据的编码：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。
    压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。
    数据的加密和解密：可以提高网络的安全性。
- TCP/IP只有四层
  - 网络接口层包括用于协作IP数据在已有网络介质上传输的协议。它定义像地址解析协议(Address Resolution Protocol,ARP)这样的协议，提供TCP/IP协议的数据结构和实际物理硬件之间的接口。

### 2. OSI七层图片

- ![](/images/OSI七层模型.gif)

### 3. TCP三次握手和四次挥手

- TCP三次握手

  -  服务器通过创建socket、bind、listen完成初始化，通过accept完成连接的建立。
  -  客户端通过创建socket、connect发起连接建立请求

  ![](images/TCP三次握手.jpg)

- TCP四次挥手

  ![](images/TCP四次挥手.jpg)

### 4. 为什么握手是三次

- 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误
- 例子：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。

### 5. 为什么挥手是四次

- 本质的原因是tcp是全双公的，要实现可靠的连接关闭，A发出结束报文FIN，收到B确认后A知道自己没有数据需要发送了，B知道A不再发送数据了，自己也不会接收数据了，但是此时A还是可以接收数据，B也可以发送数据；当B发出FIN报文的时候此时两边才会真正的断开连接，读写分开。

### 6. 如果TCP连接时某一次握手丢失了,会发生什么

- 第一次握手丢失：会触发超时重传机制，在linux里，最大重传次数由tcp_syn_retries内核参数控制，默认是5。通常每次等待时间是上一次的两倍。超过5次后还是没有回应ACK，就直接断开TCP连接。

- 第二次握手丢失：
  - 客户端会认为自己的报文丢失了，会触发超时重传机制，重新发SYN报文
  - 服务端也会触发超时重传机制，重传SYN-ACK报文，linux里最大重传次数由tcp_synack_retries内核参数决定
- 第三次握手丢失：服务端也会触发超时重传机制，重传SYN-ACK报文

### 7. 如果TCP断开连接时某一次挥手丢失了，会发生什么

- 第一次挥手：客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，直接进入到 close 状态。
- 第二次挥手：客户端会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。
- 第三次挥手：服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。
- 第四次挥手：服务端就会重发 FIN 报文

### 8. TCP、UDP区别

TCP：面向连接、可靠、传输形式为字节流、慢、所需资源多、应用场景:文件传输、邮件传输等

UDP：无连接、不可靠、传输形式为数据报文段 、快、所需资源少、应用场景：QQ语音、QQ视频等

UDP首部由源端口号、目标端口号、包长、和校验和组成

TCP首部由源端口号、目标端口号、序列号、确认应答号、数据偏移、保留、控制位、窗口大小、校验和、紧急指针、选项、填充组成

### 9. TCP如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层
3. 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段
4. TCP接收端会丢弃重复的数据
5. 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，会提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大⼩的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. 拥塞控制：当网络拥塞时，减少数据的发送
7. ARQ协议： 它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组
8. 超时重传：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

### 10. ARQ协议(自动重传请求)

自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议

- 停止等待ARQ协议

  - 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组
  - 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认
  - 优点：简单
  - 缺点：信道利用率低，等待时间长

- 连续ARQ协议

  连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了

  优点：信道利用率高，容易实现，即使确认丢失，也不必重传

  缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息

### 11. 滑动窗口和流量控制

TCP利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大⼩，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

### 12. 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注⼊到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收

为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大⼩取决于网络的拥塞程度，并且动态变化。发送方让⾃⼰的发送窗口取为拥塞窗口和接收方的接受窗口中较⼩的一个

TCP的拥塞控制采用了四种算法，即慢开始 、 拥塞避免 、快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生

- 慢开始：cwnd初始值为1，之后每收到一次确认应答，拥塞窗口的值就加1。发送数据包时，将拥塞窗口的大小与接收端主机通知的窗口大小做比较，然后按照它们当中较小的那个值，发送比其还要小的数据量。如果拥塞窗口大小超过慢启动阀值（在超时重发时，设置为当时拥塞窗口的一半），则按比例放大：

  > (1个数据段的字节数 / 拥塞窗口字节) * 1个数据段字节数

- 拥塞避免：拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送方的cwnd加1

- 快重传与快恢复：在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地⼯作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地⼯作

### 13. HTTP协议有什么组成

- 请求报文:
  1. 报文首部
     1. 请求行
     2. 请求首部字段
     3. 通用首部字段
     4. 实体首部字段
     5. 其他
  2. 空行（CR+LF）
  3. 报文主体
- 响应报文:
  1. 报文首部
     1. 状态行
     2. 响应首部字段
     3. 通用首部字段
     4. 实体首部字段
     5. 其他
  2. 空行（CR+LF）
  3. 报文主体

### 14. HTTP状态码

|      | 类别                             | 原因短语                   | 常见的状态码                                                 |
| ---- | -------------------------------- | -------------------------- | ------------------------------------------------------------ |
| 1XX  | Informational（信息状态码）      | 接收的请求正在处理         |                                                              |
| 2XX  | Success（成功状态码）            | 请求正常处理完毕           | 200 OK、204 No Content、206 Partial Content                  |
| 3XX  | Redirection（重定向状态码）      | 需要进行附加操作以完成请求 | 301 Moved Permanently、302 Not Found、303 See Other、304 Not Modified、307 Temporary Redirect |
| 4XX  | Client Error（客户端错误状态码） | 服务器无法处理请求         | 400 Bad Request、401 Unauthorized、403 Forbidden、404 Not Found |
| 5XX  | Server Error（服务器错误状态码） | 服务器处理请求出错         | 500 Internal Server Error、503 Service Unbelievable          |

### 15. HTTP报文的首部

- 通用首部字段

  | 通用首部字段名    | 说明                       |
  | ----------------- | -------------------------- |
  | Cache-Control     | 控制缓存的行为             |
  | Connection        | 逐跳首部、连接的管理       |
  | Date              | 创建报文的日期时间         |
  | Pragma            | 报文指令                   |
  | Trailer           | 报文末端的首部一览         |
  | Transfer-Encoding | 指定报文主体的传输编码方式 |
  | Upgrade           | 升级为其他协议             |
  | Via               | 代理服务器的相关信息       |
  | Warning           | 错误通知                   |

- 请求首部字段

  | 请求首部字段名      | 说明                                          |
  | ------------------- | --------------------------------------------- |
  | Accept              | 用户代理可处理的媒体类型                      |
  | Accept-Charset      | 优先的字符集                                  |
  | Accept-Encoding     | 优先的内容编码                                |
  | Accept-Language     | 优先的语言（自然语言）                        |
  | Authorization       | Web认证信息                                   |
  | Except              | 期待的服务器的特定行为                        |
  | From                | 用户的电子邮箱地址                            |
  | Host                | 请求资源所在服务器                            |
  | If-Match            | 比较实体标记（ETag）                          |
  | If-Modified-Since   | 比较资源的更新时间                            |
  | If-None-Match       | 比较实体标记（与If-Match相反）                |
  | If-Range            | 资源未更新时发送实体Byte的范围请求            |
  | If-Unmodified-Since | 比较资源的更新时间（与If-Modified-Since相反） |
  | Max-Forwards        | 最大传输逐跳数                                |
  | Proxy-Authorization | 代理服务器要求客户端的认证信息                |
  | Range               | 实体的字节范围请求                            |
  | Referer             | 对请求中URI的原始获取方                       |
  | TE                  | 传输编码的优先级                              |
  | User-Agent          | HTTP客户端程序的信息                          |

- 响应首部字段

  | 响应首部字段名     | 说明                         |
  | ------------------ | ---------------------------- |
  | Accept-Ranges      | 是否接受字节范围请求         |
  | Age                | 推算资源创建经过时间         |
  | ETag               | 资源的匹配信息               |
  | Location           | 令客户端重定向至指定URI      |
  | Proxy-Authenticate | 代理服务器对客户端的认证信息 |
  | Retry-After        | 对再次发起请求的时机要求     |
  | Server             | HTTP服务器的安装信息         |
  | Vary               | 代理服务器缓存的管理信息     |
  | WWW-Authenticate   | 服务器对客户端的认证信息     |

- 为Cookie服务的首部字段

  | 首部字段名 | 说明                           | 首部类型     |
  | ---------- | ------------------------------ | ------------ |
  | Set-Cookie | 开始状态管理所使用的Cookie信息 | 响应首部字段 |
  | Cookie     | 服务器接收到的Cookie信息       | 请求首部字段 |

- 其他首部字段

  | 首部字段名       | 说明                                             | 首部类型     |
  | ---------------- | ------------------------------------------------ | ------------ |
  | X-Frame-Options  | 控制网站内容在其他Web网站的Frame标签内的显示问题 | 响应首部字段 |
  | X-XSS-Protection | 针对跨站脚本攻击（XSS）的一种对策                | 响应首部字段 |
  | DNT              | 拒绝个人信息被收集                               | 请求首部字段 |
  | P3P              | 让个人隐私变成一种仅供程序可理解的形式           | 响应首部字段 |


### 16. 在浏览器中输⼊url地址到显示主页的过程

1. 浏览器查找域名的IP地址 DNS解析
2. TCP三次握手进行连接
3. 浏览器向Web服务器发送一个HTTP请求
4. 服务器处理请求，发回一个HTML响应
5. 浏览器开始显示HTML，解析渲染页面
6. 连接结束

### 17. MAC和IP

- 都具有唯一性,但IP具有层次性(IP由网络号和主机号组成,网络号相同,说明它们同处于一个网段.在组织结构,提供商类型和地域分布都比较集中)
- MAC寻址参考地址转发表(记录实际的MAC地址本身),IP寻址参考路由控制表(网络号和子网掩码)
- IP32位，MAC48位
- IP在网络层，MAC在数据链路层
- IP基于地理划分，MAC只和硬件设备有关

### 18. HTTP使用的认证方式

- BASIC认证（基本认证）
- DIGEST认证（摘要认证）
- SSL客户端认证
- FormBase认证（基于表单认证）

### 19. HTTP的缺点

- 通信使用明文,内容可能被窃听
- 不验证通信方的身份,因此有可能遭遇伪装
- 无法证明报文的完整性,所以有可能已遭篡改

### 20. HTTP 和 HTTPS 的区别

- HTTP默认端口是80，HTTPS默认端口是443
- HTTPS = HTTP + 加密 + 认证 + 完整性保护
- HTTPS 协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用
- 安全性和资源消耗：HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。HTTPS加密过程：使用非对称加密方式安全地交换在稍后的对称加密中要使用的密钥，确保交换的密钥是安全的前提下（就是去认证），使用对称密钥加密方式进行通信。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

### 21. 数字证书认证机构的业务流程

1. 服务器把自己的公开密钥登录至数字证书认证机构
2. 数字证书认证机构用自己的私有密钥向服务器的公开密码部署数字签名并颁发公钥证书
3. 客户端拿到服务器的公钥证书后，使用数字证书认证机构的公开密钥，向数字证书认证机构验证公钥证书上的数字签名，以确认服务器的公开密钥的真实性
4. 使用服务器的公开密钥对报文加密后发送
5. 服务器用私有密钥对报文解密

### 22. HTTPS通信步骤

1. 客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件(CipherSuite)列表(所使用的加密算法及密钥长度等)
2. 服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的
3. 之后服务器发送Certificate报文。报文中包含公开密钥证书
4. 最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束
5. SSL第一次握手结束之后，客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串。该报文已用步骤3中的公开密钥进行加密。
6. 接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密
7. 客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准
8. 服务器同样发送Change Cipher Spec报文
9. 服务器同样发送Finished报文
10. 服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求
11. 应用层协议通信，即发送HTTP响应
12. 最后由客户端断开连接。断开连接时，发送close_notify报文。
13. 之后再发送TCP FIN报文来关闭与TCP的通信

在以上流程中，应用层发送数据时会附加一种叫做MAC(Message Authentication Code)的报文摘要。MAC能够查知报文是否遭到篡改，从而保护报文的完整性。

### 23. 对称加密和非对称加密

- 对称（共享）加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等。缺点是密钥的管理与分配，换句话说，如何把密钥发送到需要解密你的消息的人的手里是一个问题
- 非对称（公开）加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等

### 24. get和post区别

- get把请求的数据放在url上，即HTTP协议头上。post把数据放在HTTP的包体内（requrest body）
- GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据)。POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
- GET在浏览器回退时是无害的，POST会再次提交请求
- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息

### 25. cookie和session的区别

- 存在的位置：cookie 存在于客户端，临时文件夹中； session存在于服务器的内存中，一个session域对象为一个用户浏览器服务
- 安全性：cookie是以明文的方式存放在客户端的，安全性低，可以通过一个加密算法进行加密后存放； session存放于服务器的内存中，所以安全性好
- 网络传输量：cookie会传递消息给服务器；session本身存放于服务器，不会有传送流量
- 生命周期(以20分钟为例)：cookie的生命周期是累计的，从创建时，就开始计时，20分钟后，cookie生命周期结束；session的生命周期是间隔的，从创建时，开始计时如在20分钟，没有访问session，那么session生命周期被销毁。但是，如果在20分钟内（如在第19分钟时）访问过session，那么，将重新计算session的生命周期。关机会造成session生命周期的结束，但是对cookie没有影响
- 访问范围：cookie为多个用户浏览器共享； session为一个用户浏览器独享

### 26. Session、Cookie在登录操作中的应用

1. 客户端把用户ID和密码等登录信息放入报文的实体部分，通常是以POST方法把请求发送给服务器。而这时，会使用HTTPS通信来进行HTML表单画面的显示和用户输入数据的发送
2. 服务器会发放用以识别用户的Session ID。通过验证从客户端发送过来的登录信息进行身份认证，然后把用户的认证状态与SessionID绑定后记录在服务器端。向客户端返回响应时，会在首部字段Set-Cookie内写入Session ID。必须防止Session ID被盗，或被猜出。为了做到这点，Session ID应使用难以推测的字符串，且服务器端也需要进行有效期的管理，保证其安全性。另外，为减轻跨站脚本攻击(XSS)造成的损失，建议事先在Cookie内加上httponly属性
3. 客户端接收到从服务器端发来的Session ID后，会将其作为Cookie保存在本地。下次向服务器发送请求时，浏览器会自动发送Cookie,所以Session ID也随之发送到服务器。服务器端可通过验证接收到的Session ID识别用户和其认证状态

## 操作系统

### 1. 进程和线程的区别

- 进程是CPU资源分配的最小单位，线程是CPU调度的最小单位
- 线程可以和属于同一个进程的其他线程共享这个进程的全部资源
- 一个进程包含多个线程，一个线程只能在一个进程之中。每一个进程最少包含一个线程
- 进程之间的切换开销比较大，但是线程之间的切换开销比较小
- 因为线程之间是共享同一个进程的，所以线程之间的通信几乎不需要系统的干扰

### 2. 进程间通信方式

1. 管道
2. 命名管道
3. 消息队列
4. 共享内存
5. 信号量
6. 套接字Socket
7. 信号

### 3. 线程通信方式

1. 锁机制：包括互斥锁、条件变量、读写锁。互斥锁提供了以排他方式防止数据结构被并发修改的方法。读写锁允许多个线程同时读共享数据，而对写操作是互斥的。条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
2. 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
3. 信号机制(Signal)：类似进程间的信号处理。线程间的通信目的主要是用于线程同步，所以线程没有像进程
   通信中的用于数据交换的通信机制。

### 3. 线程有哪几种状态

- 创建状态(new) ：进程正在被创建，尚未到就绪状态。
- 就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- 运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- 阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- 结束状态(terminated)：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

### 4. 线程间的同步方式

1. 互斥量（Mutex）：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的synchronized 关键词和各种 Lock 都是这种机制。
2. 信号量（Semphares）：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. 事件（Event）：Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较

### 5. 进程的调度算法

1. 先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进⼊该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
2. 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
3. 时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间
4. 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级
5. 多级反馈队列调度算法：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法

### 6. 什么是虚拟内存

- 虚拟内存使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等


### 7. 内存管理机制

- 块式管理：将内存分为几个固定大⼩的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很⼩的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片
- 页式管理：把主存分为大⼩相等且固定的一页一页的形式，页较⼩，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址
- 段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间⼩很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、⼦程序段X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址
- 段页式管理：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页

### 8. 什么是死锁

指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进

### 9. 产生死锁的原因

1. 竞争资源
   1.  竞争不可剥夺资源
   2. 竞争临时资源
2. 进程间推进顺序非法

### 10. 死锁产生的必要条件

1. 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用
2. 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放
3. 不可剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放
4. 环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链

### 11. 死锁预防

1. 资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）
2. 只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏请求保持条件）
3. 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
4. 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

### 12. 避免死锁

- 银行家算法：在分配资源之前先看清楚，资源分配后是否会导致系统死锁

### 13. 死锁的解除

- 抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以解除死锁状态
- 终止或者撤销进程。终止或者撤销系统中的一个或多个死锁进程，直到打破循环环路，使系统从死锁状态解脱出来

## Java基础

### 1. Object类有哪些方法

- getClass：获取类的Class对象
- hashCode：获取对象的hashCode值
- equals：比较对象是否相等，比较值和地址
- clone：浅拷贝，使用时要实现java.lang.Cloneable接口，比如A和B都有一个成员变量是X，B是Aclone出来的，改变X，A和B的都改变
- toString：返回字符串包括该对象的类名称，"@"字符以及该对象的哈希码的无符号十六进制表示形式，一般会被重写
- finalize：在垃圾回收之前被执行，可以通过重写finalize方法来重置系统资源，执行清理活动并且最大程度的减少内存泄露，JDK9之后不用了
- wait：让当前线程进入等待序列
- wait(long timeout)：在其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量前，导致当前线程等待
- wait(long timeout, int nanos)：在其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量前，导致当前线程等待
- notify：该方法唤醒在该对象上等待的某个线程
- notifyAll：该方法唤醒在该对象上等待的所有线程

### 2. 接口和抽象类的区别

- 相同点
  1. 都不能被实例化
  2. 接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化
- 不同点
  1. 接口只有定义，不能有方法的实现，java 1.8中可以定义default方法体，而抽象类可以有定义与实现，方法可在抽象类中实现
  2. 实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承
  3. 接口强调特定功能的实现，而抽象类强调所属关系
  4. 接口成员变量默认为public static final，必须赋初值，不能被修改；其所有的成员方法都是public、abstract的。抽象类中成员变量默认default，可在子类中被重新定义，也可被重新赋值；抽象方法被abstract修饰，不能被private、static、synchronized和native等修饰，必须以分号结尾，不带花括号

### 3. 什么时候用抽象类，什么时候用接口

抽象类：强调的是把共同(共有、相同)的属性方法， 抽象出来，统一写在一个地方（他们的实现代码是一样的），方便维护。（面向对象三大特性中的继承特性）

接口： 抽象的是行为 - 同一种行为的不同实现方式。当多个对象都拥有相同的行为，但是行为的具体实现方式不一样的时候可以用接口抽象（面向对象中的多态特性）

例如：所有的订单都有单号，单价，数量。都拥有，而且相同，所以可以用一个抽象类给统一描述出来。

所有的订单都需要支付，但是支付方式又不一样比如，微信支付，支付宝支付，同一种行为，但是具体的行为方式又不一样。所以用一个接口给抽象出来（规定一个行为标准）

### 4. ==和equals

- ==：基础数据类型：比较的是他们的值是否相等，比如两个int类型的变量。引用数据类型：比较的是引用的地址是否相同，比如说新建了两个User对象，比较的是两个User的地址是否一样。

- equals：Object类的源码里比较的是地址。但是像String这里面的会被重写。

- 实例：

  ```java
  String str1 = "Hello";
  String str2 = new String("Hello");
  String str3 = str2; // 引用传递
  System.out.println(str1 == str2); // false
  System.out.println(str1 == str3); // false
  System.out.println(str2 == str3); // true
  System.out.println(str1.equals(str2)); // true
  System.out.println(str1.equals(str3)); // true
  System.out.println(str2.equals(str3)); // true
  ```

- 上面实例的内存解释：String str1 = "Hello";会在堆区存放一个字符串对象"hello"(1)，然后栈里有str1指向它(1)。String str2 = new String("Hello");会在堆区再次存放一个字符串对象"hello"(2)，然后栈里有str2指向它(2)。String str3 = str2;栈里会有一个str3，指向"hello"(2)。==比较地址，equals比较值。

- 延申：

  ```java
  String s1 = "Hello";
  String s2 = new String("Hello");
  s2 = s2.intern();
  System.out.println(s1 == s2);       //  true
  System.out.println(s1.equals(s2));  //  true
  ```

- 在这里多了一个intern方法，他的意思是检查字符串池里是否存在。String s1 = "Hello";会在堆区存放一个字符串对象"hello"。s2调用intern()方法时，因为字符串里已经有了，所以就直接把s2指向它就行了。所以s1和s2指向同一个。

### 5. 为什么重写equals()，必须要重写hashCode()

- 两个对象equals相等，那么他们hashCode一定也相同
- 两个对象hashCode相等，equals不一定相等
- 通常只要我们重写 equals方法就要重写 hashCode方法
- 如果不重写，在使用HashMap，HashTable时，是根据hashCode来判断的。假如说User类重写equals，只要类型相等，name相同，就返回true。那么User u1 = new User("abc");User u2 = new User("abc");这俩作为key往hashMap里put时，不会有覆盖。当我们重写了hashCode让User的name作为计算的值，用来产生最终的hash值，这样HashMap就可以帮我们把两个对象，路由到一个下标下面了，再通过equals比对，确定两个是同一个对象，从而达到去重的效果。

### 6. sleep()和wait()的区别

- 这两个方法来自不同的类分别是，sleep来自Thread类，和wait来自Object类
- 最主要是sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法
- 使用范围：wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用
- sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常

### 7. Java泛型是什么？使用泛型有什么好处

- 在集合中存储对象并在使用前进行类型转换非常不方便。泛型防止了那种情况的发生。它提供了编译期的类型安全，确保你只能把正确类型的对象放入集合中，避免了在运行时出现ClassCastException。

### 8. Java泛型是如何工作的

- 泛型是通过类型擦除来实现的，编译器在编译时擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息。例如List<String>在运行时仅用一个List来表示。这样做的目的，是确保能和Java 5之前的版本开发二进制类库进行兼容。你无法在运行时访问到类型参数，因为编译器已经把泛型类型转换成了原始类型。

### 9. 什么是泛型中的限定通配符和非限定通配符

- 限定通配符对类型进行了限制。有两种限定通配符，一种是<? extends T>它通过确保类型必须是T的子类来设定类型的上界,不能add只能get。要用的话只能封装一个方法，方法参数可以是子类
- 另一种是<? super T>它通过确保类型必须是T的父类来设定类型的下界。泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误。例子： List<? super Person> list = new ArrayList<>(); 只能往里面addPerson类和其子类和null。反而父类放不进去。只能add不能get。要用的话只能封装一个方法，方法参数可以是父类。
- 另一方面<?>表示了非限定通配符，因为<?>可以用任意类型来替代。

### 10. 什么是反射

- 反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。

### 11. 获取Class对象的方式

1. 第一种方法通过类的全路径字符串获取 Class 对象，这也是我们平时最常用的反射获取 Class 对象的方法；

   ```java
   Class studentClass = Class.forName("com.test.reflection.pojo.Student");
   ```

2. 第二种方法有限制条件：需要导入类的包；

   ```java
   Class studentClass2 = Student.class;
   ```

3. 第三种方法已经有了 Student 对象

   ```java
   Student studentObject = new Student();
   Class studentClass3 = studentObject.getClass();
   ```
   
4. 第四种方法类加载器

   ```java
   Class studentClass4 = Main.getClassLoader().loadClass("com.test.reflection.pojo.Student");
   ```

### 12. 如何利用反射创建对象

- 使用Class对象的newInstance()方法创建该Class对象的实例，要求必须要有无参数的构造方法
- 使用Class对象获取指定的Constructor对象，再调用Constructor的newInstance()方法创建对象类的实例，此时可以选择使用某个构造方法。如果这个构造方法被私有化起来，那么必须先申请访问，将可以访问设置为true(setAccessible(boolean flag))

### 13. Java内置注解

- @Override：java.lang.Override中，只适用于修饰方法，表示一个方法声明打算重写超类中的另一个方法声明

- @Deprecated：java.lang.Deprecated中，可以用于修饰方法、属性、类，表示不鼓励程序员使用这样的元素

- @SuppressWarnings：java.lang.SuppressWarnings中，用来抑制编译时的警告信息。这个注解使用的时候需要参数，比如：

  ```java
  @SuppressWarnings("all")
  
  @SuppressWarnings("unchecked")
  
  @SuppressWarnings(value = {"unchecked", "deprecation"})
  ```

### 14. Java的元注解 

- 元注解的作用就是负责注解其他注解，Java定义了4个标准的meta-annotation类型，他们被用来提供对其他annotation类型做说明。他们都在java.lang.annotation包下。
- @Target：用于描述注解的使用范围
- @Retention：表示需要在什么级别保持该注解信息。(SOURCE < CLASS < RUNTIME)
- @Document：说明该注解将被包含在javadoc中
- @Inherited：说明子类可以父类中的该注解

### 15. Exception和Error有什么区别

- Exception 和 Error 都是继承了 Throwable 类，在 Java 中只有 Throwable 类型的实例才可以被抛出（throw）或者捕获（catch），它是异常处理机制的基本组成类型。
- Exception 和 Error 体现了 Java 平台设计者对不同异常情况的分类。Exception 是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。Error 是指在正常情况下，不大可能出现的情况，绝大部分的 Error 都会导致程序（比如 JVM 自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如 OutOfMemoryError 之类，都是 Error 的子类。
- Exception 又分为可检查（checked）异常和不检查（unchecked）异常，可检查异常在源代码里必须显式地进行捕获处理，这是编译期检查的一部分。Error，是 Throwable 不是 Exception。不检查异常就是所谓的运行时异常，类似 NullPointerException、ArrayIndexOutOfBoundsException 之类，通常是可以编码避免的逻辑错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。

### 16. 异常处理的基本原则

- 尽量不要捕获类似Exception这样的通用异常,而是应该捕获特定异常
- 不要生吞(swallow)异常

### 17. final、finally、finalize有什么不同

- final 可以用来修饰类、方法、变量，分别有不同的意义，final 修饰的 class 代表不可以继承扩展，final 的变量是不可以修改的，而 final 的方法也是不可以重写的（override）。
- finally 则是 Java 保证重点代码一定要被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭 JDBC 连接、保证 unlock 锁等动作。
- finalize 是基础类 java.lang.Object 的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize 机制现在已经不推荐使用，并且在 JDK 9 开始被标记为 deprecated。

### 18. String、StringBuffer、StringBuilder有什么区别

- String 是 Java 语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的 Immutable 类，被声明成为 final class，所有属性也都是 final 的。
- StringBuffer 是为解决上面提到拼接产生太多中间对象的问题而提供的一个类，我们可以用 append 或者 add 方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer 本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，所以除非有线程安全的需要，不然还是推荐使用它的后继者，也就是 StringBuilder。
- StringBuilder 在能力上和 StringBuffer 没有本质区别，但是它去掉了线程安全的部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。
- 在字节码层面，String在字符串拼接时，会new一个StringBuilder进行拼接。而StringBuilder由于之前new了，只需要调用append方法就行。

### 19. String str1 = "abc"; String str2 = new String ("abc"); 输出str1 == str2结果是什么

- false。str1和str2是引用类型，比较地址，前面str1引用的"abc"是常量池的，后者str2引用的是堆中的。地址不同。
- 可以调用intern()方法，如果常量池有，就直接引用它，没有就缓存起来。JDK1.6之前，少用这个方法，因为他们缓存在了永久代，使用不当会OOM。1.8之后，方法区由元空间实现，基本上问题解决了。
- 无论在哪里，使用String s = "a"; ==的结果都是ture。(静态变量和局部变量比，成员变量和局部变量比等等)

### 20. 重写和重载的区别

- 重写实现的是运行时的多态，而重载实现的是编译时的多态
- 重写的方法参数列表必须相同；而重载的方法参数列表必须不同
- 重写是父类与子类之间，重载是在一个类中
- 重写的方法的返回值类型只能是父类类型或者父类类型的子类，访问修饰符的限制一定要大于被重写方法的访问修饰符（public>protected>default>private)，而重载的方法对返回值类型没有要求

## Java集合

### 1. arraylist和linkedlist的区别

- ArrayList的实现是基于数组，连续的一块内存空间，LinkedList的实现是基于双向链表，不需要连续的空间
- 对于随机访问，ArrayList优于LinkedList，ArrayList可以根据下标以O(1)时间复杂度对元素进行随机访问。而LinkedList的每一个元素都依靠地址指针和它后一个元素连接在一起，在这种情况下，查找某个元素的时间复杂度是O(n)
- 对于插入和删除操作，LinkedList优于ArrayList，因为当元素被添加到LinkedList任意位置的时候，不需要像ArrayList那样重新计算大小或者是更新索引
- LinkedList比ArrayList更占内存，因为LinkedList的节点除了存储数据，还存储了两个引用，一个指向前一个元素，一个指向后一个元素
- ArrayList扩容：新数组长度是原来的1.5倍(用移位操作)，然后用Arrays.copyOf将数组的元素复制到新数组

### 2. Arrays.asList(a).toArray == Object[].class结果是什么?

- false，这是1.8的一个Bug

### 3. HashMap的底层数据结构

- JDK7，数组+链表组成。链表是为了解决哈希冲突。加入数据时用头插法
- JDK8，数组+链表+红黑树组成。加入数据是尾插法
  - 链表超过8且数据总量超过64就会转成红黑树
  - 不超过64就扩容

### 4. 为什么不直接用红黑树？而选择先用链表，再转红黑树

- 因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于 8 个的时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于 8 个的时候， 红黑树搜索时间复杂度是 O(logn)，而链表是 O(n)，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了

### 5. 为什么链表改为红黑树的阈值是 8

理想情况下使用随机的哈希码，容器中节点分布在 hash 桶中的频率遵循泊松分布。个数为8的时候概论已经很小了

### 6. HashMap默认加载因子是多少？为什么是 0.75，不是 0.6 或者 0.8 ？

默认的loadFactor是0.75，0.75是对空间和时间效率的一个平衡选择，一般不要修改，除非在时间和空间比较特殊的情况下 ：

- 如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值 。
- 相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1

### 7. HashMap 中 key 的存储索引是怎么计算的

1. 取key的 hashCode 值
2. 根据 hashcode 计算出hash值（高16位异或低16位）
3. 通过取模计算下标（数组长度是2的幂次方，进行与操作非常方便）

### 8. HashMap的put方法流程

1. 首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标
2. 如果数组是空的，则调用 resize 进行初始化
3. 如果没有哈希冲突直接放在对应的数组下标里
4. 如果冲突了，且 key 已经存在，就覆盖掉 value
5. 如果冲突后，发现该节点是红黑树，就将这个节点挂在树上
6. 如果冲突后是链表，判断该链表是否大于 8 ，如果大于 8 并且数组容量小于 64，就进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；否则，链表插入键值对，若 key 存在，就覆盖掉 value
7. JDK1.7版本就是先判断是不是需要扩容，不扩容就头插法

### 9. HashMap的扩容

只需要看看原来的 hash 值新增的那个bit是1还是0就好了，是0的 话索引没变，是1的话索引变成原索引 + oldCap

### 10. 解决Hash冲突

1. 开放地址法 
2. 再哈希法
3. 链地址法
4. 建立公共溢出区

### 11. 说说ConcurrentHashMap

- 1.7：采用锁分段机制，将数据分成Segment数据段，给每一个数据段配一把锁。扩容的时候是被锁保护的。put时，先tryLock，如果返回true，则node=null，否则执行scanAndLockForPut方法（预先创建node，如果拿到锁就返回node）。接着获取所在HashEntry链表index的head，如果next=null，则初始化node，头插法，检查扩容。如果next！=null，则检查node key是不是相同，否就再去判断next是不是等于null，是就覆盖当前node。
- 1.8：取消分段锁，采用CAS进行值的设置，如果CAS失败再使用synchronized加锁添加元素

## JVM

### 1. 什么是JVM内存结构

- **程序计数器**：程序计数器是一块很小的内存空间，用于存储字节码的指令地址，提供给执行引擎去取指执行。（线程私有，无内存溢出问题）
- **虚拟机栈**：描述java方法执行过程的内存模型，每个方法执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态连接、返回地址等信息，当线程请求的栈深度超过了虚拟机允许的最大深度时，就会抛出StackOverFlow的异常。（线程私有，描述java方法的执行过程）
- **本地方法栈**：本地方法区和虚拟机栈的作用类似，区别是虚拟机栈为执行 Java 方法服务，本地方法栈为 Native 方法服务。（线程私有）
- **堆**：在 JVM 运行过程中创建的对象和产生的数据都被存储在堆中，堆是被线程共享的内存区域，也是垃圾收集器进行垃圾回收的最主要的内存区域。（线程共享）
- **方法区**：jdk8以前方法区是由永久代实现的，存储类的元信息，常量池，静态变量等，jdk8以后，方法区由元空间实现，存储类的元信息等，常量池、静态变量存储在堆中（线程共享）

### 2. JVM内存分配与回收策略

1. 对象优先分配在Eden区。new出来的对象都放在堆内存里，JVM将堆分为新生代和老年代。新生代8/10是Eden区，1/10是ServivorFrom区，1/10是ServivorTo区。Eden区空间不足会发起一次minor GC。
2. 大对象直接进入老年代。JVM参数：-XX:PretenureSizeThreshold（只在Serial和ParNew两个收集器下有效）
3. 长期存活的对象将进入老年代。若Servivor区的对象经过一次GC存活下来，则其年龄加一，默认到15进入老年代。
4. Minor GC后存活的对象Survivor区放不下，则部分去老年代，部分放在Survivor区。
5. Eden、SurvivorFrom与SurvivorTo区默认比例8:1:1。如果Eden区满了，就进行minor GC，存活的对象放进Survivor区。
6. 对象动态年龄判断。如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。
7. 老年代空间分配担保机制。在MinorGC之前，判断老年代剩余可用空间是否小于年轻代里现有的所有对象大小之和，没有，就进行minorGC，如果是，就看是否配置担保参数：-xx:-HandlePromotionFailure，没有就直接FullGC，如果配置了，就判断老年代剩余可用空间是否小于之前每次minorGC后进入老年代的对象平均大小，否就进行minorGC，是就进行FullGC。

### 3. minor GC和Full GC有什么不同

1. minor GC/Young GC：指放生在新生代的垃圾收集动作。非常频繁，且速度很快
   - eden区满了，在new对象时，就会触发
   - eden和from存活对象移动到to，年龄+1
   - 将eden和from回收
   - 将原来的from和to名字交换
2. Major GC/Full GC：一般会回收老年代，年轻代，方法区的垃圾，速度很慢
   - 老年代满了，就会触发

### 4. 如何确定垃圾

- **引用计数法**：在为对象添加一个引用时，引用计数加 1；在为对象删除一个引用时，引进计数减 1；如果一个对象的引用计数为 0，则表示此刻该对象没有被引用，可以被回收。（循环引用问题）
- **可达性分析**：首先定义一些 GC Roots 对象（哪些可以作为GC Roots对象：栈帧本地变量表、方法区常量池、方法区静态属性、活跃线程引用对象、本地方法栈JNI对象），然后以这些 GC Roots 对象作为起点向下搜索，如果在 GC roots 和一个对象之间没有可达路径，则称该对象是不可达的。不可达对象要经过至少两次标记才能判定其是否可以被回收，如果在两次标记后该对象仍然是不可达的，则将被垃圾收集器回收。

### 5. java中常见的垃圾回收算法

1. **标记清除算法**：其过程分为标记和清除两个阶段。在标记阶段利用可达性遍历内存，标记所有需要回收的对象，在清除阶段清除可回收的对象并释放其所占用的内存空间。（有碎片）
2. **复制算法**：复制算法首先将内存划分为两块大小相等的内存区域，即区域 1 和区域 2，新生成的对象都被存放在区域 1 中，在区域 1 内的对象存储满后会对区域 1 进行一次标记，并将标记后仍然存活的对象全部复制到区域 2 中，这时区域 1 将不存在任何存活的对象，直接清理整个区域 1 的内存即可。（清理效率高，易实现，不适合有大量存活久的对象）
3. **标记整理算法**：在标记完成后将存活的对象移到内存的另一端，然后清除该端的对象并释放内存。（结合了标记清除算法和复制算法的优点）
4. **分代收集算法**：JVM将堆分为新生代和老年代。新生代8/10是Eden区，1/10是ServivorFrom区，1/10是ServivorTo区。新生代使用复制算法（新生代需要复制的对象少），进行垃圾回收时会将在 Eden 区和 ServivorFrom 区中存活的对象复制到 ServivorTo 区，然后清理 Eden 区和 ServivorFrom 区的内存空间。老年代使用标记清除算法或标记整理（老年代主要是生命周期长的对象和大对象）。还有一个区域，即方法区的永久代，永久代用来存储 Class 类、常量、方法描述等。在永久代主要回收废弃的常量和无用的类。新生代使用复制算法时，如果ServivorTo区空间不够，则直接进入老年区。若Servivor区的对象经过一次GC存活下来，则其年龄加一，默认到15进入老年代。还有对象动态年龄判断机制,如果form区年龄总和超过survivor区的50%，就进入老年代。

### 6. JVM垃圾收集器

- Serial：单线程收集器。新生代采用复制算法，老年代采用标记-整理算法。简单而高效
- Serial Old：单线程收集器。在JDK1.5及以前与Parallel Scavenge收集器搭配使用。或者作为CMS收集器的后备方案
- parNew收集器：Serial收集器的多线程版本。新生代采用复制算法，老年代采用标记-整理算法。默认线程数和cpu数相同。运行在Server模式下的虚拟机的首要选择。除了Serial收集器外，只有它能与CMS收集器配合工作
- Parallel Scavenge收集器：是Server模式下的默认收集器。新生代采用复制算法，老年代采用标记-整理算法。高效率的利用CPU。在优化比较困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机完成。
- Parllel Old收集器：使用多线程，标记-整理算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑Parallel Scavenge收集器和Parllel Old收集器。
- CMS收集器（老年代）：以获取最短回收停顿时间为目标的收集器。HotSpot虚拟机第一款真正意义上的并发收集器。标记-清除算法。优点：并发收集、低停顿。缺点：对CPU资源敏感，无法处理浮动垃圾，使用标记-清除算法，会有大量空间碎片。执行过程中的不确定性，会存在上一次垃圾回收还没执行完，然后垃圾回收又被触发的情况。过程：
  1. 初始标记：stop-the-world，仅仅标记GC Roots能直接关联到的对象，速度很快。
  2. 并发标记：从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但不需要停顿用户线程。
  3. 重新标记：stop-the-world，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。
  4. 并发清除：清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。
- G1收集器：
  1. G1垃圾收集器将整个JVM内存分为多个大小相等的region,年轻代和老年代逻辑分区 
  2. G1是Java9以后的默认垃圾回收器了
  3. G1在整体上使用标记整理算法，局部使用复制算法
  4. G1的每个Region大小在1-32M之间，可以通过-XX:G1HeapRegionSize=n指定区大小
  5. 总的Region个数最大可以存在2048个，即heap最大能够达到32M\*2048=64G
  6. 0.5<obj<1,那么放到old区，old标记为H
  7. 1<obj<n,连续的n个region,作为H
  8. G1 mixGC的过程
     - 初始标记：标记出GCRoot对象，以及GCRoot所在的Region(RootRegion)
     - Root Region Scanning:扫表整个old的Region
     - 并发标记：并发追溯标记，进行GCRootsTracing的过程
     - 最终标记：修正并发标记期间，因程序运行导致标记发生变化的那一部分对象
     - 清理回收：根据时间来进行价值最大化的回收，重置rset

### 7. java中的引用类型

1. 强引用：在 Java 中最常见的就是强引用。在把一个对象赋给一个引用变量时，这个引用变量就是一个强引用。有强引用的对象一定为可达性状态，所以不会被垃圾回收机制回收。因此，强引用是造成 Java 内存泄漏（Memory Link）的主要原因。
2. 软引用：软引用通过 SoftReference 类实现。如果一个对象只有软引用，则在系统内存空间不足时该对象将被回收。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。
3. 弱引用：弱引用通过 WeakReference 类实现，并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系，如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择。
4. 虚引用(幻象引用)：虚引用通过 PhantomReference 类实现，你不能通过它访问对象。虚引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制，比如，通常用来做所谓的 Post-Mortem 清理机制，java平台自身Cleaner机制等。也有人利用虚引用监控对象的创建和销毁。

### 8. JVM的类加载机制

1. 加载：读取Class文件，将其转化为某种静态数据结构存储在方法区内，并在堆中生成一个便于用户调用的java.lang.Class类型的对象
2. 验证：(元数据、字节码验证)对Class静态结构进行语法和语义分析，保证其不会产生危害虚拟机的行为
3. 准备：主要工作是在方法区中为类变量分配内存空间并设置类中静态变量的默认值。初始值指不同数据类型的默认值，这里需要注意 final 类型的变量（给的值）和非 final 类型的变量（默认值）在准备阶段的数据初始化过程不同。
4. 解析：符号引用替换为直接引用。(A引用了B，在编译阶段，A不知道B有没有编译，B此时也没有被加载，A不知道B的实际地址，所以用一个字符串S来代表B的地址，S就是符号引用。在运行时，如果A发生了类加载，到解析阶段，发现B还未加载，就会触发B的类加载，将B加载到虚拟机中，此时A中B的符号引用将会被替换成B的实际地址，这就是直接引用。如果A调用B是一个具体的实现类，那么就称为静态解析，而如果使用了多态，B可能是一个抽象类或者接口，B可能有两个具体的实现类C和D，这个时候不会替换，等到运行过程中发生了调用，此时虚拟机调用栈中将会得到具体的类型信息，这时再进行解析。这也是为啥有时候解析会发生在初始化之后，这就是动态解析)
5. 初始化：会判断代码中是否存在主动的资源初始化操作。比如成员变量的赋值动作，静态变量的赋值动作，以及静态代码块的逻辑。只有显式的调用new，才会调用构造函数，进行对象的实例化。

### 9. 什么情况下JVM不会执行类的初始化流程 

- 常量在编译时会将其常量值存入使用该常量的类的常量池中，该过程不需要调用常量所在的类，因此不会触发该常量类的初始化
- 在子类引用父类的静态字段时，不会触发子类的初始化，只会触发父类的初始化
- 定义对象数组，不会触发该类的初始化
- 在使用类名获取 Class 对象时不会触发类的初始化
- 在使用 Class.forName 加载指定的类时，可以通过 initialize 参数设置是否需要对类进行初始化
- 在使用 ClassLoader 默认的 loadClass 方法加载类时不会触发该类的初始化。

### 10. JVM的类加载器

- 启动类加载器：负责加载 Java_HOME/lib 目录中的类库，或通过-Xbootclasspath 参数指定路径中被虚拟机认可的类库
- 扩展类加载器：负责加载 Java_HOME/lib/ext 目录中的类库，或通过 java.ext.dirs 系统变量加载指定路径中的类库
- 应用程序类加载器：负责加载用户路径（classpath）上的类库。
- 除了上述 3 种类加载器，我们也可以通过继承 java.lang.ClassLoader 实现自定义的类加载器。

### 11. 双亲委派机制

- 双亲委派机制指一个类在收到类加载请求后不会尝试自己加载这个类，而是把该类加载请求向上委派给其父类去完成，其父类在接收到该类加载请求后又会将其委派给自己的父类，以此类推，这样所有的类加载请求都被向上委派到启动类加载器中。若父类加载器在接收到类加载请求后发现自己也无法加载该类（通常原因是该类的 Class 文件在父类的类加载路径中不存在），则父类会将该信息反馈给子类并向下委派子类加载器加载该类，直到该类被成功加载，若找不到该类，则 JVM 会抛出 ClassNotFoud 异常。

### 12. 创建出来的对象放在哪儿

- 大部分放在堆里面
- 没有方法逃逸的对象，直接栈上分配
- 没有线程逃逸，可以进行syn擦除，同步擦除策略
- 标量替换优化，替换的聚合量

### 13. 对象空间的内存分配

- 指针碰撞法。使用过的空间在一边，空闲的在另一边，中间是指针。该方法适用于GC后没有碎片。
- 空闲列表。维护一个列表记录哪些内存块可用。分配时，从列表找一个足够大的空间划分给对象实例，并更新列表上的记录。
- 解决线程安全：
  - 一种是对分配内存空间的动作进行同步处理，实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性。
  - 另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在java堆中预先分配一小块内存，称为本地线程分配缓冲

## Java多线程

### 1. java如何开启线程

1. 继承Thread类、重写run()方法
2. 实现Runnable接口，实现run()方法
3. 实现Callable接口，实现call()方法，通过FutureTask创建一个线程，可以获得返回值
4. 创建线程池

### 2. 怎么保证线程安全

1. 使用JUC下面的类
2. 使用Synchronized关键字
3. 使用JDK提供的各种Lock

### 3. Volatile关键字作用

- 内存可见性：所有线程都能看到共享内存的最新状态
- 防止指令重排：在new一个对象时，会执行分配内存，初始化对象，然后这个变量指向内存。如果发生指令重排，执行顺序是132，执行到第3的时候，线程B刚好进来了，并且执行到注释2，这时候判断mInstance 不为空，直接使用一个未初始化的对象。

### 3. Volatile和Synchronized有什么区别

- synchronized通过加锁的方式，可以在需要原子性、可见性和有序性这三种特性的时候都可以作为其中一种解决方案
- volatile通过在volatile变量的操作前后插入内存屏障的方式，保证了变量在并发场景下的可见性和有序性
- volatile关键字是无法保证原子性的，而synchronized通过monitorenter和monitorexit两个指令，可以保证被synchronized修饰的代码在同一时间只能被一个线程访问，即可保证不会出现CPU时间片在多个线程间切换，即可保证原子性
- volatile是Java虚拟机提供的一种轻量级同步机制，不是锁。而Synchronized会有阻塞和性能损耗的问题
- Volatile能防止指令重排

### 4. 对AQS的理解。AQS如何实现可重入锁

- AQS的成员属性：

  - state：资源是否被占用的标记位，volatile保证线程可见性，int，可以在共享模式下由多个线程占用
  - head、tail：头尾节点，封装的一个内部类Node(prev、next、waiter、status)，未拿到资源的线程排队的双向链表

- AQS的核心方法：

  - protected boolean tryAcquire(int arg)：被protect修饰，参数是int，代表对state的修改，返回是boolean，代表是否成功获得锁。该方法只有一行，就是抛出异常。很明显要继承AQS重写这个方法。比如：

    ```java
    class Syncer extends AbstractQueuedSynchronizer {
    	@Override
    	protected boolean tryAcquire(int arg) {
    		if (arg != 1) {
    			return false;
    		}
    		if (getState() == 1) {
    			return false;
    		}
    		return compareAndSetState(0, 1);
    	}
    }
    ```

  - public final void acquire(int arg) ：不允许重写，调用之后一定获得锁。先调用tryAcquire，如果不行就调用acquire的重载方法。然后进行尝试获取锁，入队，修改status等操作。acquireQueued这个方法，如果当前线程所在节点处于头节点后面一个，就会不断尝试拿锁，直到成功。如果不是头节点，则判断是不是需要挂起，如果之前节点不是头节点并且状态是singal，则需要挂起。

  - protected boolean tryRelease(int arg) ：和tryAcquire差不多，需要重写

  - public final boolean release(int arg)：尝试释放成功，就要唤醒等待队列的其他节点。先把自己设置为head，然后从尾到头找第一个head，然后去自旋拿锁。

### 5. A、B、C三个线程，如何保证三个线程同时执行？如何在并发情况下保证三个线程依次执行？如何保证三个线程有序交错进行？

- 同时执行：使用CountDownLatch类，初始化时为1。让这三个线程都await()，然后主线程里调用countDown()，三个线程就同时进行了
- 依次执行：volatile修饰一个变量，每个线程都要判断，做完任务之后，修改这个变量，让下一个线程满足条件
- 有序交错执行：定义一个信号量int number；然后private Lock lock = new ReentrantLock();然后private Condition conditionA = lock.newCondition();。。。线程里执行的时候就是lock.lock(); while(numer!=0){conditionA.await();}改变信号量，唤醒下一个线程conditionB.signal();最后lock.unlock()

### 6. 说说几种常见的线程池及使用场景

- newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行
- newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待
- newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程
- newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行

### 7. 线程池的参数

- corePoolSize：核心池的大小
- maximumPoolSize：线程池最大线程数
- keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止
- unit：参数keepAliveTime的时间单位
- workQueue：一个阻塞队列，用来存储等待执行的任务
- threadFactory：用于设置创建线程的工厂
- handler：表示当拒绝处理任务时的策略，有以下四种取值：1、AbortPolicy：直接抛出异常。2、CallerRunsPolicy：只用调用者所在线程来运行任务。3、DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。4、DiscardPolicy：不处理，丢弃掉。

### 8. CAS实现原子性操作

- 读取旧值为一个临时变量
- 对旧值的临时变量进行操作或者依赖旧值临时变量进行一些操作
- 判断旧值临时变量是不是等于旧值,等于则没被修改,那么新值写入.不等于则被修改,此时放弃或者从步骤1重试

### 9. ABA问题

- ABA问题指的是多个线程同时执行,那么开始时其获得的值都是A,当一个线程修改了A为B,第二个线程修改了B为A,那么第三个线程修改时判断A仍然是A,认为其没有修改过,因此会CAS成功

- 在JDK1.5之后提供了`AtomicStampedReference`类来解决ABA问题,解决思路是保存元素的引用,引用相当于版本号,是每一个变量的标识,因此在CAS前判断下是否是同一个引用即可

### 10. CAS应用题。三个线程将一个值累加到100。

```java
// 1.错误写法
public class Main {
    static Integer num = 0;
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++) {
            new Thread(() -> {
                while (num < 1000) {
                    System.out.println("thread name:" + Thread.currentThread().getName() + ":" + num++);
                }
            }).start();
        }
    }
}

// 2.原子类
public class Main {
    static AtomicInteger num = new AtomicInteger(0);
    public static void main(String[] args) {
        for (int i = 0; i < 3; i++) {
            new Thread(() -> {
                while (num.get() < 1000) {
                    System.out.println("thread name:" + Thread.currentThread().getName() + ":" + num.incrementAndGet());
                }
            }).start();
        }
    }
}
```

### 11. synchronized与ReentrantLock的区别

- 底层实现上来说，synchronized 是JVM层面的锁，是Java关键字，通过monitor对象来完成（monitorenter与monitorexit），对象只有在同步块或同步方法中才能调用wait/notify方法，ReentrantLock 是从jdk1.5以来（java.util.concurrent.locks.Lock）提供的API层面的锁
- synchronized 不需要用户去手动释放锁，ReentrantLock则需要用户去手动释放锁
- synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成； ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断
- synchronized为非公平锁 ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁
- synchronized不能绑定； ReentrantLock通过绑定Condition结合await()/singal()方法实现线程的精确唤醒
- synchronized锁的是对象，锁是保存在对象头里面的，根据对象头数据来标识是否有线程获得锁/争抢锁；ReentrantLock锁的是线程，根据进入的线程和int类型的state标识锁的获得/争抢
- synchronized的阻塞队列是头插法，ReentrantLock的是尾插法

### 12. 并发操作三大特性

1. 原子性：一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行
2. 可见性：是一个线程修改了某个共享变量，其状态能够立即被其他线程知晓，通常被解释为将线程本地状态反映到主内存上，volatile 就是负责保证可见性的。
3. 有序性：保证线程内串行语义，避免指令重排等。

### 13. Java的对象结构

- 对象头：Mark Word(和运行时状态有关的数据)、Class Point(指向当前对象类型所在方法区中的类型数据)
- 实例数据：初始化对象时，设置的属性，方法等
- 填充字节：保证对象大小是8bit的倍数

### 14. synchronized 底层如何实现？Java的锁机制

synchronized 代码块是由一对儿 monitorenter/monitorexit 指令实现的，Monitor 对象是同步的基本实现单元。在 Java 6 之前，Monitor 的实现完全是依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量级操作。现代的（Oracle）JDK 中，JVM 对此进行了大刀阔斧地改进，提供了三种不同的锁：偏斜锁（Biased Locking）、轻量级锁和重量级锁，大大改进了其性能。

- 四种状态：无锁、偏向锁(1.6引入)、轻量级锁(1.6引入)、重量级锁。
- 锁只能升级，不能降级(99%的情况)
- 无锁：无竞争，或者存在竞争，用非锁方式同步线程(CAS)
- 简单概括升级过程：当一把锁第一次被线程持有的时候是偏向锁，如果这个线程再次加锁还是偏向锁。如果别的线程来加锁(交替执行)膨胀为轻量锁，如果是资源竞争膨胀为重量锁
- 偏向锁：对象头里锁标志位是01，且前一位是1，就是偏向锁。然后再去读对象头前23bit，线程ID，通过线程ID来确认当前想要获得对象锁的这个线程。如果发现有多个线程在竞争，那么就会升级会轻量级锁
- 轻量级锁：锁标志位是00。当一个线程想要获得某个对象的锁时，如果是轻量级锁，线程会在自己的虚拟机栈中开辟一块被称为Lock Record的空间(存放对象头Mark Word的副本，以及owner指针)，线程通过CAS尝试获取锁，一旦获得，会复制对象头中的Mark Word，并且owner指针指向该对象。对象头中的前30bit会生成一个指针，指向Lock Record。其他线程再来，就会自旋。如果多个线程自旋，就会升级为重量级锁。
- 重量级锁：锁标志位是10。前面的位是一个地址，指向C++里面的一个对象ObjectMonitor。通过Monitor来管理资源。首先Entry Set有一些想进入Monitor的线程，处于Waiting状态。某一个线程A进入后，会处于Active状态，假设该线程执行时，遇到一个判断条件，需要它让出执行权，它将进入Wait Set，状态变为Waiting。此时Entry Set里的线程就有机会进入Monitor。假设线程B进入完成任务，可以通过notify的形式唤醒Wait Set中的线程A，让A进入Monitor继续执行任务，执行完后便可以退出。(synchronized同步机制)

### 15. 讲一下悲观锁和乐观锁

- 悲观锁：操作系统会悲观的认为，如果不严格同步线程调用，那么一定会产生异常，所以用互斥锁将资源锁定，只供一个线程调用，而阻塞其他线程。
- 乐观锁：由CAS来实现同步的工具，由于不会锁定资源，而且当线程需要修改共享资源的对象时，总是会乐观的认为，对象状态值没有被其他线程修改过，而是每次自己都会主动尝试去compare状态值。(其实是使用了无锁机制)

### 16. 用synchronized实现一个读写锁

```java
public class ReadWriteLock {
    private int readCount = 0;
    private int writeCount = 0;

    /**
     * 读锁
     */
    public synchronized void lockRead() throws InterruptedException {
        while (writeCount > 0) {
            wait();
        }
        readCount++;
    }

    /**
     * 释放读锁
     */
    public synchronized void unlockRead() {
        readCount--;
        notifyAll();
    }

    /**
     * 写锁
     */
    public synchronized void lockWrite() throws InterruptedException {
        while (writeCount > 0) {
            wait();
        }

        writeCount++;

        // 读锁为0时获取写锁
        while (readCount > 0) {
            wait();
        }
    }

    /**
     * 释放写锁
     */
    public synchronized void unlockWrite() {
        writeCount--;
        notifyAll();
    }
}
```

### 17. 非公平锁和公平锁

- 公平锁:按照请求锁的顺序分配，拥有稳定获得锁的机会，但是性能可能比非公平锁低
- 非公平锁：不按照请求的顺序分配，不一定拥有获得锁的机会，但是性能可能比公平锁高(后申请的线程，可能在前面休眠线程恢复前拿到锁，这样就可能提高并发的性能，这是因为，通常情况，唤醒一个挂起的线程，线程切换之间产生短暂延时，非公平锁就能利用这段时间来完成操作)

### 18. 说说ReentrantLock

- 一个成员变量Sync，这是一个内部类。它继承了AQS。核心方法就是nonfairTryAcquire和tryRelease等
- 在new一个ReentrantLock时，默认会sync = new NonfairSync();也就是非公平锁。这里面就重写了lock和tryAcquire两个方法。lock一上来就是CAS操作获取锁，不管前面有没有在等待，这里就体现它的非公平。但是只有一次机会，没成功就调用acquire方法(先tryAcquire，失败进入FIFO队列)。tryAquire方法就是直接调用父类的nonfairTryAcquire
- 在new一个ReentrantLock时，传入参数为true，就new一个公平锁fairSync。它也是重写了lock和tryAcquire两个方法。lock直接调用了父类AQS的acquire方法。tryAquire，如果锁空闲，且FIFO队列种没有排在当前线程之前的线程，就允许当前线程直接获取锁，获取失败返回false，然后在acquire方法种进入排队。如果锁不是空闲的，为了满足可重入，这里也进行一些判断，如果当前线程也不是持有锁的独占线程，也返回false。如果当前线程已经获取锁，对state进行累加，可以继续使用。
- 内部写好了，本身的方法直接调用内部类的方法就行。

### 19. 一个线程两次调用 start() 方法会出现什么情况？谈谈线程的生命周期和状态转移。

Java 的线程是不允许启动两次的，第二次调用必然会抛出 IllegalThreadStateException，这是一种运行时异常，多次调用 start 被认为是编程错误。

线程生命周期的不同状态，在 Java 5 以后，线程状态被明确定义在其公共内部枚举类型 java.lang.Thread.State 中

- 新建（NEW），表示线程被创建出来还没真正启动的状态，可以认为它是个 Java 内部状态。

- 就绪（RUNNABLE），表示该线程已经在 JVM 中执行，当然由于执行需要计算资源，它可能是正在运行，也可能还在等待系统分配给它 CPU 片段，在就绪队列里面排队。在其他一些分析中，会额外区分一种状态 RUNNING，但是从 Java API 的角度，并不能表示出来。

- 阻塞（BLOCKED），这个状态和我们前面两讲介绍的同步非常相关，阻塞表示线程在等待 Monitor lock。比如，线程试图通过 synchronized 去获取某个锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。

- 等待（WAITING），表示正在等待其他线程采取某些操作。一个常见的场景是类似生产者消费者模式，发现任务条件尚未满足，就让当前消费者线程等待（wait），另外的生产者线程去准备任务数据，然后通过类似 notify 等动作，通知消费线程可以继续工作了。Thread.join() 也会令线程进入等待状态。

- 计时等待（TIMED_WAIT），其进入条件和等待状态类似，但是调用的是存在超时条件的方法，比如 wait 或 join 等方法的指定超时版本，如下面示例：

  ```java
  public final native void wait(long timeout) throws InterruptedException;
  ```

- 终止（TERMINATED），不管是意外退出还是正常执行结束，线程已经完成使命，终止运行，也有人把这个状态叫作死亡。

### 20. 三个线程交替打印0-100

```java
// 使用synchronized来解决
public class Test1 {
    // 锁
    private static final Object LOCK = new Object();

    // 线程数量
    private static final int THREAD_COUNT = 3;

    // 开始
    private static volatile int start = 0;

    // 结束
    private static final int END = 100;

    private static class Print implements Runnable {

        private final int index;

        private Print(int index) {
            this.index = index;
        }

        @Override
        public void run() {
            while (start < END) {
                synchronized (LOCK) {
                    while (start % THREAD_COUNT != index) {
                        try {
                            LOCK.wait();
                        } catch (InterruptedException e) {
                            throw new RuntimeException(e);
                        }
                    }

                    if (start <= END) {
                        System.out.println(String.format("线程%s 打印结果：%s", index + 1, start));
                    }

                    start++;

                    LOCK.notifyAll();
                }
            }
        }
    }

    public static void main(String[] args) {
        for (int i = 0; i < THREAD_COUNT; i++) {
            new Thread(new Print(i)).start();
        }
    }
}

// 使用ReentrantLock配合CONDITION使用
public class Test1 {
    private static final ReentrantLock LOCK = new ReentrantLock();

    private static final Condition CONDITION = LOCK.newCondition();

    private static final int THREAD_COUNT = 3;

    private static volatile int start = 0;

    private static final int END = 100;

    private static class Print implements Runnable {

        private final int index;

        private Print(int index) {
            this.index = index;
        }

        @Override
        public void run() {
            while (start < END) {
                LOCK.lock();
                try {
                    while (start % THREAD_COUNT != index) {
                        CONDITION.await();
                    }

                    if (start <= END) {
                        System.out.printf("线程%s 打印结果：%s%n", index + 1, start);
                    }

                    start++;

                    CONDITION.signalAll();
                } catch (InterruptedException e) {
                    throw new RuntimeException(e);
                } finally {
                    LOCK.unlock();
                }
            }
        }
    }

    public static void main(String[] args) {
        for (int i = 0; i < THREAD_COUNT; i++) {
            new Thread(new Print(i)).start();
        }
    }
}
```



## MySQL数据库

### MySQL

#### 1. 一条SQL查询语句是如何执行的

- 连接器：连接器负责跟客户端建立连接、获取权限、维持和管理连接。
- 查询缓存：之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。但是大多时候弊大于利，查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。MySQL8.0版本直接将查询缓存模块删除了。
- 分析器：词法分析，语法分析
- 优化器：优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。
- 执行器：开始执行的时候，要先判断一下你对这个表有没有执行查询的权限，如果没有，就会返回没有权限的错误 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。如果有权限，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

#### 2. redo log和binlog的区别

- redo log：当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。
- bin log：
- redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用
- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”
- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

#### 3. 执行器和InnoDB引擎在执行update语句时的流程

> mysql> update T set c = c + 1 where ID = 2;

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成

#### 4. 数据库为什么能够恢复到半个月内任意一秒的状态？（两阶段提交、binlog）

当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

- 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；
- 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。

做到这一切的保证就是两阶段提交：redo log的写入拆成了两个步骤：prepare和commit。第一次写入redo log后，redo log处于prepare状态，然后写入bin log，最后提交事务，redo log处于commit状态。

#### 5. Sql的优化

1. sql尽量使用索引,而且查询要走索引
2. 对sql语句优化
   1. 子查询变成left join
   2. limit 分布优化，先利用ID定位，再分页
   3. or条件优化，多个or条件可以用union all对结果进行合并（union all结果可能重复）
   4. 不必要的排序
   5. where代替having,having 检索完所有记录，才进行过滤
   6. 避免嵌套查询
   7. 对多个字段进行等值查询时，联合索引

#### 6. MySQL记录存储(Page)

- 页头：记录页面控制信息，56字节，包括页的左右兄弟页面指针、页面空间使用情况等
- 记录：

  - 最大虚记录：比页内最大主键还大
  - 最小虚记录：比页内最小主键还小
- 记录堆：行记录存储区，分为有效记录和已删除记录两种
- 自由空间链表：已删除记录组成的链表
- 未分配空间：页面未使用空间
- Slot区：slot是一些页面有效记录的指针
- 页尾：页面最后部分、8个字节，主要存储页面的校验信息

#### 7. 怎么删除表的前10000行

- 第一种方式：直接执行delete from T limit 10000，但是单个语句占用时间长，锁的时间也比较长，而且大事务还会导致主从延迟
- 第二种方式：在一个连接里循环执行20次delete from T limit 500
- 第三种方式：在20个连接里执行delete from T limit 500，会认为造成锁冲突

#### 8. B-树和B+树的区别

- B-树内部节点是保存数据的;而B+树内部节点是不保存数据的，只作索引作用，它的叶子节点才保存数据。
- B+树相邻的叶子节点之间是通过链表指针连起来的，B-树却不是
- 查找过程中，B-树在找到具体的数值以后就结束，而B+树则需要通过索引找到叶子结点中的数据才结束
- B-树中任何一个关键字出现且只出现在一个结点中，而B+树可以出现多次

#### 9. 什么是change buffer？什么时候用？怎样用收益大？

- 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。
- 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。
- 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。反过来，假设一个业务的更新模式是写入之后马上会做查询，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。change buffer 反而起到了副作用。

#### 10. mysql为什么有时候查询突然慢一下？什么时候刷脏页（flush）？

1. redo log写满了，需要将一部分redo log写入到磁盘
2. 内存满了，需要淘汰一些数据页，如果是脏页就要先将脏页写到磁盘
3. mysql认为系统空闲的时候
4. mysql正常关闭的时候

#### 11. count(pk/*/1/字段)的区别

count(pk/*/1)统计的是符合条件的数据库表的行数，count(字段)统计的是符合条件的且列值不为NULL的数据库表的行数

字段有索引时：count(*) ≈count(1)>count(字段)>count(pk)。有索引的话，count(字段)会走二级索引，二级索引存储数据比主键索引少

字段无索引时：count(*) ≈count(1)>count(pk)>count(字段)。count(字段)无法走索引了，而主键还能走主键索引

count(1)不需要取出字段统计，就用常量1统计，count(字段)需要取出字段并且过滤掉NULL值。理论上count(1)更快。

count(*)内部做了很多优化，不取值，按行累加，效率很高

### InnoDB

#### 1. InnoDB内存结构

##### 缓冲池BufferPool

- 用于加速数据的访问和修改，通过将热点数据缓存在内存的方法，最大限度地减少磁

  盘 IO，加速热点数据读写。

- 默认大小128M，Buffer Pool 中数据**以页为存储单位**，其实现的数据结构是**以页为单位的单链**

  **表**。

- 由于内存的空间限制，Buffer Pool 仅能容纳最热点的数据

- Buffer Pool 使用LRU算法（Least Recently Used 最近最少使用）淘汰非热点数据页。

  - LRU：根据页数据的历史访问来淘汰数据，**如果数据最近被访问过，那么将来被访问的几率也**

    **更高**，优先淘汰最近没有被访问到的数据。

- 对于 Buffer Pool 中数据的查询，InnoDB 直接读取返回。对于 Buffer Pool 中数据的修改，

  InnoDB 直接在 Buffer Pool 中修改，并将修改写入redo log。

- buffer pool中的数据以页为存储单位，数据结构是单链表

##### change buffer

- 用于加速非热点数据中二级索引的写入操作
- 对二级索引的修改操作会录入到redo log中
- 缓冲到一定量或者系统空闲时进行merge操作（写入磁盘）
- 在系统表空间中有相应的持久化区域
- 其物理结构为一颗名为ibuf的B+树

##### 自适应哈希索引Adaptive Hash Index

- 用于实现对于热数据页的一次查询，是建立在索引之上的索引
- 作用：对频繁查询的数据页和索引页进一步提速
- 大小为buffer pool的1/64
- 若二级索引命中AHI
  - 从AHI获取索引页记录指针，再根据主键沿着聚簇索引查找数据
- 若聚簇索引命中AHI
  - 直接返回目标数据页的记录指针，根据记录指针可以直接定位数据页

##### 日志缓冲log buffer

- innodb使用log buffer来缓冲文件的写入操作
- 内存写入加上日志文件顺序写使得innodb日志写入性能极高

#### 2. InnoDB磁盘结构

在磁盘中，InnoDB 将所有数据都逻辑地存放在一个空间中，称为表空间（Tablespace）。表空间由段（Segment）、区（extent）、页（Page）组成。开启独立表空间innodb_file_per_table=1，每张表的数据都会存储到一个独立表空间，即表名.ibd 文件。关闭独占表空间innodb_file_per_table=0，则所有基于InnoDB存储引擎的表数据都会记录到系统表空间，即 ibdata1 文件

##### 系统表空间

系统表空间是 InnoDB 数据字典、双写缓冲、修改缓冲和回滚日志的存储位置，如果关闭独立表空间，

它将存储所有表数据和索引。它默认下是一个初始大小 12MB、名为 ibdata1 的文件，系统表空间所对应的文件由

innodb_data_file_path 定义。指定系统表空间文件自动增长后，其增长大小由 innodb_autoextend_increment 设置（默认为64MB）且不可缩减，即使删除系统表空间中存储的表和索引，此过程释放的空间仅仅是在表空间文件中标记为已释放而已，并不会缩减其在磁盘中的大小。

- 数据字典（Data Dictionary）： 数据字典是由各种表对象的元数据信息（表结构，索引，列信息等）组成的内部表
- 双写缓冲（Doublewrite Buffer）：双写缓冲用于保证写入磁盘时页数据的完整性，防止发生部分写失效问题。
- 修改缓冲（Change Buffer）： 内存中 Change Buffer 对应的持久化区域
- 回滚日志（Undo Log）：实现事务进行 回滚 操作时对数据的恢复。是实现多版本并发控制（MVCC）重要组成。在事务篇详细讲解

##### 独立表空间

- 独立表空间用于存放每个表的数据和索引。其他类型的信息，如：回滚日志、双写缓冲区、系统事务信息、修改缓冲等仍存放于系统表空间内。因此即使用了独立表空间，系统表空间也会不断增长。在5.7版本中默认开启
- 开启独立表空间（File-per-table TableSpace）（ innodb_file_per_table=ON ）之后，InnoDB 会为每个数据库单独创建子文件夹，数据库文件夹内为每个数据表单独建立一个表空间文件 table.ibd 。同时创建一个 table.frm 文件用于保存表结构信息。
- 每个独立表空间的初始大小是 96KB。

##### 通用表空间

通用表空间（General Tablespace）是一个由 CREATE TABLESPACE 命令创建的共享表空间，创建时必
须指定该表空间名称和 ibd 文件位置，ibd 文件可以放置于任何 MySQL 有权限的地方。该表空间内可以
容纳多张数据表，同时在创建时可以指定该表空间所使用的默认引擎。
通用表空间存在的目的是为了在系统表空间与独立表空间之间作出平衡。系统表空间与独立表空间中的
表可以向通用表空间移动，反之亦可，但系统表空间中的表无法直接与独立表空间中的表相互转化。

##### 回滚表空间

Undo TableSpace 用于存放一个或多个 undo log 文件。默认 undo log 存储在系统表空间中，MySql
5.7中支持自定义 Undo log 表空间并存储所有 undo log。一旦用户定义了 Undo Tablespace，则系统
表空间中的 Undo log 区域将失效。对于 Undo Tablespace 的启用必须在 MySQL 初始化前设置，
Undo Tablespace 默认大小为 10MB。Undo Tablespace 中的 Undo log 表可以进行 truncate 操作。

##### 临时表空间

MySQL 5.7 之前临时表存储在系统表空间中，这样会导致 ibdata 在使用临时表的场景下疯狂增长。5.7
版本之后 InnoDB 引擎从系统表空间中抽离出临时表空间（Temporary Tablespace），用于独立保存
临时表数据及其回滚信息。该表空间文件路径由 innodb_temp_data_file_path 指定，但必须继承
innodb_data_home_dir 。

#### 3. 表空间存储结构

##### 段

表空间由各个段（Segment）组成，创建的段类型分为数据段、索引段、回滚段等。由于 InnoDB 采用
聚簇索引与 B+ 树的结构存储数据，所以事实上数据页和二级索引页仅仅只是 B+ 树的叶子节点，因此数
据段称为 Leaf node segment，索引段其实指的是 B+ 树的非叶子节点，称为 Non-Leaf node
segment。一个段会包含多个区，至少会有一个区，段扩展的最小单位是区。

- 数据段称为 Leaf node segment
- 索引段称为 Non-Leaf node segment

##### 区

区（Extend）是由连续的页组成的空间，大小固定为 1MB，由于默认页大小为 16K，因此一个区默认存储 64 个连续的页。如果页大小调整为 4K，则 256 个连续页组成一个区。为了保证页的连续性，InnoDB 存储引擎会一次从磁盘申请 4 ~ 5 个区。

##### 页

- 页（Page）是 InnoDB 的基本存储单位，每个页大小默认为 16K
- 操作系统读写磁盘最小单位是页，4k
- 磁盘存储数据量最小单位512byte

##### 行

- innodb的数据是以行为单位存储、一个页中包含多个行
- innodb提供4种行格式
  - compact
  - redundant
  - dynamic
  - compressed
- 默认行格式为dynamic

### 事务

#### 1. 事务四大特性ACID

1. 原子性A，要么执行，要么不执行
2. 一致性C，事务前后数据的完整性必须保持一致
3. 隔离性I，多个用户并发使用数据库时，批次事务操作数据不能互相干扰，所以要隔离。
4. 持久性D，一旦事务提交，对数据的改变就是永久的

#### 2. 事务的隔离级别

1. 读未提交RU：Read Uncommitted 一个事务还没提交时，它做的变更就能被别的事务看到（可能发生脏读、不可重复读和幻读问题）
2. 读已提交RC：Read committed 一个事务提交之后，它做的变更才会被其他事务看到（可能发生不可重复读和幻读问题）
3. 可重复读RR：Repeatable Read 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的（可能发生幻读问题），但其实mysql已经将幻读问题通过其他方式解决
4. 可串行化：Serializable 同时只能执行一个事务，相当于事务中的单线程

#### 3. 事务并发可能出现的情况

1. 脏读：指一个事务读取到另一个事务未提交的数据
2. 不可重复读：指一个事务读到另一个事务已经update的数据，引发事务中的多次查询结果不一致
3. 虚读/幻读：一个事务读到另一个事务已经Insert的数据，导致事务中多次查询的结果不一致

#### 4. 什么是MVCC？

- MVCC全称叫多版本并发控制，是RDBMS常用的一种并发控制方法，用来对数据库数据进行并发访问，实现事务。核心思想：读不加锁，读写不冲突
- 实现原理：数据快照，不同事务访问数据快照中不同版本的数据
- 关键要素：Undo log和Read View

#### 5. undo log

- Insert Undo log：是在Insert操作中产生的Undo日志。Insert 操作的记录只对事务本身可见，对于其它事务此记录是不可见的，所以 Insert Undo Log 可以在事务提交后直接删除而不需要进行回收操作。
- Update Undo log：是Update或Delete 操作中产生的Undo日志。Update操作会对已经存在的行记录产生影响，为了实现MVCC多版本并发控制机制，因此Update Undo日志不能在事务提交时就删除，而是在事务提交时将日志放入指定区域，等待 Purge 线程进行最后的删除操作。

#### 6. Read View

ReadView是张存储事务id的表，主要包含当前系统中有哪些活跃的读写事务，把它们的事务id放到一个列表中。结合Undo日志的默认字段【事务trx_id】来控制那个版本的Undo日志可被其他事务看见。

##### 四个列：

- m_ids：表示在生成ReadView时，当前系统中活跃的读写事务id列表
- m_low_limit_id：事务id下限，表示当前系统中活跃的读写事务中最小的事务id，m_ids事务列表中的最小事务id
- m_up_limit_id：事务id上限，表示生成ReadView时，系统中应该分配给下一个事务的id值
- m_creator_trx_id：表示生成该ReadView的事务的事务id

##### 生成时机

- 开启事务之后，在第一次查询(select)时，生成ReadView
- RC 和 RR 隔离级别的差异本质是因为MVCC中ReadView的生成时机不同，详细生成时机在案例中分析

#### 7. 事务隔离机制（可重复读）

##### 事务的启动时机

- 第一种启动方式begin/start transaction，一致性视图是在执行第一个快照读语句时创建的；
- 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的

##### 数据的row trx_id

每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id 

##### 一致性视图read view

innodb为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）

##### 数据版本可见性规则

- 如果小于低水位，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
- 如果大于高水位，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
- 如果处在低水位和高水位之间，那就包括两种情况
  - a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；
  - b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。

##### 数据的查询

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

1. 版本未提交，不可见；
2. 版本已提交，但是是在视图创建后提交的，不可见；
3. 版本已提交，而且是在视图创建前提交的，可见。

##### 当前读和快照读

快照读：读不加锁，读取的是版本链的快照数据，默认的读都是快照读

```mysql
select * from t where ?
```

当前读：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。

除了 update 语句外，select 语句如果加锁，也是当前读。

```mysql
select k from t where id=1 lock in share mode;（读锁，s锁，共享锁）
select k from t where id=1 for update;（写锁，x锁，徘他锁）
insert into t values ();（写锁）
update t set ? where ?;（写锁）
delete from table where ?;（写锁）
```

##### 可重复读和读已提交这俩个隔离级别的区别

- 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
- 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

##### 实战

**可重复读隔离级别**

```mysql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `k` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, k) values(1,1),(2,2);
```



| 事务A                                       | 事务B                                       | 事务C                          |
| ------------------------------------------- | ------------------------------------------- | ------------------------------ |
| start transaction with consistent snapshot; |                                             |                                |
|                                             | start transaction with consistent snapshot; |                                |
|                                             |                                             | update t set k=k+1 where id=1; |
|                                             | update t set k=k+1 where id=1;              |                                |
|                                             | select k from t where id=1;                 |                                |
| select k from t where id=1;                 |                                             |                                |
| commit;                                     |                                             |                                |
|                                             | commit;                                     |                                |

结果：事务B查询到的k是3，事务A查询到的k是1

| 事务A                                       | 事务B                                       | 事务C                                       |
| ------------------------------------------- | ------------------------------------------- | ------------------------------------------- |
| start transaction with consistent snapshot; |                                             |                                             |
|                                             | start transaction with consistent snapshot; |                                             |
|                                             |                                             | start transaction with consistent snapshot; |
|                                             |                                             | update t set k=k+1 where id=1;              |
|                                             | update t set k=k+1 where id=1;              |                                             |
|                                             | select k from t where id=1;                 |                                             |
|                                             |                                             | commit;                                     |
| select k from t where id=1;                 |                                             |                                             |
| commit;                                     |                                             |                                             |
|                                             | commit;                                     |                                             |

由于两阶段锁协议，事务C还没释放锁，所以事务B得等到事务C释放之后才能继续它的当前读。

**读已提交隔离级别**

| 事务A                       | 事务B                          | 事务C                          |
| --------------------------- | ------------------------------ | ------------------------------ |
| begin;                      |                                |                                |
|                             | begin;                         |                                |
|                             |                                | update t set k=k+1 where id=1; |
|                             | update t set k=k+1 where id=1; |                                |
|                             | select k from t where id=1;    |                                |
|                             | **read view**                  |                                |
| select k from t where id=1; |                                |                                |
| **read view**               |                                |                                |
| commit;                     |                                |                                |
|                             | commit;                        |                                |

由于是读已提交的隔离级别，read view的创建时机不同，事务A看到的k是2，事务B看到的是3。

### 索引

#### 1. 索引的常见模型

- Hash：适用于只有等值查询的场景，比如Memcached及其一些NoSQL引擎
- 有序数组：在等值查询和范围查询场景中的性能就都非常优秀。只适用于静态存储引擎。
- 二叉搜索树：查询是O(logN)，维护它是一颗平衡二叉树也需要O(logN)，数据库大多不适用二叉树，树高过高，会使用N叉树

#### 2.InnoDB的索引模型

- 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的
- 每一个索引在 InnoDB 里面对应一棵 B+ 树。

#### 3. 主键索引和普通索引的区别

- 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引
- 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引
- 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树
- 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表

#### 4. 聚簇和非聚簇索引的区别是什么

- 聚簇索引：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引，所以主键就是聚簇索引，修改聚簇索引其实就是修改主键。
- 非聚簇索引：索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引
- MySQL中Innodb中两者都有，而myisam只有非聚簇索引

#### 5. 什么是覆盖索引

- 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。该操作能用于性能优化。

#### 6. 什么是最左前缀

- 联合索引的最左N个字段，也可以是字符串索引的最左M个字符

#### 7. 在建立联合索引的时候，如何安排索引内的字段排序

- 这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

#### 8. 什么是索引下推

- 是组合索引查询优化的手段

- ```mysql
  show variables like 'optimizer_switch';
  
  -- 开启
  set optimizer_switch = 'index_condition_pushdown=on';
  ```

- like 'hello%' and age > 10检索，MySQL5.6之前，会对匹配的数据进行回表查询。5.6之后，会先过滤掉age < 10的数据，再进行回表查询，减少回表率，提升检索速度。

- 举例：现在有(a,b,c)的联合索引，使用select * from t where a=13 and b>15 and c=5 and d=6;走(a,b)索引，然后过滤掉c!=5的数据之后再去回表，减少回表率

#### 9. 索引在什么情况下失效

- 在索引列上做了函数运算，不过mysql8之后可以加函数索引解决这个问题
- 没有符合最左匹配法则，联合索引和like这两种情况
- 索引列出现隐式转换的时候，比如索引列是字符串，但是sql查询里没有使用引号
- 使用or，但是前后没有同时使用索引，可以使用union来改进
- 使用不等于 !=或者<>
- 使用is null或者is not null
- 使用explain来看到底走了哪些索引

#### 10. mysql的索引有哪些

- FULLTEXT：全文索引，倒排索引
- HASH：哈希索引，适合等值查询，不适合范围查询
- BTREE：B+树，
- RTREE：优势在于范围查找

#### 11. 唯一索引和普通索引怎么选择

- 这两者在查询上没有差别，主要是更新性能的影响。尽量使用普通索引
- 如果所有更新后面，马上要查，那么应该关闭change buffer
- 实际中，普通索引和change buffer配合使用

#### 12. 索引的设计原则

- 代码先行，索引后上。
- 选择合适的列。选择经常用于查询、连接、过滤、排序的列作为索引列
- 联合索引尽量覆盖业务上多个列
- 尽量使用覆盖索引
- 避免过长索引。长字符串可以用前缀索引
- 选择适当的索引类型。如普通索引、唯一索引、全文索引等
- 如果有排序，考虑在排序的列上加索引
- 避免冗余索引
- 考虑区分度。尽量不要挑选区分度不高的字段作为索引
- 定期维护索引。删除不再使用的索引、重建碎片化的索引
- 多表join关联查询on两边的字段
- 频繁更新的不建议使用索引

#### 13. mysql为什么选错索引

- 数据库统计索引区分度不准，使用采样统计，导致优化器判断使用不同情况下的预计扫描行不准确

  - 解决：可以使用analyze table tableName 来让MySQL重新统计

- sql有排序或使用临时表，优化器容易因考虑其他因素反而选错了索引

  - 解决：1、使用force index强行使用某个索引

  - 2、修改SQL语句引导优化器选择正确索引。例如：

    ```mysql
    select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;
    
    select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b,a limit 1;
    ```

  - 3、增加或删除索引，从而使用正确索引

#### 14. 如何给字符串字符段加索引

- 直接创建完整索引，这样可能比较占用空间
- 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引
- 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题，不支持范围扫描
- 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，不支持范围扫描，例如身份证字段，可以创建一个整数字段存身份证的hash值，在这个整数字段上创建索引

### 锁

#### 1. MySQL的锁

- 按锁功能划分：
  - 共享锁 shard lock S锁 读锁：读锁之间是共享的，读锁之间互相不阻塞 select * from t lock in share mode
  - 排他锁 exclusive lock x锁 写锁：写锁是排他的，写锁阻塞其他的读和写锁 select * from t for update

- 按粒度划分：
  - 全局锁：全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。典型使用场景是做全库逻辑备份。对于全部是InnoDB引擎的库，建议使用-Single-transaction参数，这里是使用事务的可重复读隔离级别，使用后能开启一个事务，确保拿到一致性视图。
  - 表级锁：MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。与 FTWRL (Flush tables with read lock)类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。表锁一般用在数据库引擎不支持行锁的时候才被用到。
    - 表读锁 table read lock：阻塞对当前表的写，但不阻塞读
    - 表写锁 table write lock：阻塞对当前表的读和写
    - 元数据锁 meta data lock：不需要显式指定，在访问表时会被自动加上，作用保证读写的正确性
      - 当对表做增删改查操作的时候加元数据读锁
      - 当对标做结构变更操作的时候加元数据写锁

    - 自增锁 auto-inc locks：特殊的表级锁，自增列事务性插入操作时产生

  - 行锁：MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。
    - 记录锁 record locks：锁定索引中一条记录
    - 间隙锁 gap locks：仅仅锁住一个索引区间
    - 临建锁 next-key locks：记录锁和间隙锁的组合，解决幻读的问题
    - 插入意向锁 insert intention locks：做insert时添加的对记录id的锁
    - 意向锁：存储引擎级别的“表级”锁


#### 2. 如何安全地给小表加字段

在MySQL5.5版本引入了元数据锁（meta data lock，MDL），对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。

如果有一个类似alter table t add f int；这样的语句被阻塞了，后续所有的语句都会被阻塞，等于这个表完全不可读写了。

首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。

比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。

#### 3. 两阶段锁协议

- 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

#### 4. 出现死锁应该怎么办

- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。默认就是on。

#### 5. 怎么解决由热点行更新导致的性能问题

- 问题的原因在于死锁检测要耗费大量的CPU资源
- 方法一：假如能确保这个业务一定不会出现死锁，可以临时把死锁检错关掉
- 方法二：控制并发度。比如控制同一行最多就10个线程在更新，可以考虑使用中间件实现，或者修改MySQL源码，基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。但是如果有太多客户端同时进来，并发度也上去了。解决的基本思路就是在进入引擎之前排队。
- 方法三：你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。

#### 6. innodb的行级锁

mysql的行级锁是由存储引擎实现，innodb行锁是通过给索引上的索引项加锁来实现的

只有通过索引条件检索的数据innodb才使用行级锁，否则innodb都使用表锁

按照范围分类：记录锁、间隙锁、临建锁、插入意向锁

按功能分：读锁、写锁

如何加行锁？update、delete、insert会自动给涉及的数据集加写锁；对于普通select，不会加任何锁。lock in share mode;（读锁，s锁，共享锁）；for update;（写锁，x锁，排他）

案例

```mysql
CREATE TABLE `t1_simple` (
    `id` int(11) NOT NULL,
    `pubtime` int(11) NULL DEFAULT NULL,
    PRIMARY KEY (`id`) USING BTREE,
    INDEX `idx_pu`(`pubtime`) USING BTREE
) ENGINE = InnoDB;
INSERT INTO `t1_simple` VALUES (1, 10);
INSERT INTO `t1_simple` VALUES (4, 3);
INSERT INTO `t1_simple` VALUES (6, 100);
INSERT INTO `t1_simple` VALUES (8, 5);
INSERT INTO `t1_simple` VALUES (10, 1);
INSERT INTO `t1_simple` VALUES (100, 20);
```

##### 记录锁

记录锁（Record Locks）仅仅锁住索引记录的一行，在单条索引记录上加锁。记录锁锁住的永远是索引，而非记录本身，即使该表上没有任何显示索引，那么innodb会在后台创建一个隐藏的聚簇索引索引，那么锁住的就是这个隐藏的聚簇索引索引

```mysql
-- 加记录读锁
select * from t1_simple where id = 1 lock in share mode;
-- 加记录写锁
select * from t1_simple where id = 1 for update;
-- 新增，修改，删除加记录写锁
insert into t1_simple values (1, 22);
update t1_simple set pubtime=33 where id =1;
delete from t1_simple where id =1;
```

##### 间隙锁

- 间隙锁(Gap Locks)，仅仅锁住一个索引区间（开区间，不包括双端端点）。
- 间隙锁可用于防止幻读，保证索引间隙不会被插入数据。
- 在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。
- 在可重复读（REPEATABLE READ）这个隔离级别下生效。

```mysql
-- session1
begin;
select * from t1_simple where id > 4 for update; -- 加间隙锁
-- 临键锁区间(4,100+)
commit;

-- session2
begin;
insert into t1_simple values (7,100); -- 阻塞
insert into t1_simple values (3,100); -- 成功
commit;
```

##### 临建锁

- 临键锁(Next-Key Locks)相当于记录锁 + 间隙锁【左开右闭区间】，例如（5,8]
- 默认情况下，innodb使用临键锁来锁定记录，但在不同的场景中会退化
  - 唯一性字段等值（=）且记录存在，退化为记录锁
  - 唯一性字段等值（=）且记录不存在，退化为间隙锁
  - 唯一性字段范围（< >），还是临键锁
  - 非唯一性字段，默认是临键锁
- 当查询的索引含有唯一属性的时候，临键锁会进行优化，将其降级为记录锁，即仅锁住索引本身，不是范围。

```mysql
-- session1
begin;
select * from t1_simple where pubtime = 20 for update;
-- 临键锁区间(10,20],(20,100]
commit;

-- session2
begin;
insert into t1_simple values (16, 19); -- 阻塞
select * from t1_simple where pubtime = 19 for update; -- 不阻塞
select * from t1_simple where pubtime = 20 for update; -- 阻塞
insert into t1_simple values (16, 50); -- 阻塞
insert into t1_simple values (16, 101); -- 成功
commit;
```

##### 插入意向锁

- 插入意向锁（Insert Intention Locks）是一种在 INSERT 操作之前设置的一种特殊的间隙锁。
- 插入意向锁表示了一种插入意图，即当多个不同的事务，同时往同一个索引的同一个间隙中插入数据的时候，它们互相之间无需等待，即不会阻塞。
- 插入意向锁不会阻止插入意向锁，但是插入意向锁会阻止其他间隙写锁（排他锁）、记录锁。

```mysql
-- session1
-- 第一次
begin;
insert into t1_simple values (60, 200);
-- 插入意向锁区间(10,100)
commit;
-- 第二次
begin;
select * from t1_simple where id > 10 for update;
-- 临键锁（区间）写锁区间(10,100+)
commit;

-- session2
-- 第一次
begin;
insert into t1_simple values (70, 300); -- 没有发生阻塞
-- 插入意向锁区间(10,100)
commit;
-- 说明两个插入意向锁之间是兼容的，可以共存!
-- 第二次
begin;
insert into t1_simple values (90, 300); -- 被阻塞，阻塞的原因在于，插入意向锁和其他写锁之间是互斥的！
commit;
```

#### 7. 行锁加锁规则

- 主键索引
  - 等值条件，命中，加记录锁
  - 等值条件，未命中，加间隙锁
  - 范围条件，命中，包含where条件的临键区间，加临键锁
  - 范围条件，没有命中，加间隙锁

- 辅助索引
  - 等值条件，命中，命中记录的辅助索引项 + 主键索引项加记录锁，辅助索引项两侧加间隙锁
  - 等值条件，未命中，加间隙锁
  - 范围条件，命中，包含where条件的临键区间加临键锁。命中记录的id索引项加记录锁
  - 范围条件，没有命中，加间隙锁

### 实战

#### 1. 现在有学生表、科目表、成绩表，求总分最高的学生和单科分数最高的学生

```mysql
student(id, name)
course(id, name)
score(id, course_id, student_id, score)

-- 在分数表求最大分数
select sum(score) from score group by student_id order by sum(score) desc limit 1;

-- 求分数表最大分数的student_id
select distinct(student_id), sum(score) from score group by student_id having sum(score) = (select sum(score) from score group by student_id order by sum(score) desc limit 1);

-- 求总分最高的学生 
select s.name, t.score from student s right join (select distinct(student_id), sum(score) score from score group by student_id having sum(score) = (select sum(score) from score group by student_id order by sum(score) desc limit 1)) t on s.id = t.student_id;

-- 在分数表单科最高分
select max(score) max_score, course_id from score group by course_id;

-- 在分数表单科最高分的学生id
select student_id, s1.course_id, s2.max_score from score s1 right join (select max(score) max_score, course_id from score group by course_id) s2 on s1.course_id = s2.course_id and s1.score = s2.max_score;

-- 求单科分数最高的学生
select s.name, c.name, s2.max_score from score s1 right join (select max(score) max_score, course_id from score group by course_id) s2 on s1.course_id = s2.course_id and s1.score = s2.max_score left join course c on c.id = s1.course_id left join student s on s.id = student_id;
```



## Redis数据库

### 1. redis的底层数据结构

#### string

简单动态字符串 (Simple Dynamic String)SDS。不用c语言字段的char*，因为

1. 计算长度是O(n)
2. 对于二进制不友好，比如存储图片的二进制，可能会提前遇到字符串的结尾标志
3. 不可修改

redis的结构体

```c
struct --attribute_- ((-_packed__)) sdshdr8{
    uint8_t len;/* buf已保祥的字符串字节数，不包含结束标示*/
    uint8_t alloc;/* buf申请的总的字节数，不包含结束标示*/
    char buf [];
}

// 忽略sdshdr16、sdshdr32、sdshdr64、sdshdr5
```

比如字符串name的sds结构如下：

| len：4 | alloc：4 | n    | a    | m    | e    | \0   |
| ------ | -------- | ---- | ---- | ---- | ---- | ---- |

后面会多存一个 \0,实际存储多一个字节

#### IntSet

IntSet是Redis中set集合的一种实现方式，基于整数数组来实现，并且具备⻓
度可变、有序等特征。

```c
typedef struct intset {
    uint32_t encoding; /*编码方式，支持存放16位、32位、64位*/
    uint32_t Length;/* 元素个数 */
    int8_t contents[];/*整数数组，保存集合数据*/
}
```

假设原本有一个intset，元素是{5,10,20}，这时候存的都是16位，两个byte的数据。新增一个50000，那么会先进行扩容，两个byte扩展为4个byte，倒着扩容的，顺序是20，10，5，encoding改成INTSET_ENC_INT32，length改成4。 如果是要扩容的情况，就直接看是大于0还是小于0，小于0插最前面，大于0插最后面。如果不扩容，就二分查找法找到要插入的位置然后插入。

#### Dict

整个redis就类似于一个java1.7的hashmap。用Dict来实现

```c
typedef struct dictht {
    // entry数组 数组中保存的是指向entry的指针
    dictEntry **table;
    //哈希表大小
    unsigned Long size;
    //哈希表大小的掩码，总等于size - 1
    unsigned Long sizemask;
    // entry个数
    unsigned Long used;
}

typedef struct dictEntry {
    void *key; // 键
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;//值
    //下一个Entry的指针
    struct dictEntry *next;
}

typedef struct dict {
    dictType *type;// dict类型，内置不同的hash函数
    void *privdata; // 私有数据，在做特殊hash运算时用
    dictht ht[2];// 一个Dict包含两个哈希表，其中一个是当前数据，另一个一般是空，rehash时使用
    Long rehashidx; // rehash的进度，-1表示未进行
    int16_t pauserehash；// rehash是否暂停，1则暂停，o则继续
}
```

Dict的负载因子LoadFactor = used/size，新增时或者删除时都会检查，会进行扩容或者缩容

rehash过程：

1. 计算新hash表的realsize，即第一个大于等于dict.ht[0].used的2^n
2. 按照新的realsize申请内存空间，创建dictht，并赋值给dict.ht[1]
3. 设置rehashidx= 0，标示开始rehash
4. 将dict.ht[0]中的每一个dictEntry都rehash到dict.ht[1]
   每次执行新增、查询、修改、删除操作时，都检查一下dict.rehashidx是否大于-1，如果是则将ht[0].table[rehashidx]的entry链表rehash到dict.ht[1]，井且将rehashidx++。直至dict.ht[0]的所有数据都rehash到dict.ht[1] (渐进式hash，不会一次性就copy到新的hashTable)
5. 将dict.ht[1]赋值给dict.ht[0]，给dict.ht[1]初始化为空哈希表
6. 将rehashidx赋值为-1，代表rehash结束
7. 在rehash过程中，新增操作，则直接写入ht[1]，查询、修改和删除则会在dict.ht[0]和dict.ht[1]依次查找并执行。这样可以确保h[0]的数据只减不增，随着rehash最终为空

#### ZipList

压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束。

| zlbytes | tltail | zllen | entry1 | entry2 | ...  | entryN | zlend |
| ------- | ------ | ----- | ------ | ------ | ---- | ------ | ----- |

在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。

其中entry的结构如下：

| previous_entry_length | encoding | content |
| --------------------- | -------- | ------- |

- previous_entry_length：前一节点的字节大小，占1个或5个字节。如果前一节点的⻓度小于254字节，则采用1个字节来保存这个⻓度值。如果前一节点的⻓度大于254字节，则采用5个字节来保存这个⻓度值，第一个字节为0xfe，后4个字节才是真实⻓度数据
- encoding：编码属性，记录content的数据类型（字符串还是整数）以及content的字节数，占用1个、2个或5个字节
- Content：负责保存节点的数据，可以是字符串或整数

zipList可能导致的问题：连锁更新(Cascade Update）

如果每个entry都是250个字节，那么previous_entry_length只需要一个字节存就可以了，而如果恰好在最前面插入一个254字节的数据，就会导致后续的每一个entry的previous_entry_length都要从1个字节变成5个字节。

QuickList

zipList需要连续内存空间，存储数据也不能太多，怎么办？quickList是一个有前后指针的列表，每个node就是一个zipList，相当于就是把数据打碎了，但不是很碎，然后用一个有前后指针的列表来管理。能够设置每个zipList的大小，也能设置前后各有多少个zipList不压缩，其余压缩（更加节省空间）。

#### SkipList

有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。结构如下：

```c
typedef struct zskiplist {
    //头尾节点指针
    struct zskiplistNode *header, *tail;
    //节点数量
    unsigned Long Length;
    // 最大的索引层级，默认是1
    int Level;
} zskiplist;

typedef struct zskiplistNode {
    sds ele; //节点存储的值
    double score;// 节点分数，排序、查找用
    struct zskiplistNode *backward;// 前一个节点指针
    struct zskiplistLevel {
        struct zskiplistNode * forward;//下一个节点指针
        unsigned Long span;//索引跨度
    } level[];//多级索引数组
} zskiplistNode;
```

#### redisObject

redis的value都是redisObjec，管你什么类型都统统封装成redisObject，结构如下：

```c
typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:LRU_BITS;
    int refcount;
    void *ptr;
} robj;
```

type：对象类型，分别是string、hash、list、set、zset，占4个bit位

encoding：底层编码方式，共有11种，占4个bit

lru：表示该对象最后一次被访问的时间，其占用24个bit

refcount：对象引用计数器

\*ptr：指针，指向实际存放数据的空间

| 编码方式                | 说明                 |
| ----------------------- | -------------------- |
| OBJ_ENCODING_RAW        | raw编码动态字符串    |
| OBJ_ENCODING_INT        | long类型的整数字符串 |
| OBJ_ENCODING_HT         | hash表（dict）       |
| OBJ_ENCODING_ZIPMAP     | 废弃                 |
| OBJ_ENCODING_LINKEDLIST | 双端链表             |
| OBJ_ENCODING_INTSET     | 整数集合             |
| OBJ_ENCODING_SKIPLIST   | 跳表                 |
| OBJ_ENCODING_EMBSTR     | embstr的动态字符串   |
| OBJ_ENCODING_QUICKLIST  | 快速列表             |
| OBJ_ENCODING_STREAM     | stream流             |

| 数据类型   | 编码方式                                             |
| ---------- | ---------------------------------------------------- |
| OBJ_STRING | int、embstr、raw                                     |
| OBJ_LIST   | LinkedList和ZipList（3.2以前）、QuickList（3.2以后） |
| OBJ_SET    | intset、HT                                           |
| OBJ_ZSET   | ZipList、HT、SkipList                                |
| OBJ_HASH   | ZipList、HT                                          |

### 2. redis单线程为什么这么快？（redis网络模型）

Redis 单线程是指它对网络 IO 和数据读写的操作采用了一个线程，而 采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的 Redis 也能获得 高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()/recv() 潜在的 网络 IO 操作阻塞点。

使用select/epoll等机制。select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升Redis 的响应性能。

select就是用1024个bit来代表1024个FD，有就绪的就通知，然后用户进程需要进行遍历才知道哪些是就绪的FD。存在的问题：需要将整个fd_set从⽤户空间拷⻉到内核空间，select结束还要再次拷⻉回⽤户空间；select⽆法得知具体是哪个fd就绪，需要遍历整个fd_set；fd_set监听的fd数量不能超过1024

poll是在select上稍微改进了一下。过程：1.创建pollfd数组，向其中添加关注的fd信息；2.调⽤poll函数，将pollfd数组拷⻉到内核空间，转链表存储；3.内核遍历fd，判断是否就绪；4.数据就绪或超时后，拷⻉pollfd数组到⽤户空间，返回就绪fd数量n；5.判断n是否⼤于0，⼤于0则遍历pollfd数组，找到就绪的fd。和select相比，无大小限制了，但是监听FD过多，遍历时间也更长。

epoll就是在内核空间，用一个红黑树来存FD（FD直接进入内核空间，无需多余拷贝），如果这个FD上面有相应的事件了，就放到list里。用户进程无需遍历所有的FD，就能知道哪些FD就绪了。

### 3. redis的持久化

#### AOF

##### 定义

记录日志，但是是执行写入操作后再记。（不会阻塞当前这个写操作，但是会影响紧接着的下一个写操作，还有个好处就是不用检查语法是否正确）

##### 写回的配置项

Always：同步写回

Everysec：每秒写回

No：由操作系统来控制什么时候写回

性能越来越好，丢失数据越来越多

##### 日志文件太大怎么办

有重写机制，一个key可能被设置多次，重写机制就是浓缩日志，有一条最新的设置key的语句就行。这个机制是重新启了一个新线程，复制了一份当时的内存数据来进行操作的。不会阻塞主线程。

#### RDB

##### 定义

记录某一时刻的数据，相比于AOF，能够更快恢复。

##### 是否阻塞？

redis提供了两个命令，分别是save和bgsave；

save：在主线程执行，会导致阻塞

bgsave：创建一个子进程，专门用来写入RDB文件，避免主线程阻塞。默认配置

##### 执行RDB时，如果有写入操作，会影响快照吗？

copy-on-write机制。首先bgsave子进程本身是由主线程fork生成的，共享主线程的所有内存数据。如果此时有个写入操作，这块数据会被复制一份，生成副本，bgsave会把副本数据写入RDB文件。而主线程仍然可以直接修改原来的数据。

##### 快照的间隔时间？

并不是间隔越小越好，首先fork子进程这个操作本身就是阻塞主线程的。然后假如数据很多，但是间隔时间短，很可能上一次还没结束，下一次就开始。

针对这个问题，我们可以做增量快照。做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。但是也不完美，因为会引入额外的空间来记录哪些是修改过的数据。

#### 最佳实践：

- RDB+AOF：数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择
- RDB：如果允许分钟级别的数据丢失
-  AOF：优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。

## 消息队列

### 1. 消息队列解决的问题

- 解耦
- 异步
- 削峰

### 2. 保证MQ重复消费幂等性

- 数据写库时, 首先检查主键, 如果有数据, 则不能插入, 进入一次update
- 写redis, 就没问题, redis的set天然幂等
- 生产者发消息时带上全局唯一ID, 消费者拿到消息后, 先去redis查这个id, 没有消费过就处理, 然后写入这个id到redis

### 3. 保证MQ消息不丢

- 生产者的问题: 使用confirm机制
- MQ的问题: 持久化到磁盘, queue持久化, 消息也持久化. 这个机制可以和confirm机制配合使用
- 消费者的问题: 打开autoAck机制或者自己手动Ack
