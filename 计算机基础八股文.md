# 计算机基础八股文

## 计算机网络

### 1. OSI与TCP/IP各层的结构与功能,都有哪些协议?

- 五层协议各层作用
  - 应用层(application-layer)的任务是通过应用进程间的交互来完成特定网络应用。应用层的协议包括域名系统DNS、HTTP协议、电子邮件的SMTP协议。这一层的数据都叫报文
  - 运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。运输层的协议：TCP(提供面向连接的，可靠的数据传输服务)和UDP(提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）)
  - 在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信⼦网。网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。 常用IP协议，分组也叫IP数据报
  - 数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。将IP数据报组装成帧。
  - 物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。
- OSI多的两层
  - 会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。
  - 表示层的具体功能如下：
    数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。
    数据的编码：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。
    压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。
    数据的加密和解密：可以提高网络的安全性。
- TCP/IP只有四层
  - 网络接口层包括用于协作IP数据在已有网络介质上传输的协议。它定义像地址解析协议(Address Resolution Protocol,ARP)这样的协议，提供TCP/IP协议的数据结构和实际物理硬件之间的接口。

### 2. OSI七层图片

- ![](G:/javaWorkspace_idea/ylJava/images/OSI七层模型.gif)

### 3. TCP三次握手和四次挥手

- TCP三次握手

  -  服务器通过创建socket、bind、listen完成初始化，通过accept完成连接的建立。
  -  客户端通过创建socket、connect发起连接建立请求

  ![](G:/javaWorkspace_idea/ylJava/images/TCP三次握手.jpg)

- TCP四次挥手

  ![](G:/javaWorkspace_idea/ylJava/images/TCP四次挥手.jpg)

### 4. 为什么握手是三次

- 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误
- 第一次握手：client自己什么都不能确认。server确认对方发送正常，自己接收正常
- 第二次握手：client确认自己发送正常，接收正常，对方发送正常，接收正常
- 第三次握手：server确认自己发送正常，对方接收正常
- 例子：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。

### 5. 为什么挥手是四次

- 本质的原因是tcp是全双公的，要实现可靠的连接关闭，A发出结束报文FIN，收到B确认后A知道自己没有数据需要发送了，B知道A不再发送数据了，自己也不会接收数据了，但是此时A还是可以接收数据，B也可以发送数据；当B发出FIN报文的时候此时两边才会真正的断开连接，读写分开。

### 6. 如果TCP连接时某一次握手丢失了,会发生什么

- 第一次握手丢失：会触发超时重传机制，在linux里，最大重传次数由tcp_syn_retries内核参数控制，默认是5。通常每次等待时间是上一次的两倍。超过5次后还是没有回应ACK，就直接断开TCP连接。

- 第二次握手丢失：
  - 客户端会认为自己的报文丢失了，会触发超时重传机制，重新发SYN报文
  - 服务端也会触发超时重传机制，重传SYN-ACK报文，linux里最大重传次数由tcp_synack_retries内核参数决定
- 第三次握手丢失：服务端也会触发超时重传机制，重传SYN-ACK报文

### 7. 如果TCP断开连接时某一次挥手丢失了，会发生什么

- 第一次挥手：客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，直接进入到 close 状态。
- 第二次挥手：客户端会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。
- 第三次挥手：服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。
- 第四次挥手：服务端就会重发 FIN 报文

### 8. TCP、UDP区别

TCP：面向连接、可靠、传输形式为字节流、慢、所需资源多、应用场景:文件传输、邮件传输、浏览网页等

UDP：无连接、不可靠、传输形式为数据报文段 、快、所需资源少、应用场景：视频、语音、直播等

UDP首部由源端口号、目标端口号、包长、和校验和组成

TCP首部由源端口号、目标端口号、序列号、确认应答号、数据偏移、保留、控制位、窗口大小、校验和、紧急指针、选项、填充组成

### 9. TCP如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层
3. 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段
4. TCP接收端会丢弃重复的数据
5. 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，会提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大⼩的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. 拥塞控制：当网络拥塞时，减少数据的发送
7. ARQ协议： 它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组
8. 超时重传：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

### 10. ARQ协议(自动重传请求)

自动重传请求（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议

- 停止等待ARQ协议

  - 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组
  - 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认
  - 优点：简单
  - 缺点：信道利用率低，等待时间长

- 连续ARQ协议

  连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了

  优点：信道利用率高，容易实现，即使确认丢失，也不必重传

  缺点：不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息

### 11. 滑动窗口和流量控制

TCP利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大⼩，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

### 12. 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注⼊到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收

为了进行拥塞控制，TCP 发送方要维持一个拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大⼩取决于网络的拥塞程度，并且动态变化。发送方让⾃⼰的发送窗口取为拥塞窗口和接收方的接受窗口中较⼩的一个

TCP的拥塞控制采用了四种算法，即慢开始 、 拥塞避免 、快重传和快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生

- 慢开始：cwnd初始值为1，之后每收到一次确认应答，拥塞窗口的值就加1。发送数据包时，将拥塞窗口的大小与接收端主机通知的窗口大小做比较，然后按照它们当中较小的那个值，发送比其还要小的数据量。如果拥塞窗口大小超过慢启动阀值（在超时重发时，设置为当时拥塞窗口的一半），则按比例放大：

  > (1个数据段的字节数 / 拥塞窗口字节) * 1个数据段字节数

- 拥塞避免：拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送方的cwnd加1

- 快重传与快恢复：在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地⼯作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地⼯作

### 13. HTTP协议有什么组成

- 请求报文:
  1. 报文首部
     1. 请求行
     2. 请求首部字段
     3. 通用首部字段
     4. 实体首部字段
     5. 其他
  2. 空行（CR+LF）
  3. 报文主体
- 响应报文:
  1. 报文首部
     1. 状态行
     2. 响应首部字段
     3. 通用首部字段
     4. 实体首部字段
     5. 其他
  2. 空行（CR+LF）
  3. 报文主体

### 14. HTTP状态码

|      | 类别                             | 原因短语                   | 常见的状态码                                                 |
| ---- | -------------------------------- | -------------------------- | ------------------------------------------------------------ |
| 1XX  | Informational（信息状态码）      | 接收的请求正在处理         |                                                              |
| 2XX  | Success（成功状态码）            | 请求正常处理完毕           | 200 OK、204 No Content、206 Partial Content                  |
| 3XX  | Redirection（重定向状态码）      | 需要进行附加操作以完成请求 | 301 Moved Permanently、302 Not Found、303 See Other、304 Not Modified、307 Temporary Redirect |
| 4XX  | Client Error（客户端错误状态码） | 服务器无法处理请求         | 400 Bad Request、401 Unauthorized、403 Forbidden、404 Not Found |
| 5XX  | Server Error（服务器错误状态码） | 服务器处理请求出错         | 500 Internal Server Error、503 Service Unbelievable          |

### 15. HTTP报文的首部

- 通用首部字段

  | 通用首部字段名    | 说明                       |
  | ----------------- | -------------------------- |
  | Cache-Control     | 控制缓存的行为             |
  | Connection        | 逐跳首部、连接的管理       |
  | Date              | 创建报文的日期时间         |
  | Pragma            | 报文指令                   |
  | Trailer           | 报文末端的首部一览         |
  | Transfer-Encoding | 指定报文主体的传输编码方式 |
  | Upgrade           | 升级为其他协议             |
  | Via               | 代理服务器的相关信息       |
  | Warning           | 错误通知                   |

- 请求首部字段

  | 请求首部字段名      | 说明                                          |
  | ------------------- | --------------------------------------------- |
  | Accept              | 用户代理可处理的媒体类型                      |
  | Accept-Charset      | 优先的字符集                                  |
  | Accept-Encoding     | 优先的内容编码                                |
  | Accept-Language     | 优先的语言（自然语言）                        |
  | Authorization       | Web认证信息                                   |
  | Except              | 期待的服务器的特定行为                        |
  | From                | 用户的电子邮箱地址                            |
  | Host                | 请求资源所在服务器                            |
  | If-Match            | 比较实体标记（ETag）                          |
  | If-Modified-Since   | 比较资源的更新时间                            |
  | If-None-Match       | 比较实体标记（与If-Match相反）                |
  | If-Range            | 资源未更新时发送实体Byte的范围请求            |
  | If-Unmodified-Since | 比较资源的更新时间（与If-Modified-Since相反） |
  | Max-Forwards        | 最大传输逐跳数                                |
  | Proxy-Authorization | 代理服务器要求客户端的认证信息                |
  | Range               | 实体的字节范围请求                            |
  | Referer             | 对请求中URI的原始获取方                       |
  | TE                  | 传输编码的优先级                              |
  | User-Agent          | HTTP客户端程序的信息                          |

- 响应首部字段

  | 响应首部字段名     | 说明                         |
  | ------------------ | ---------------------------- |
  | Accept-Ranges      | 是否接受字节范围请求         |
  | Age                | 推算资源创建经过时间         |
  | ETag               | 资源的匹配信息               |
  | Location           | 令客户端重定向至指定URI      |
  | Proxy-Authenticate | 代理服务器对客户端的认证信息 |
  | Retry-After        | 对再次发起请求的时机要求     |
  | Server             | HTTP服务器的安装信息         |
  | Vary               | 代理服务器缓存的管理信息     |
  | WWW-Authenticate   | 服务器对客户端的认证信息     |

- 为Cookie服务的首部字段

  | 首部字段名 | 说明                           | 首部类型     |
  | ---------- | ------------------------------ | ------------ |
  | Set-Cookie | 开始状态管理所使用的Cookie信息 | 响应首部字段 |
  | Cookie     | 服务器接收到的Cookie信息       | 请求首部字段 |

- 其他首部字段

  | 首部字段名       | 说明                                             | 首部类型     |
  | ---------------- | ------------------------------------------------ | ------------ |
  | X-Frame-Options  | 控制网站内容在其他Web网站的Frame标签内的显示问题 | 响应首部字段 |
  | X-XSS-Protection | 针对跨站脚本攻击（XSS）的一种对策                | 响应首部字段 |
  | DNT              | 拒绝个人信息被收集                               | 请求首部字段 |
  | P3P              | 让个人隐私变成一种仅供程序可理解的形式           | 响应首部字段 |


### 16. 在浏览器中输⼊url地址到显示主页的过程

1. 浏览器查找域名的IP地址 DNS解析
2. TCP三次握手进行连接
3. 浏览器向Web服务器发送一个HTTP请求
4. 服务器处理请求，发回一个HTML响应
5. 浏览器开始显示HTML，解析渲染页面
6. 连接结束

### 17. MAC和IP

- 都具有唯一性,但IP具有层次性(IP由网络号和主机号组成,网络号相同,说明它们同处于一个网段.在组织结构,提供商类型和地域分布都比较集中)
- MAC寻址参考地址转发表(记录实际的MAC地址本身),IP寻址参考路由控制表(网络号和子网掩码)
- IP32位，MAC48位
- IP在网络层，MAC在数据链路层
- IP基于地理划分，MAC只和硬件设备有关

### 18. HTTP使用的认证方式

- BASIC认证（基本认证）
- DIGEST认证（摘要认证）
- SSL客户端认证
- FormBase认证（基于表单认证）

### 19. HTTP的缺点

- 通信使用明文,内容可能被窃听
- 不验证通信方的身份,因此有可能遭遇伪装
- 无法证明报文的完整性,所以有可能已遭篡改

### 20. HTTP 和 HTTPS 的区别

- HTTP默认端口是80，HTTPS默认端口是443
- HTTPS = HTTP + 加密 + 认证 + 完整性保护
- HTTPS 协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用
- 安全性和资源消耗：HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上。HTTPS加密过程：使用非对称加密方式安全地交换在稍后的对称加密中要使用的密钥，确保交换的密钥是安全的前提下（就是去认证），使用对称密钥加密方式进行通信。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。
  - 安全性：HTTPS > HTTP
  - 资源消耗：HTTPS > HTTP
  - 数据传输：HTTP：明文，HTTPS：密文
  - HTTPS传输内容加密使用对称加密算法，对此加密的密钥使用非对称加密


### 21. 对称加密和非对称加密

- 对称（共享）加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等。缺点是密钥的管理与分配，换句话说，如何把密钥发送到需要解密你的消息的人的手里是一个问题
- 非对称（公开）加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等

### 22. 数字证书认证机构的业务流程

1. 服务器把自己的公开密钥登录至数字证书认证机构
2. 数字证书认证机构用自己的私有密钥向服务器的公开密码部署数字签名并颁发公钥证书
3. 客户端拿到服务器的公钥证书后，使用数字证书认证机构的公开密钥，向数字证书认证机构验证公钥证书上的数字签名，以确认服务器的公开密钥的真实性
4. 使用服务器的公开密钥对报文加密后发送
5. 服务器用私有密钥对报文解密

### 23. HTTPS通信步骤

1. 客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件(CipherSuite)列表(所使用的加密算法及密钥长度等)
2. 服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的
3. 之后服务器发送Certificate报文。报文中包含公开密钥证书
4. 最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束
5. SSL第一次握手结束之后，客户端以Client Key Exchange报文作为回应。报文中包含通信加密中使用的一种被称为Pre-master secret的随机密码串。该报文已用步骤3中的公开密钥进行加密。
6. 接着客户端继续发送Change Cipher Spec报文。该报文会提示服务器，在此报文之后的通信会采用Pre-master secret密钥加密
7. 客户端发送Finished报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准
8. 服务器同样发送Change Cipher Spec报文
9. 服务器同样发送Finished报文
10. 服务器和客户端的Finished报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求
11. 应用层协议通信，即发送HTTP响应
12. 最后由客户端断开连接。断开连接时，发送close_notify报文。
13. 之后再发送TCP FIN报文来关闭与TCP的通信

在以上流程中，应用层发送数据时会附加一种叫做MAC(Message Authentication Code)的报文摘要。MAC能够查知报文是否遭到篡改，从而保护报文的完整性。

### 24. get和post区别

- get把请求的数据放在url上，即HTTP协议头上。post把数据放在HTTP的包体内（requrest body）
- GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据)。POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
- GET在浏览器回退时是无害的，POST会再次提交请求
- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制
- GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息

### 25. cookie和session的区别

- 存在的位置：cookie 存在于客户端，临时文件夹中； session存在于服务器的内存中，一个session域对象为一个用户浏览器服务
- 安全性：cookie是以明文的方式存放在客户端的，安全性低，可以通过一个加密算法进行加密后存放； session存放于服务器的内存中，所以安全性好
- 网络传输量：cookie会传递消息给服务器；session本身存放于服务器，不会有传送流量
- 生命周期(以20分钟为例)：cookie的生命周期是累计的，从创建时，就开始计时，20分钟后，cookie生命周期结束；session的生命周期是间隔的，从创建时，开始计时如在20分钟，没有访问session，那么session生命周期被销毁。但是，如果在20分钟内（如在第19分钟时）访问过session，那么，将重新计算session的生命周期。关机会造成session生命周期的结束，但是对cookie没有影响
- 访问范围：cookie为多个用户浏览器共享； session为一个用户浏览器独享

### 26. Session、Cookie在登录操作中的应用

1. 客户端把用户ID和密码等登录信息放入报文的实体部分，通常是以POST方法把请求发送给服务器。而这时，会使用HTTPS通信来进行HTML表单画面的显示和用户输入数据的发送
2. 服务器会发放用以识别用户的Session ID。通过验证从客户端发送过来的登录信息进行身份认证，然后把用户的认证状态与SessionID绑定后记录在服务器端。向客户端返回响应时，会在首部字段Set-Cookie内写入Session ID。必须防止Session ID被盗，或被猜出。为了做到这点，Session ID应使用难以推测的字符串，且服务器端也需要进行有效期的管理，保证其安全性。另外，为减轻跨站脚本攻击(XSS)造成的损失，建议事先在Cookie内加上httponly属性
3. 客户端接收到从服务器端发来的Session ID后，会将其作为Cookie保存在本地。下次向服务器发送请求时，浏览器会自动发送Cookie,所以Session ID也随之发送到服务器。服务器端可通过验证接收到的Session ID识别用户和其认证状态

### 27. WebSocket协议

WebSocket 是一种基于 TCP 的全双工通信协议，允许客户端和服务器之间进行实时、低延迟的双向通信。它通过 HTTP 协议完成握手后，升级为 WebSocket 协议，从而建立持久连接。

通信流程：

1. **握手阶段**：
   - 客户端通过 HTTP 请求向服务器发起 WebSocket 握手请求。
   - 请求头中包含 `Upgrade: websocket` 和 `Connection: Upgrade`，表明希望将连接升级为 WebSocket 协议。
   - 服务器验证请求后，返回响应头 `101 Switching Protocols`，表示握手成功。
2. **数据传输阶段**：
   - 握手完成后，HTTP 连接升级为 WebSocket 协议。
   - 客户端和服务器可以通过该连接自由地发送和接收数据。
3. **关闭连接**：
   - 任一方可以主动发送关闭帧（Close Frame）来终止连接。

### 28. SSE协议

SSE（Server-Sent Events） 是一种基于 HTTP 协议的服务器推送技术。它允许服务器通过单一的 HTTP 长连接，持续向客户端发送事件流（Event Stream）。客户端（通常是浏览器）通过监听这些事件流，可以实时更新页面内容。

通信流程：

1. **客户端发起请求**：
   - 客户端通过普通的 HTTP GET 请求访问服务器端的 SSE 接口。
   - 在请求头中指定 `Accept: text/event-stream`，表明希望接收事件流。
2. **服务器保持长连接**：
   - 服务器接收到请求后，不会立即关闭连接，而是保持长连接，并通过该连接持续向客户端推送数据。
3. **客户端处理事件**：
   - 客户端通过 JavaScript 的 `EventSource` API 监听事件流，并对每条消息进行处理。

## 操作系统

### 1. 进程和线程的区别

- 进程是CPU资源分配的最小单位，线程是CPU调度的最小单位
- 线程可以和属于同一个进程的其他线程共享这个进程的全部资源
- 一个进程包含多个线程，一个线程只能在一个进程之中。每一个进程最少包含一个线程
- 进程之间的切换开销比较大，但是线程之间的切换开销比较小
- 因为线程之间是共享同一个进程的，所以线程之间的通信几乎不需要系统的干扰

### 2. 进程间通信方式

1. 管道
2. 命名管道
3. 消息队列
4. 共享内存
5. 信号量
6. 套接字Socket
7. 信号

### 3. 线程通信方式

1. 锁机制：包括互斥锁、条件变量、读写锁。互斥锁提供了以排他方式防止数据结构被并发修改的方法。读写锁允许多个线程同时读共享数据，而对写操作是互斥的。条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
2. 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
3. 信号机制(Signal)：类似进程间的信号处理。线程间的通信目的主要是用于线程同步，所以线程没有像进程
   通信中的用于数据交换的通信机制。

### 3. 线程有哪几种状态

- 创建状态(new) ：进程正在被创建，尚未到就绪状态。
- 就绪状态(ready) ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- 运行状态(running) ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- 阻塞状态(waiting) ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- 结束状态(terminated)：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

### 4. 线程间的同步方式

1. 互斥量（Mutex）：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的synchronized 关键词和各种 Lock 都是这种机制。
2. 信号量（Semphares）：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. 事件（Event）：Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较

### 5. 进程的调度算法

1. 先到先服务(FCFS)调度算法 : 从就绪队列中选择一个最先进⼊该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
2. 短作业优先(SJF)的调度算法 : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度
3. 时间片轮转调度算法 : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间
4. 优先级调度 ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级
5. 多级反馈队列调度算法：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法

### 6. 什么是虚拟内存

- 虚拟内存使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如 RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等


### 7. 内存管理机制

- 块式管理：将内存分为几个固定大⼩的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很⼩的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片
- 页式管理：把主存分为大⼩相等且固定的一页一页的形式，页较⼩，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址
- 段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间⼩很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、⼦程序段X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址
- 段页式管理：结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页

### 8. 什么是死锁

指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进

### 9. 产生死锁的原因

1. 竞争资源
   1.  竞争不可剥夺资源
   2.  竞争临时资源
2. 进程间推进顺序非法

### 10. 死锁产生的必要条件

1. 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用
2. 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放
3. 不可剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放
4. 环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链

### 11. 死锁预防

1. 资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）
2. 只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏请求保持条件）
3. 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
4. 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

### 12. 避免死锁

- 银行家算法：在分配资源之前先看清楚，资源分配后是否会导致系统死锁

### 13. 死锁的解除

- 抢占资源。从一个或多个进程中抢占足够数量的资源，分配给死锁进程，以解除死锁状态
- 终止或者撤销进程。终止或者撤销系统中的一个或多个死锁进程，直到打破循环环路，使系统从死锁状态解脱出来