# 项目

## 在线客服

### 1. 为什么离职？

我之前在公司主要负责客服系统的开发和维护，现在大模型比较火，我注意到很多客服系统都逐步引入了智能客服功能。我个人对这些新技术比较感兴趣，就去自学了spring ai框架，并且在小组内做了分享，但是近期领导好像并没有引入新技术的打算。并且日常接到的需求也逐渐没有挑战了，就是普通的增删改查，没有太多成长性了，就想着出来再看看机会。

### 2. 项目背景及需求分析

公司目前已经电话客服，在线客服还是使用第三方公司的服务，无法满足一些定制化需求，公司决定自研。

需求如下：

- 用户群体分为两类：客服人员和用户，用户又来自于不同的渠道，包括web端、app端、微信h5等
- 聊天由用户主动发起，分配客服人员后便可进行聊天
- 客服可查询用户的所有聊天记录
- 不需要语音和视频聊天

### 3. 网络模式选型

- client-server：客户端之间的通讯依赖服务端的转发。服务端持有所有客户端的信息，方便监控，但是服务器的最大连接数是瓶颈
- peer2peer：去中心化网络，客户端之间可两两建立连接。可保证客户端通讯的私密性，并且规模可以无限扩大，无需转发对于语音视频也有优势，但是应用时常需要解决网络穿透问题。

对于客服系统而言，连接数取决于客服人员的处理能力，且需要保存聊天记录，监控各种状态，所以采用client-server模式。

### 4. 应用层协议的选项

- HTTP轮询：客户端通过HTTP请求轮询服务端有没有新消息。如果没有新消息则马上返回，存在大量无用请求
- HTTP长轮询：有新消息才返回，否则超时等待，这样可以减少请求，但是每次请求都建立了连接，增加了服务端的网络I/O开销，对性能不友好
- WebSocket：全双工通信协议。在WebSocket API中，浏览器和服务器只需要完成一次握手，就可以创建持久性的可双向数据传输的连接。

WebSocket协议建立长连接和全双工通信的特点更适合客服系统

### 5. 在分布式架构下，用户和客服分别连接了不同的服务器，怎么收发消息？

问题描述：用户 A 连接到 Server 1。客服 B 连接到 Server 2。

现状：使用redis共享内存

最初系统采用redis作为全局路由表存储，主要存的是clientID -> serverID。每次客户端连接或断开时，都会更新这个路由表。消息发送时，通过查询Redis找到对应的目标服务器。

缺点：如果网络不稳定，客户端频繁建立、断开连接，可能出现：建立了连接1，断开了，此时由于网络问题还未删除全局路由表对应的数据，新连接建立了，然后删除请求又好了，redis根据key删除了连接。导致消息发送失败。

改进方案：使用广播策略

核心思想：

- 使用消息队列实现广播
- 每台服务器只保存自己连接的客户端信息，自己能处理就处理，不能就广播出去

优点：

不再依赖全局路由表，避免了网络抖动造成的问题。本地存储使用 Map<WsClientType, ConcurrentHashMap<String,Channel>>（消息类型（seat/web/app/wechat/en_wechat）：用户id或坐席id：channel）。在删除的时候使用boolean remove(Object key, Object value)方法。

即使某台服务器宕机，其他服务器也能正常处理自己的连接，不会导致全局不可用，整体可用性提升

除此之外，我还将广播的各种方法抽象成接口，给了两套实现，一套kafka，一套redis。通过配置来判断走kafka还是redis。如果kafka或者redis某一个突然不可用，可迅速切换到另一个实现。

### 6. 如果机器多了，广播消息会增长特别快，你怎么优化？

一致性哈希算法。

**基本原理**：一致性哈希的核心思想是将所有的节点（服务器）和数据映射到一个虚拟的环形空间（称为一致性哈希环），并通过哈希值计算它们的位置。数据顺时针找到的第一个节点就是其所在的服务器。

**相较于传统哈希算法（取模哈希hash(key) % N）的优势**：传统哈希扩容缩容时，所有数据都需要重新计算哈希，导致数据大量迁移。而哈希环上节点的增减只会迁移少部分数据

**虚拟节点**：优化手段，用于解决数据分布不均的问题。每个物理节点会被映射到多个虚拟节点。这些虚拟节点均匀分布在一致性哈希环上。数据项通过哈希计算后，会找到最近的虚拟节点，再通过虚拟节点找到对应的物理节点。

结合到客服系统

1. 构建一致性哈希环：
   - 将每台服务器映射到一致性哈希环上。
   - 用户和客服也通过哈希函数计算出哈希值，并映射到环上。
2. 消息路由：
   - 当用户 A 发送消息给客服 B 时，首先计算用户 A 和客服 B 的哈希值。
   - 根据一致性哈希规则找到对应的服务器：
     - 如果用户 A 和客服 B 在同一台服务器上，则直接处理。
     - 如果不在同一台服务器上，则将消息发送到客服 B 所在的目标服务器。
3. 动态扩容：
   - 当新增一台服务器时，只需将其映射到环上，并迁移少量受影响的数据。
   - 不会影响其他服务器的工作。

### 7. 坐席侧特殊处理

存在的问题：

- 消息处理存在阻塞操作，例如写入数据库，rpc调用机器人服务
- netty中channel的handler处理是由分配好的线程处理，而不是处理时再去现分配。一个线程可处理多个channel
- 坐席数量少但是重要，一个坐席可能同时服务多个用户，如果其handler和用户的handler由同一个线程处理，用户rpc调用阻塞了，会导致该坐席服务的所有用户都无法及时响应

解决办法：

- 区别对待用户端和坐席端
  - 用户端：继续使用Netty的默认线程模型
  - 坐席端：引入自定义线程池，调用方法ctx.channel().pipeline().addLast()时，区分坐席和用户，如果是坐席就多传一个参数，自定义的线程池传进去
- 该方法的可行性：netty中pipeline的handler是串行执行的，保证这个业务handler是最后一个handler，才可以异步执行

效果：这样改进后，坐席侧的延迟降低了，不会出现卡住的情况。

### 8. 整个平台的架构是怎样的

- flyway：数据库脚本管理工具，新建表、修改字段、添加索引等sql
- Scheduler：定时任务调度工具
- 配置中心Spring Cloud Config： 基于 Git 或文件系统的配置中心
  - **动态更新：** 支持运行时动态刷新配置，无需重启服务。
  - **环境隔离：** 不同环境（开发、测试、生产）可以使用不同的配置。
  - **安全性：** 敏感信息（如数据库密码）可以加密存储。
- 服务注册与发现Kubernetes
  - 服务注册：
    - Kubernetes 自动为每个 Pod 分配 IP 地址，并通过 Service 对象暴露访问入口。
  - 服务发现：
    - Kubernetes 内置了 DNS 服务（如 CoreDNS），客户端可以通过 DNS 名称访问目标服务。
- 熔断限流Istio
  - 熔断：当某个服务实例连续失败达到一定阈值时，Istio 会将其标记为不可用，并停止向其转发流量。
  - 限流：Istio 支持基于请求速率或并发数的限流策略，防止后端服务被压垮。
- 网关服务Istio
  - 流量管理：
    - 支持基于路径、Header 的路由规则。
    - 提供金丝雀发布、蓝绿部署等功能。
  - 安全通信：
    - 支持 mTLS（双向 TLS），确保服务间通信的安全性。
- springboot
- 监控平台
  - 调用链监控
  - JVM监控
  - 慢查询监控

### 9. 整个系统的架构是怎样的

业务架构：

- 帮助中心：用户进入客服系统后，根据不同渠道展示不同的提前配置的问题、欢迎语
- 机器人问答和知识库：在知识库提前配置好问题和答案，用户在输入框如果能模糊匹配问题，则直接返回答案
- 坐席调度：均衡分配、排队队列、自动进线、会话邀请
- IM：基础会话
- 工单系统：工单创建，状态流转，可配置表单
- 其他：质检系统、电话系统等由别的团队负责

技术架构：

- flyway：数据库脚本
- springboot
- mybatis
- kafka
- feign
- mysql
- redis
- mongodb

### 10. 用户进线的流程

帮助中心 -> 机器人对话 -> 转人工 -> 排队 -> 人工对话 -> 坐席侧填写服务单、工单 -> 用户侧满意度反馈

### 11. 坐席分配规则

每个坐席都有最大接待上限

优先分配用户上一次会话分配的坐席。

每个坐席都有一个或多个技能组，会先根据用户的技能组查询坐席，分配原则就是在不超过最大接待上限的情况下分配给最闲的坐席，如果最闲的坐席有多个就随机分配

### 12. 为什么选择用redis的zset作为排队队列

- **ZADD：**用于添加元素
  - score的计算：
    - 非VIP：优先级（1-100）拼接时间戳
    - VIP：VIP等级 拼接 100减优先级 拼接 用10的13次方减去时间戳，最后再乘以-1
- **ZRANK：**返回有序集中成员的排名，可用于展示当前排名
- **ZREM：**移除有序集中的一个或多个成员，可用于退出排队
- **ZRANGE：**返回有序集中指定区间内的成员，可用于客服工作台会话邀请场景
- **ZPOPMIN：**返回最低得分的成员，也就是最早排队的成员，可以用于自动进线场景
- **ZCOUNT：**返回计算有序集合中指定分数区间的成员数量，可用于计算排队长度
- **ZSCORE：**返回有序集中，成员的分数值，可用于查看用户排队时间

### 13. zset的底层实现

Redis 的 ZSet 是一种有序集合数据结构，它的底层实现是基于两种核心数据结构的组合：

- **哈希表（Hash Table）**：用于存储成员与分数的映射关系。
- **跳跃表（Skip List）**：用于维护成员的排序顺序。
  - 跳跃表是一种多层链表结构，每一层都包含部分节点，高层节点之间的跨度更大，底层节点则包含所有元素。
  - 复杂度O(logN)

ZSet 的设计目标是支持高效的操作，包括插入、删除、按分数范围查询等。

Redis 在某些情况下会对 ZSet 的底层实现进行优化：

- **小规模数据**：当 ZSet 中的元素数量较少时，Redis 会使用压缩列表（ziplist）来节省内存。
- **大规模数据**：当元素数量超过一定阈值（默认 128 个）时，Redis 切换为哈希表 + 跳跃表的实现。

### 14. 怎么解决网络的不确定性

- **建立心跳机制**：客户端连续几次心跳未响应的话就会执行断线重连，服务端如果持续一段时间空闲状态则断开连接清理资源。
  - tcp keepalive：内置于 TCP 协议中的机制，用于检测连接是否仍然有效。但是Keepalive 的探测包是底层协议的行为，无法携带业务数据，无法满足某些应用层的需求（如用户状态更新、消息确认等）
- **消息可靠性**：使用消息队列kafka和持久化存储redis来保证消息不丢失，kafka可实现可靠传递
- **幂等性设计**：每条消息生成全局唯一UUID，接收方根据ID去重
- **监控与报警**：实时监测网络延迟和丢包率，出现不稳定状况时及时通知
- **用户体验优化**：若长期不可用，客户端进入离线模式，消息缓存到本地。或者暂时关闭非核心业务，优化保证核心业务

### 15. 你们netty里使用的handler有哪些？

- http协议相关的
  - HttpServerCodec：HTTP编解码工具
  - ChunkedWriteHandler：大数据流的支持
  - HttpObjectAggregator：对于http的消息进行聚合,聚合成FullHttpRequest或者FullHttpResponse
- 心跳相关的：
  - IdleStateHandler：如果几分钟之内没有向服务器发送心跳，则自动断开
  - HeartBeatHandler：自定义空闲状态检测,自定义心跳处理 todo
  - customerRefreshHandler：刷新操作 todo
- webSocket相关的：
  - CustomWebSocketServerProtocolHandler：该handler添加成功后会继续增加handler
    - securityHandshake：获取客户端类型，根据类型获取对应的安全验证checker，验证失败则发送401并断开连接，验证通过就在channel中保存身份信息，并在响应头加上cookie，发送握手成功响应，发送握手成功事件，删除握手处理器，响应403forbidden
    - Utf8FrameValidator：负责utf-8编码
- 业务相关的
  - exceptionAndEventHandler：处理握手成功事件
  - 根据不同的客户端添加不同的业务处理器，注意这里使用了自定义线程池，拿AppServerHandler举例，做了什么处理
    - 添加Handler：userListener，作用是通过检测连接读空闲来触发用户超时未回复事件，通过检测连接写空闲来除法坐席超时未回复事件
    - 添加Handler：textFrameOutBundHandler，作用是向客户端写消息的时候，将消息封装为netty定义的符合websocket协议的对象
    - 添加Handler：msgMemoryMonitor，作用是进行消息占用内存的记录
    - 添加Handler：refrshTokenHandler，作用是刷新客户端http请求时使用的token
    - 向客户端发送一条包含用户id的消息
    - 发布spring事件ChannelActiveEvent，事件会触发修改用户状态、发送历史消息、如果不存在会话则创建机器人会话或发送欢迎语等操作

### 16. 项目中有用过切面编程AOP吗（分布式锁）

在我参与的项目中，确实有用到 AOP 来实现分布式锁的功能。我们通过 AOP 的方式，在方法执行前后动态地加入分布式锁逻辑，从而避免了在业务代码中显式地调用加锁和解锁操作，提高了代码的可维护性和复用性。

为了实现这一点，我们定义了一个自定义注解 `@CommonLock`，开发者可以在需要加锁的方法上标注这个注解，并指定一些参数，比如锁的前缀、等待时间、锁的持有时间等。然后，我们通过 AOP 的切面拦截这些方法，在方法执行前尝试获取锁，执行后再自动释放锁。

在切面类 `CommonLockAspect` 中，我们通过 `@Around` 注解实现了对目标方法的拦截。在拦截逻辑中，我们会根据注解的配置动态生成锁的名称，这个锁名可以包含方法参数中的特定字段值，以确保锁的粒度足够细。接着，我们调用 `DistributedRedisLock` 类提供的 `executeWithLock` 方法，将目标方法的执行包裹在加锁和解锁的操作中。

`DistributedRedisLock` 是基于 Redisson 实现的一个工具类，它利用 Redisson 提供的分布式锁功能，确保了锁的安全性和可靠性。在加锁时，我们支持设置等待时间和锁的持有时间，避免死锁的发生；在解锁时，只有当前线程持有的锁才会被释放，保证了线程安全。

通过这种方式，我们不仅实现了分布式锁的功能，还很好地分离了业务逻辑和并发控制逻辑，达到了代码简洁、职责单一的目标。同时，AOP 的使用也大大降低了开发者的使用成本，只需简单地添加注解即可完成分布式锁的集成。

### 17. 分布式锁为什么适合用来做切面呢

1. 代码解耦：避免业务逻辑和锁逻辑的耦合
2. 复用性强：一处定义，多处使用
3. 降低开发成本：减少人为错误
4. 统一管理：方便扩展和优化
5. 提升可读性

### 18. 你们的分布式锁是用什么实现的

在我们的项目中，分布式锁是基于 Redisson 框架实现的。，因为它不仅提供了开箱即用的分布式锁功能，还支持自动续期、可重入锁等高级特性。通过切面编程，我们将分布式锁的逻辑封装成一个透明的模块，极大地提升了代码的简洁性、复用性和可维护性。我们通过 Redisson 的 `RLock` 接口来实现分布式锁。

key就是前缀拼接动态参数。在要加锁的方法上直接打上注解即可，方法参数上可打注解@LockField，表示key的拼接。

其他实现对比：

- 原生 Redis 实现（SETNX + EXPIRE）：优点是简单直接，缺点是需要手动管理锁的续期和释放，容易出错。
- Zookeeper 实现：Zookeeper 通过临时节点实现分布式锁，可靠性高，但性能不如 Redis。

### 19. 用redis实现一个分布式锁

核心思想：使用lua脚本将setnx和expire两个命令合并为一个原子操作

加锁代码如下：

```lua
-- Lua 脚本（原子执行）
local result = redis.call('SET', KEYS[1], ARGV[1], 'NX', 'EX', tonumber(ARGV[2]))
return result
```

```java
redis.eval(luaScript, Collections.singletonList(lockKey), identifier, "30");
```

释放锁代码如下：

```java
// 使用 Lua 脚本实现 CAS（Compare And Swap）
String script = "if redis.call('GET', KEYS[1]) == ARGV[1] then return redis.call('DEL', KEYS[1]) else return 0 end";
Long result = (Long) redis.eval(script, 
    Collections.singletonList(lockKey), 
    identifier);
if (result == 1) {
    System.out.println("锁释放成功");
}
```

可重入锁：将锁的值设计为 `客户端唯一标识符:持有次数` 的格式，例如 `client_123:3` 表示客户端 `client_123` 已持有锁 3 次。

### 20. Jedis和Redisson的客户端的区别

**Jedis**

- **定位**：
   Jedis 是一个轻量级的 Redis 客户端，主要提供对 Redis 命令的直接封装。它更接近 Redis 的原生命令操作。
- **特点**：
  - 提供了 Redis 所有命令的 Java 接口（如 `SET`、`GET`、`HSET` 等）。
  - 使用简单，适合需要直接操作 Redis 的场景。
  - 不提供高级功能（如分布式锁、分布式集合等），开发者需要自己实现这些逻辑。
- **连接管理**：
   Jedis 默认是单线程的，每个线程需要独立创建连接。如果并发量较高，建议使用连接池（`JedisPool`）来管理连接。
- **性能**：
   Jedis 的性能较高，但需要开发者自行优化连接池配置和管理。
- **分布式锁**：
   Jedis 不直接提供分布式锁功能，需要开发者手动实现。例如，使用 `SETNX` 和 `EXPIRE` 命令组合实现简单的分布式锁。
- **其他工具**：
   Jedis 不提供分布式集合、信号量、计数器等高级工具，开发者需要自行实现。

**Redisson**

- **定位**：
   Redisson 是一个功能强大的 Redis 客户端，专注于提供分布式场景下的解决方案。
- **特点**：
  - 在 Redis 的基础上封装了丰富的分布式工具，例如分布式锁、分布式集合、信号量、计数器、队列等。
  - 提供了开箱即用的高级功能，开发者无需手动实现复杂的逻辑。
  - 更适合需要分布式协调的场景。
- **连接管理**：
   Redisson 内部实现了基于 Netty 的异步非阻塞通信，默认支持多线程共享连接，无需额外配置连接池。
- **性能**：
   Redisson 的性能略低于 Jedis，但差距不大。由于其提供了更多的功能（如自动续期、分布式锁等），在分布式场景下更具优势。
- **分布式锁**：
   Redisson 提供了多种分布式锁实现，包括可重入锁（Reentrant Lock）、公平锁（Fair Lock）、联锁（MultiLock）和红锁（RedLock）。
- **其他工具**：
   Redisson 提供了丰富的分布式工具，例如：
  - 分布式集合（Set、Map、List）。
  - 分布式信号量（Semaphore）。
  - 分布式计数器（AtomicLong）。
  - 分布式队列（Queue、BlockingQueue）。

### 21. redisson的几种锁

| 锁类型       | 特点                                                         | 使用场景                                                 | 示例代码                                                     |
| ------------ | ------------------------------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------------ |
| **可重入锁** | 支持同一线程多次获取                                         | 递归调用、嵌套调用                                       | RLock lock = redissonClient.getLock("lockKey");              |
| **公平锁**   | 按请求顺序分配锁，避免饥饿问题                               | 需要公平性的场景，需要严格按照请求顺利处理任务           | RLock fairLock = redissonClient.getFairLock("fairLockKey");  |
| **联锁**     | 同时对多个资源加锁。联锁的获取是原子性的，避免了死锁问题。   | 需要同时操作多个资源的场景，例如跨服务调用或分布式事务。 | RLock lock1 = redissonClient.getLock("lock1");<br />RLock lock2 = redissonClient.getLock("lock2");<br />RLock multiLock = redissonClient.getMultiLock(lock1, lock2); |
| **红锁**     | 基于多个 Redis 实例实现高可用锁                              | Redis 单点部署存在风险，需要更高的容错能力。             | Config config1 = new Config();<br/>config1.useSingleServer().setAddress("redis://127.0.0.1:6379");<br/>RedissonClient redisson1 = Redisson.create(config1);<br/>Config config2 = new Config();<br/>config2.useSingleServer().setAddress("redis://127.0.0.1:6380");<br/>RedissonClient redisson2 = Redisson.create(config2);<br/>RLock lock1 = redisson1.getLock("lock1");<br/>RLock lock2 = redisson2.getLock("lock2");<br/>RLock redLock = redissonClient.getRedLock(lock1, lock2); |
| **读写锁**   | 支持读写分离，允许多个线程同时获取读锁，但只允许一个线程获取写锁。 | 读多写少的场景，例如缓存系统、配置中心等                 | RReadWriteLock rwLock = redissonClient.getReadWriteLock("rwLockKey");<br />rwLock.readLock().lock();<br />rwLock.writeLock().lock(); |
| **信号量**   | 控制同时访问某个资源的线程数量。支持分布式环境下的限流和资源分配。 | 限制并发线程数的场景，例如限流、连接池管理等。           | RSemaphore semaphore = redissonClient.getSemaphore("semaphoreKey");<br/>semaphore.trySetPermits(10); // 设置初始许可数量<br/><br/>if (semaphore.tryAcquire()) {<br/>    try {<br/>        // 核心业务逻辑<br/>    } finally {<br/>        semaphore.release();<br/>    }<br/>} |
| **计数锁**   | 允许一个或多个线程等待，直到其他线程完成某些操作后触发。     | 多线程协作的场景，例如等待多个任务完成后继续执行。       | RCountDownLatch latch = redissonClient.getCountDownLatch("latchKey");<br/>latch.trySetCount(5); // 设置初始计数值<br/><br/>new Thread(() -> {<br/>    try {<br/>        latch.await(); // 等待计数变为 0<br/>    } catch (InterruptedException e) {<br/>        e.printStackTrace();<br/>    }<br/>}).start();<br/><br/>for (int i = 0; i < 5; i++) {<br/>    new Thread(() -> {<br/>        // 执行任务<br/>        latch.countDown(); // 减少计数<br/>    }).start();<br/>} |
| **局部锁**   | 本地缓存锁状态，减少 Redis 访问                              | 高频加锁操作、读多写少的场景。最终一致性                 | // 创建一个本地缓存的 Map<br/>RMap<String, String> map = redissonClient.getMap("myMap", LocalCachedMapOptions.defaults());<br/>// 获取局部锁<br/>RLock lock = map.getLock("key");<br/>lock.lock(); |

### 22. 锁一般会设置超时时间，为什么？超时时间一般设置多大？

设置超时时间的原因：

- 防止死锁
- 避免长时间占用资源
- 容错机制：分布式系统中可能存在网络延迟、节点故障等问题。超时时间提供了一种容错机制，确保即使某些异常情况发生，系统仍然能够正常运行。

超时时间一般设置多大：

- 业务处理时间：超时时间应该大于业务逻辑的最大执行时间。
- 系统性能：超时时间过长会导致锁资源被长时间占用，降低系统的并发能力。超时时间过短可能导致锁在业务处理完成前就过期，引发数据一致性问题。
- 经验值：简单操作：3~5 秒。复杂操作：10~30 秒。特殊场景：根据具体需求调整。
- 自动续期：可以使用 Redisson 提供的 看门狗（Watchdog）机制，自动延长锁的有效时间

总结：锁的超时时间是为了防止死锁和资源长时间占用，通常设置为业务逻辑最大执行时间的 2~3 倍，实际值需要根据具体场景灵活调整。

### 23. 分布式锁什么情况下会发生死锁

- 没有正确释放锁，finally里面没有正确释放
- 锁的超时时间不足，线程A拿到锁因超时自动释放，此时线程B拿到锁，线程 A 完成业务逻辑后尝试释放锁，但此时锁已经被线程 B 持有，可能导致数据不一致或死锁。
  - 解决方案：释放锁时提前判断拿到该锁的是不是当前线程
- 多个锁交叉持有。线程 A 先获取锁 X，再尝试获取锁 Y。线程 B 先获取锁 Y，再尝试获取锁 X。两个线程互相等待对方释放锁，导致死锁。
  - 解决方案：
    - 使用全局统一的加锁顺序。例如，总是先获取锁 X，再获取锁 Y。
    - 使用 Redisson 提供的 联锁（MultiLock） 功能，确保多个锁的获取是原子性的。
- 锁的粒度过大
  - 解决方案：尽量使用细粒度的锁，例如按用户ID、订单ID等维度划分锁key

### 24. 你们项目里有用到分布式事务吗？

在我们的客服系统中，存在一些需要跨服务调用的业务场景。例如，当工单处理完成后，根据工单类型触发不同的操作。以停催类工单为例，工单完成后需要调用催收团队提供的 RPC 接口通知停止催收。由于这些业务场景对实时一致性要求不高，但必须保证最终一致性，因此我们采用了基于**本地消息表**的解决方案。

具体实现如下：

1. 本地事务保障可靠性：
   - 在工单处理完成时，开启本地事务，将业务数据（如工单状态）与一条消息记录同时写入数据库。消息记录包含以下字段：
     - `business_id`：业务数据的唯一标识。
     - `business_snapshot`：业务数据快照（用于后续补偿）。
     - `message_type`：消息类型（如停催通知）。
     - `status`：消息状态（初始为“未发送”）。
     - `retry`：重试次数
   - 由于业务数据和消息记录在同一个事务中提交，可以确保两者的一致性。
2. 异步消息投递：
   - 编写一个定时任务（Job），每隔一段时间扫描本地消息表，筛选出状态为“未发送”的消息。
   - 对于每条消息，调用下游服务的 RPC 接口（如停催接口），并将调用结果更新到消息表中：
     - 如果调用成功，将状态更新为“已发送”。
     - 如果调用失败，记录失败原因，并设置重试次数限制。
3. 幂等性设计：
   - 下游服务的接口必须支持幂等性，避免重复调用导致数据不一致。例如，可以通过在下游服务中维护一个唯一键（如 `business_id`）来防止重复处理。
4. 补偿机制：
   - 如果多次重试后仍然失败，会触发人工介入或自动回滚机制。例如，将工单状态标记为“异常”，并通过告警系统通知运维人员。

这种方案的优点是简单易实现，且能够保证最终一致性。虽然性能可能略低于其他方案（如 TCC 或 Saga），但在我们的业务场景中足够满足需求。
 此外，我们还评估过其他方案，例如：

- **TCC（Try-Confirm-Cancel）**：适用于对性能要求较高的场景，但实现复杂度较高。
- **Saga 模式**：适合长时间运行的业务流程，但需要额外的状态机管理。 最终选择了本地消息表，因为它实现成本低且易于维护。
- **kafka**：本地消息表成本更低、实时性要求不高。需要额外保障消息发送与事务的一致性（如使用 Kafka 事务），增加了实现难度。

### 25. 线上接口突然很慢怎么办？

- 定位问题：采用APM工具快速定位，常见的工具：skywalking、pinpoint、cat、zipkin。假如没有接入APM，可以用Arthas的trace命令分析具体哪个方法慢
- 解决：
  - 数据库慢sql：
    - 先通过explain分析，走没走索引
    - 小表驱动大表
    - 内存中执行join组装数据，可以使用completableFuture并行查再组装
    - select *别用，按需返回字段
    - 单表太大，考虑分片库或分表、es存储等
  - 调第三方接口慢：
    - 熔断限流
    - 事务型操作根据实际的情况酌情决定是否重试补偿(本地消息表+job重试)
    - 循环查单个改为批量查
    - 能缓存的就缓存
  - 中间件慢：
    - redis慢：热key上本地缓存。大key：拆分大key
    - kafka慢：生产者批量丢消息。扩分区，增加消费节点
  - 程序逻辑慢：
    - 校验逻辑前置
    - 循环改批量
    - 同步改异步
    - 线程池合理设置
    - 锁合理设置
    - 优化gc参数（考虑young gc、full gc是否太频繁、调整gc算法、新生代老年代比例）
    - 只打印必要日志(warn或error级别)
  - 结构优化：

## 异步导出工具

### 1. 你的异步导出工具具体做了什么事？

我们之前的客服系统中，涉及到大量的数据导出功能，比如通话记录、聊天记录、工单等。由于这些导出操作会涉及大量数据查询和文件生成，原有的同步导出方式会导致接口响应时间过长，甚至可能阻塞系统，影响用户体验。

为了解决这个问题，我主导了一个重构项目，目标是将所有的导出接口统一接入一个异步导出工具。具体来说，我做了以下几个关键点：

1. **设计思路**：
   - 我采用了生产者-消费者模型，用户点击“导出”按钮时，系统会生成一个导出任务，并将其发送到 Kafka 消息队列中。
   - 后端有一个专门的消费者服务负责监听消息队列，接收任务并执行具体的导出逻辑。
2. **技术实现**：
   - 在项目启动时，我通过 Spring 的 `BeanPostProcessor` 机制扫描所有带有特定注解的方法，并将这些方法及其唯一标识（`code`）注册到一个全局的 Map 中。
   - 生产者在发送任务时，只需要指定任务的 `code` 和相关参数，消费者接收到任务后，会根据 `code` 从 Map 中找到对应的导出方法并执行。
   - 导出完成后，生成的文件会被存储到文件中心，同时更新数据库中的任务状态（如“生成中”或“已完成”）。
3. **优化与挑战**：
   - **高并发处理**：为了应对高并发场景，我对 Kafka 的分区进行了合理配置，确保任务能够均匀分配到多个消费者实例。
   - **失败重试机制**：针对导出失败的任务，我实现了基于 Redis 的延迟队列，支持自动重试和手动触发。
   - **性能提升**：通过异步处理，我们将导出接口的响应时间从原来的几十秒降低到了几百毫秒，用户体验显著提升。
4. **结果**：
   - 重构后，系统的导出功能变得更加稳定，支持每天数万次的导出请求。
   - 用户可以通过下载中心实时查看导出进度，满意度大幅提升。

### 2. 导出任务，生产消费者为什么一定要用消息队列？起一个线程池是不是也可以？

- 首先，使用线程池确实可以实现异步处理，但它和消息队列相比有一些局限性。
- 消息队列的优势主要体现在以下几个方面：
  1. **解耦性**：消息队列可以让生产者和消费者完全解耦，消费者可以独立扩展或替换，而线程池的生产者和消费者是强耦合的。
  2. **可靠性**：消息队列本身具备持久化能力，即使消费者宕机，任务也不会丢失；而线程池中的任务如果执行失败，可能会直接丢失。
  3. **扩展性**：消息队列支持分布式扩展，消费者可以根据负载动态扩容；而线程池的容量有限，难以应对突发流量。
  4. **流量削峰**：消息队列可以缓冲高峰期的任务请求，避免系统被瞬时流量压垮；而线程池可能会因为任务过多而导致过载。
- 在我们的客服系统中，导出任务是一个高频且耗时的操作，可能会面临以下挑战：
  - 大量用户同时提交导出请求，可能导致线程池过载。
  - 如果系统宕机，未完成的任务会丢失，影响用户体验。
  - 需要支持水平扩展以应对未来的业务增长。
- 基于这些需求，我们选择了消息队列（如Kafka）作为解决方案，因为它能够很好地满足解耦、可靠性和扩展性的要求。
- 当然，如果是小规模系统，任务量不大且对可靠性和扩展性要求不高，使用线程池也是可以的。但在我们的TOB场景中，消息队列显然是更优的选择。

### 3. 为什么选择BeanPostProcessor来实现特定功能

BeanPostProcessor是Spring框架提供的一个扩展点，允许我们在Spring容器实例化Bean之后、初始化完成的前后对其进行定制化处理。
在我们的系统中，导出任务的方法分散在不同的业务模块中，且可能随着业务增长不断增加新的导出方法。如果手动维护这些方法的注册逻辑，代码会变得复杂且容易出错。通过BeanPostProcessor，我们可以在运行时自动扫描所有带有特定注解的方法，并将它们注册到一个统一的map中，方便后续调用。

优点：动态扫描与注册、减少人为错误、灵活性与扩展性

## 工单系统

### 1. 工单业务是怎么样的？

- 创建流程模板：首先由管理员创建流程模板。节点的审批：指定人，角色，部门审批。节点的功能：通过、驳回、拒绝等。配置表单：可自行拖拽字段进行配置
- 发起人根据某一个流程模板创建流程
- 审批人审批，需要填写各种字段
- 审批结束，流程结束

### 2. 怎么开发一个新流程？

业务层需要调用createFlow，resubmitFlow等方法

需要实现一个flowCallback\<E extends IFlowInfoVO\>接口，并将其放入spring容器中

一些核心方法如下：

- getFlowCodes：返回一个String字符串，唯一标识。整个流程框架使用的是策略模式，该code表示调用哪一个策略类
- callbackBusiness：流程发起、通过、驳回等操作时，都会调用该方法。调用时会传入流程的各种元信息
- refreshBusinessContent：查看流程详情时会调用该方法。默认返回的是流程创建时的快照数据，如有实时查询的数据则写在这里
- splitStartCircleStep：解析动态审批人。例如某个节点配置的是由汇报链直到老板的下一级来审批，该方法就是解析这些节点，变成多个节点

需要开发人员手写一个json，需要在json里配置审批人员，审批节点，流转规则等

### 3. 流程的关键表

- Flow：id，流程模板id，发起人id，提交时的参数map，流程模板的快照，流程状态，优先级
- FlowStep：id，流程id，节点状态，下一个节点的集合，表单id
- FlowAuditor：id，流程节点id，经办人类型，经办人id
- FlowAuditStep：id，流程id，流程节点id，实际审批人id，审批结果，被驳回的节点
- FlowSchema：id，名称，工作流json，工作流类型，业务方code

### 4. 可配置表单的关键表

- Form：id，类型，状态
- FormField：id，表单id，名称，数据类型
- FormFieldData：id，表单字段id，数据

## OA系统

### 1. 项目中用过什么设计模式？

在我们之前开发的一个OA系统的员工管理模块中，最初只支持内部员工的增删改查操作。但随着业务扩展，需要接入多种类型的外包员工（比如电销员工、催收员工、客服员工等）。这些外包员工与内部员工在基础操作上类似，但在校验逻辑、数据同步目标等方面存在显著差异。比如，某些员工类型需要校验邮箱，而另一些不需要；部分外包员工的数据还需要同步到外部系统（如电销系统或催收系统）。

针对这些问题，我采用了策略模式和模板方法模式进行重构：

- **策略模式**：用于处理不同员工类型的校验逻辑差异。每种员工类型对应一个具体的策略实现类，通过上下文对象动态选择合适的策略，避免了大量的`if-else`判断，提高了代码的可维护性和扩展性。
- **模板方法模式**：用于定义员工新增操作的整体流程（如校验、入库、同步、通知等）。这些步骤对于所有员工类型来说是固定的，但每个步骤的具体实现可能因员工类型而异。通过抽象类定义模板方法，子类实现具体细节，从而实现了流程的复用和灵活性。

通过这次重构，我们成功解决了以下问题：

- 消除了大量重复代码，减少了代码冗余。
- 提高了系统的可扩展性。当有新的员工类型接入时，只需新增对应的策略实现类和模板方法子类即可，无需修改现有代码，符合开闭原则。
- 改善了代码的可读性和维护性，团队成员在理解代码逻辑时更加直观，降低了沟通成本。

这次实践让我深刻体会到设计模式在应对复杂业务需求时的强大作用。未来，在面对类似的多态性需求时，我会继续探索更多设计模式的应用场景，同时也会注重与其他团队成员分享经验，推动整个团队的技术进步。
